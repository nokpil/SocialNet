{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network\n",
    "import envs\n",
    "import json\n",
    "from itertools import product\n",
    "from functools import reduce  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5272c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 3\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 400\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SI'\n",
    "env_name = 'SL_NK_' + action_type\n",
    "\n",
    "nx_dict = {'complete': nx.complete_graph, 'ba': nx.barabasi_albert_graph, 'er': nx.erdos_renyi_graph, 'maxmc':max_mean_clustering_network} \n",
    "nx_arg_dict = {'complete': {'n': M}, 'ba': {'n': M, 'm': 19}, 'er': {'n': M, 'p': 0.3}, 'maxmc': {'n': M}}\n",
    "\n",
    "env_kwargs = {\n",
    "        'E': E,\n",
    "        'M': M,\n",
    "        'N': N,\n",
    "        'K': K,\n",
    "        'neighbor_num': NN,\n",
    "        'exp': exp,\n",
    "        'graph': nx_dict[graph_type],\n",
    "        'graph_dict': nx_arg_dict[graph_type],\n",
    "        'reward_type': reward_type,\n",
    "        'action_type': action_type,\n",
    "        'extra_type': extra_type,\n",
    "    'corr_type': 'TT'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict = {}\n",
    "baseline_data_dict['keys'] = ['Ret', 'FinalScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ee0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_num = 10\n",
    "test_ensemble_num = 100\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8e415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "# 'FollowBest', 'FollowBest_indv', 'FollowBest_random', 'FollowBest_prob','FollowMajor', 'FollowMajor_indv', 'FollowMajor_random', 'FollowMajor_prob', 'IndvLearning', \n",
    "baselines = ['IndvRandom', 'IndvProb', 'RandomCopy']\n",
    "\n",
    "for baseline_name in baselines:\n",
    "    if baseline_name not in baseline_data_dict.keys():\n",
    "        print(f\"Baseline : {baseline_name}\")\n",
    "        baseline_data = {}\n",
    "        baseline_data['Ret'] = []\n",
    "        baseline_data['FinalScore'] = []\n",
    "        baseline_data['scr_buf'] = []\n",
    "        baseline_data['unq_buf'] = []\n",
    "\n",
    "        for i in range(env_num):\n",
    "            print(i)\n",
    "            env_base = env_list[i]\n",
    "            ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT')\n",
    "            scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "            unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "\n",
    "            o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "            ep_ret, ep_len = 0, 0\n",
    "            for t in range(trj_len):\n",
    "                a = ac_base.step(o)\n",
    "                next_o, r, s = env_base.step(a)\n",
    "                ep_ret += r\n",
    "                ep_len += 1\n",
    "                scr_buf[..., t] = s\n",
    "                for e in range(test_ensemble_num):\n",
    "                    freq = np.unique(a[e], axis=0)\n",
    "                    unq_buf[e][t] = freq.shape[0]\n",
    "                o = next_o\n",
    "\n",
    "            baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "            baseline_data['FinalScore'].append(np.mean(s))\n",
    "            baseline_data['scr_buf'].append(scr_buf)\n",
    "            baseline_data['unq_buf'].append(unq_buf)\n",
    "        baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "        baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "        baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "        baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "        baseline_data_dict[baseline_name] = baseline_data\n",
    "        print(\"Baseline finished\")\n",
    "        print(f\"{baseline_name}, {baseline_data_dict[baseline_name]['Ret']}, {baseline_data_dict[baseline_name]['FinalScore']}\")\n",
    "with open(f'baseline_{graph_type}_N{N}K{K}NN{NN}_exp{exp}_L400_3.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'baseline_{graph_type}_N{N}K{K}NN{NN}_exp{exp}_L400_tot.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_complete_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85411a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./baseline_complete_N15K3NN3_exp8_L400_tot.pkl', 'rb') as f:\n",
    "    baseline_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dict['RandomCopy']['scr_buf'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_complete_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b26afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_complete_dict['FollowBest']['scr_buf'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148c25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merger of two dictionary\n",
    "score_list = ['Ret', 'FinalScore']\n",
    "\n",
    "baseline_complete_dict2 = baseline_dict\n",
    "for key1 in baseline_complete_dict.keys():\n",
    "    if key1 != 'keys':\n",
    "        print(key1)\n",
    "        for key2 in baseline_complete_dict[key1]:\n",
    "            if key2 in score_list:\n",
    "                baseline_complete_dict[key1][key2] = baseline_complete_dict[key1][key2] * 0.2 + baseline_complete_dict2[key1][key2] * 0.8\n",
    "                print(f'{key2}:{baseline_complete_dict[key1][key2]}')\n",
    "            else:\n",
    "                baseline_complete_dict[key1][key2] = np.r_[baseline_complete_dict[key1][key2], baseline_complete_dict2[key1][key2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157963c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/baseline_complete_N15K{i}NN3_tot.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_complete_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R'}\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], ls=(0, (3, 2)), label=label_dict[baseline_name])\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Payoff')\n",
    "ax.legend(fontsize=8, loc=4)\n",
    "#fig_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_disc_g99_I100_L200_RST_TMT'\n",
    "#plt.savefig(f'./result/figure/{fig_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba33d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7560b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate = np.tile(np.expand_dims(states, axis=-2), (1, 1, 15, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_indv = np.zeros_like(states_indv_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_indv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd48d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 100\n",
    "M = 100\n",
    "N = 15\n",
    "\n",
    "states = np.random.randint(0, 2, (E, M, N))\n",
    "states_indv_candidate = np.tile(np.expand_dims(states, axis=-2), (1, 1, N, 1))\n",
    "index_indv = np.zeros_like(states_indv_candidate)\n",
    "np.put_along_axis(index_indv, np.tile(np.arange(N)[np.newaxis, np.newaxis, :, np.newaxis], (E, M, 1, 1)), 1, axis=-1)\n",
    "states_indv_candidate = (states_indv_candidate + index_indv) % 2\n",
    "scores_indv = env.get_score(states=states_indv_candidate.reshape(-1, N, N)).reshape(E, M, N, 1)\n",
    "maxscore_indv = np.argmax(scores_indv, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77756061",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_indv = np.zeros_like(states)\n",
    "np.put_along_axis(index_indv, maxscore_indv, 1, axis=-1)\n",
    "states_indv = (states + index_indv) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape, B[None,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77479683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf23a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxscore_indv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxscore_indv.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate.reshape(-1, 15, 15).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxscore_indv.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate[maxscore_indv.squeeze()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa683d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate = (states_indv_candidate + index_indv) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_indv = env.get_score(states=states_indv_candidate.reshape(-1, N, N)).reshape(E, M, N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_indv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938dece4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_indv = np.max(score_indv, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c95969",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_indv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580eed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.put_along_axis(index_indv, np.random.randint(0, N, (E, M, 1)), 1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_indv_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_score(states_indv_candidate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef020ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

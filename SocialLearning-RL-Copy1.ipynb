{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:48:02.560846Z",
     "start_time": "2021-04-04T02:48:02.517939Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as RLRP\n",
    "from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.nn.init import xavier_normal\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network\n",
    "import envs\n",
    "import json\n",
    "from itertools import product\n",
    "from functools import reduce  \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 3\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 200\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SI'\n",
    "env_name = 'SL_NK_' + action_type\n",
    "\n",
    "nx_dict = {'complete': nx.complete_graph, 'ba': nx.barabasi_albert_graph, 'er': nx.erdos_renyi_graph, 'maxmc':max_mean_clustering_network} \n",
    "nx_arg_dict = {'complete': {'n': M}, 'ba': {'n': M, 'm': 19}, 'er': {'n': M, 'p': 0.3}, 'maxmc': {'n': M}}\n",
    "\n",
    "env_kwargs = {\n",
    "        'E': E,\n",
    "        'M': M,\n",
    "        'N': N,\n",
    "        'K': K,\n",
    "        'neighbor_num': NN,\n",
    "        'exp': exp,\n",
    "        'graph': nx_dict[graph_type],\n",
    "        'graph_dict': nx_arg_dict[graph_type],\n",
    "        'reward_type': reward_type,\n",
    "        'action_type': action_type,\n",
    "        'extra_type': extra_type,\n",
    "    'corr_type': 'TT'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase transition을 찾는 NN\n",
    "# 다양한 example에서 공통된 미방의 꼴을 찾는 (공통의 정의?)\n",
    "# 수열의 embedding (f(x), -5 < x < 5 범위의 수열을 함수의 symbolic한 form과 매칭시키는 함수)\n",
    "# dynamics를 embedding하는 것 (CA를 embedding하면 비슷한 것끼리 뭉치나?\n",
    "# NN의 classification 분포를 바탕으로 판단하는 다른 NN (이미 있을 것)\n",
    "# GA의 Neural Net version\n",
    "\n",
    "# 내재적인 rule이 있는지, 얼마나 쉬운지의 여부를 측정하는 neural measure?\n",
    "# test_loss / train_loss를 minimize 할 수 있는가?\n",
    "# neural network 1 의 output을 reward로 받는 neural network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_name, epoch):\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = nx.complete_graph\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'E': env_kwargs['E'],\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sampler import BatchSampler\n",
    "ensemble_num = 10\n",
    "agent_num = 100\n",
    "trj_len = 200\n",
    "batch_size = 1000\n",
    "\n",
    "train_sampler = BatchSampler(ensemble_num, agent_num, trj_len, batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2025\n",
    "# complete_L200_2 2269\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "# 79, 177\n",
    "exp_name = 'test_test'\n",
    "epoch = 5000 # 5738\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "reward_supply_type = 'full'\n",
    "env_kwargs['rescale'] = False\n",
    "terminate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 10,\n",
       " 'K': 11,\n",
       " 'M': 100,\n",
       " 'N': 15,\n",
       " 'action_type': 'total',\n",
       " 'corr_type': 'TT',\n",
       " 'env_scheduler': <envs.env_scheduler.random_env_scheduler at 0x16333a41708>,\n",
       " 'exp': 8,\n",
       " 'extra_type': 'SIRF',\n",
       " 'graph': <function decorator.complete_graph(n, create_using=None)>,\n",
       " 'graph_dict': {'n': 100},\n",
       " 'graph_type': 'complete',\n",
       " 'neighbor_num': 3,\n",
       " 'rescale': False,\n",
       " 'reward_type': 'indv_raw_full'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.35 MiB for an array with shape (100, 100, 3, 19) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-22d4d5282bf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_pi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mnext_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mep_ret\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mep_len\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive\\연구\\ML\\MyProject\\SocialNet\\SocialNet\\envs\\nk_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mrew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Even if reward correction is True, this makes the state and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSL_NK_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSL_NK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive\\연구\\ML\\MyProject\\SocialNet\\SocialNet\\envs\\nk_env.py\u001b[0m in \u001b[0;36mget_obs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             [\n\u001b[0;32m    156\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighbor_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m             ],\n\u001b[0;32m    159\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.35 MiB for an array with shape (100, 100, 3, 19) and data type float64"
     ]
    }
   ],
   "source": [
    "# normal test, without unique/prob\n",
    "buf_list = []\n",
    "final_score_list = []\n",
    "\n",
    "Ret_list = []\n",
    "env_num = 50\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    test_ensemble_num = 100\n",
    "    buf = PPOBuffer(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        test_ensemble_num, \n",
    "        env_kwargs['M'], \n",
    "        dim_len, \n",
    "        trj_len, \n",
    "        gamma, \n",
    "        lam, \n",
    "        split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "\n",
    "    \n",
    "    env = env_list[i]\n",
    "    o, _ = env.reset(test_ensemble_num, base=True) \n",
    "    ep_ret, ep_len = 0, 0\n",
    "    best_ep_ret = -np.inf\n",
    "\n",
    "    for t in range(trj_len):\n",
    "        epoch_ended = t == trj_len - 1\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "\n",
    "        next_o, r, s = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        \n",
    "        if reward_supply_type == 'full':\n",
    "            buf.store(o, a, r, v, s, logp)\n",
    "        else:\n",
    "            if epoch_ended:\n",
    "                if reward_supply_type == 'final':\n",
    "                    buf.store(o, a, r * trj_len, v, s, logp)\n",
    "                elif reward_supply_type == 'finalmean':\n",
    "                    buf.store(o, a, ep_ret, v, s, logp)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "            else:\n",
    "                buf.store(o, a, 0, v, s, logp)\n",
    "\n",
    "        # Update obs (critical!)\n",
    "        o = next_o\n",
    "        \n",
    "        if epoch_ended:\n",
    "            a, v, logp, pi = ac.step(\n",
    "                torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                return_pi=True\n",
    "            )\n",
    "            _, _, s = env.step(a)\n",
    "            if terminate:\n",
    "                buf.finish_path(np.zeros_like(v))\n",
    "            else:\n",
    "                buf.finish_path(v)\n",
    "    \n",
    "    Ret=ep_ret / ep_len\n",
    "    Ret_list.append(Ret)\n",
    "    EpLen=ep_len\n",
    "    FinalScore=np.mean(s)\n",
    "    buf_list.append(buf)\n",
    "    final_score_list.append(FinalScore)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "\n",
    "Ret_list = np.array(Ret_list)\n",
    "final_score_list = np.array(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = np.array(Ret_list)\n",
    "final_score_list = np.array(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Ret_list), np.mean(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_buf_list = []\n",
    "for buf in buf_list:\n",
    "    scr_buf_list.append(buf.scr_buf)\n",
    "scr_buf_list = np.array(scr_buf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_dict = {}\n",
    "inspection_dict['scr_buf_list'] = scr_buf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/inspection_dict/inspection_dict_{exp_name}_E{epoch}.pkl', 'wb') as f:\n",
    "    pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original landscape test\n",
    "\n",
    "buf_list = []\n",
    "final_score_list = []\n",
    "unq_buf_list = []\n",
    "prob_buf_list = []\n",
    "Ret_list = []\n",
    "env_num = 5\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    test_ensemble_num = 1\n",
    "    buf = PPOBuffer(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        test_ensemble_num, \n",
    "        env_kwargs['M'], \n",
    "        dim_len, \n",
    "        trj_len, \n",
    "        gamma, \n",
    "        lam, \n",
    "        split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "    unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "    prob_buf = []\n",
    "    \n",
    "    env = env_list[i]\n",
    "    env_list[i].env_scheduler.local_rank = i\n",
    "    o, _ = env.reset(test_ensemble_num)\n",
    "    print(env.landscape.get_global_max()[1])\n",
    "    ep_ret, ep_len = 0, 0\n",
    "    best_ep_ret = -np.inf\n",
    "\n",
    "    for t in range(trj_len):\n",
    "        epoch_ended = t == trj_len - 1\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "        \n",
    "        next_o, r, s = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        #print(np.mean(r), np.mean(s))\n",
    "        # save and log\n",
    "        \n",
    "        if reward_supply_type == 'full':\n",
    "            buf.store(o, a, r, v, s, logp)\n",
    "        else:\n",
    "            if epoch_ended:\n",
    "                if reward_supply_type == 'final':\n",
    "                    buf.store(o, a, r * trj_len, v, s, logp)\n",
    "                elif reward_supply_type == 'finalmean':\n",
    "                    buf.store(o, a, ep_ret, v, s, logp)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "            else:\n",
    "                buf.store(o, a, 0, v, s, logp)\n",
    "\n",
    "        # Update obs (critical!)\n",
    "        o = next_o\n",
    "        for e in range(test_ensemble_num):\n",
    "            freq = np.unique(a[e], axis=0)\n",
    "            unq_buf[e][t] = freq.shape[0]\n",
    "        \n",
    "        if epoch_ended:\n",
    "            a, v, logp, pi = ac.step(\n",
    "                torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                return_pi=True\n",
    "            )\n",
    "            _, _, s = env.step(a)\n",
    "            if terminate:\n",
    "                buf.finish_path(np.zeros_like(v))\n",
    "            else:\n",
    "                buf.finish_path(v)\n",
    "            prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "    \n",
    "    unq_buf_list.append(unq_buf)\n",
    "    prob_buf_list.append(prob_buf)\n",
    "    Ret=ep_ret / ep_len\n",
    "    Ret_list.append(Ret)\n",
    "    EpLen=ep_len\n",
    "    FinalScore=np.mean(s)\n",
    "    buf_list.append(buf)\n",
    "    final_score_list.append(FinalScore)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "\n",
    "unq_buf_list = np.array(unq_buf_list)\n",
    "prob_buf_list = np.array(prob_buf_list)\n",
    "Ret_list = np.array(Ret_list)\n",
    "final_score_list = np.array(final_score_list)\n",
    "\n",
    "inspection_dict = {}\n",
    "inspection_dict['buf_list'] = buf_list\n",
    "inspection_dict['unq_buf_list'] = unq_buf_list\n",
    "inspection_dict['prob_buf_list'] = prob_buf_list\n",
    "\n",
    "#with open('./result/inspection_dict/inspection_dict_complete_N15K7NN3L200_disc_g99_I100_L200_RST_TMT.pkl', 'wb') as f:\n",
    "#    pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_list[4].rew_buf[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = f'data/runs/{exp_name}/'\n",
    "\n",
    "with open(rel_path + f\"{exp_name}_landscape_list.pkl\", 'rb') as f:\n",
    "    landscape_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(env_num):\n",
    "    print(landscape_list[i].get_global_max()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example = a[0][6]\n",
    "land.get_value(example)/land.get_global_max()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reward_group_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/inspection_dict/inspection_dict_complete_N15K7NN3L200_disc_g99_I100_L200_RST_TMT.pkl', 'wb') as f:\n",
    "    pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_list[10]\n",
    "o, _ = env.reset(test_ensemble_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single env batch test\n",
    "buf_list = []\n",
    "final_score_list = []\n",
    "unq_buf_list = []\n",
    "prob_buf_list = []\n",
    "Ret_list = []\n",
    "env_num = 10\n",
    "test_env = envs.__dict__[env_name](**env_kwargs)\n",
    "env_list = [test_env for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    test_ensemble_num = 100\n",
    "    buf = PPOBuffer(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        test_ensemble_num, \n",
    "        env_kwargs['M'], \n",
    "        dim_len, \n",
    "        trj_len, \n",
    "        gamma, \n",
    "        lam, \n",
    "        split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "    unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "    prob_buf = []\n",
    "    \n",
    "    env = env_list[i]\n",
    "    o, _ = env.reset(test_ensemble_num) \n",
    "    ep_ret, ep_len = 0, 0\n",
    "    best_ep_ret = -np.inf\n",
    "\n",
    "    for t in range(trj_len):\n",
    "        epoch_ended = t == trj_len - 1\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "        \n",
    "        next_o, r, s = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        #print(np.mean(r), np.mean(s))\n",
    "        # save and log\n",
    "        \n",
    "        if reward_supply_type == 'full':\n",
    "            buf.store(o, a, r, v, s, logp)\n",
    "        else:\n",
    "            if epoch_ended:\n",
    "                if reward_supply_type == 'final':\n",
    "                    buf.store(o, a, r * trj_len, v, s, logp)\n",
    "                elif reward_supply_type == 'finalmean':\n",
    "                    buf.store(o, a, ep_ret, v, s, logp)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "            else:\n",
    "                buf.store(o, a, 0, v, s, logp)\n",
    "\n",
    "        # Update obs (critical!)\n",
    "        o = next_o\n",
    "        for e in range(test_ensemble_num):\n",
    "            freq = np.unique(a[e], axis=0)\n",
    "            unq_buf[e][t] = freq.shape[0]\n",
    "        \n",
    "        if epoch_ended:\n",
    "            a, v, logp, pi = ac.step(\n",
    "                torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                return_pi=True\n",
    "            )\n",
    "            _, _, s = env.step(a)\n",
    "            if terminate:\n",
    "                buf.finish_path(np.zeros_like(v))\n",
    "            else:\n",
    "                buf.finish_path(v)\n",
    "           \n",
    "            prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "    \n",
    "    unq_buf_list.append(unq_buf)\n",
    "    prob_buf_list.append(prob_buf)\n",
    "    Ret=ep_ret / ep_len\n",
    "    Ret_list.append(Ret)\n",
    "    EpLen=ep_len\n",
    "    FinalScore=np.mean(s)\n",
    "    buf_list.append(buf)\n",
    "    final_score_list.append(FinalScore)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "\n",
    "unq_buf_list = np.array(unq_buf_list)\n",
    "prob_buf_list = np.array(prob_buf_list)\n",
    "Ret_list = np.array(Ret_list)\n",
    "final_score_list = np.array(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple epochs test\n",
    "\n",
    "epoch_list = [1600, 1800, 2000, 2025, 2200, 2400, 2600, 2800, 3000, 3200]\n",
    "result = {}\n",
    "\n",
    "for epoch in epoch_list :\n",
    "    print(epoch)\n",
    "    exp_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_new_rand200'\n",
    "    ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "    score_list = []\n",
    "    env_num = 10\n",
    "    test_ensemble_num = 100\n",
    "    env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "\n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        buf = PPOBuffer(\n",
    "            obs_dim, \n",
    "            act_dim, \n",
    "            test_ensemble_num, \n",
    "            env_kwargs['M'], \n",
    "            dim_len, \n",
    "            trj_len, \n",
    "            gamma, \n",
    "            lam, \n",
    "            split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "\n",
    "        env = env_list[i]\n",
    "        o, _ = env.reset(test_ensemble_num) \n",
    "        ep_ret, ep_len = 0, 0\n",
    "        best_ep_ret = -np.inf\n",
    "        env.scores.flatten().max()\n",
    "\n",
    "        for t in range(trj_len):\n",
    "            a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "\n",
    "            next_o, r, s = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "            #print(np.mean(r), np.mean(s))\n",
    "            # save and log\n",
    "            buf.store(o, a, r, v, s, logp)\n",
    "\n",
    "            # Update obs (critical!)\n",
    "            o = next_o\n",
    "            epoch_ended = t == trj_len - 1\n",
    "\n",
    "            if epoch_ended:\n",
    "                a, v, logp, pi = ac.step(\n",
    "                    torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                    return_pi=True\n",
    "                )\n",
    "                _, _, s = env.step(a)\n",
    "                buf.finish_path(v)\n",
    "\n",
    "        score_list.append(buf.scr_buf)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "        \n",
    "    result[epoch] = np.array(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_dict = {}\n",
    "inspection_dict['buf_list'] = buf_list\n",
    "inspection_dict['unq_buf_list'] = unq_buf_list\n",
    "inspection_dict['prob_buf_list'] = prob_buf_list\n",
    "\n",
    "with open('./result/inspection_dict/inspection_dict_complete_N15K7NN3L200_newppo_g95_1.pkl', 'wb') as f:\n",
    "    pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance(y_pred: np.ndarray, y_true: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes fraction of variance that ypred explains about y.\n",
    "    Returns 1 - Var[y-ypred] / Var[y]\n",
    "    interpretation:\n",
    "        ev=0  =>  might as well have predicted zero\n",
    "        ev=1  =>  perfect prediction\n",
    "        ev<0  =>  worse than just predicting zero\n",
    "    :param y_pred: the prediction\n",
    "    :param y_true: the expected value\n",
    "    :return: explained variance of ypred and y\n",
    "    \"\"\"\n",
    "    y_pred, y_true = y_pred.flatten(), y_true.flatten()\n",
    "    var_y = np.var(y_true)\n",
    "    return np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = np.array(Ret_list)\n",
    "final_score_list = np.array(final_score_list)\n",
    "np.mean(Ret_list), np.mean(final_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.7796671434669661, 87.42018489279255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buf_list[0].ret_buf[5][14])\n",
    "plt.plot(buf_list[0].val_buf[5][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_list[0].rew_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buf_list[0].rew_buf[1][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((buf_list[0].val_buf[1].flatten() - buf_list[0].ret_buf[1].flatten())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance(buf_list[0].val_buf, buf_list[0].ret_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/inspection_dict/inspection_dict_complete_N15K7NN3L200_disc_g99_I100_L200_RST_TMT.pkl', 'rb') as f:\n",
    "    inspection_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_list = inspection_dict['buf_list']\n",
    "unq_buf_list = inspection_dict['unq_buf_list']\n",
    "prob_buf_list = inspection_dict['prob_buf_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(buf_list[0].adv_buf[i][j])\n",
    "plt.plot(buf_list2[0].adv_buf[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buf_list[0].val_buf[i][j])\n",
    "plt.plot(buf_list2[0].val_buf[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buf_list[0].rew_buf[i][j])\n",
    "plt.plot(buf_list2[0].rew_buf[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_scr_list = []\n",
    "for i in range(len(buf_list)):\n",
    "    buf_scr_list.append(buf_list[i].scr_buf)\n",
    "buf_scr_list = np.array(buf_scr_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = baseline_data_dict['FollowBest_indv']['scr_buf']\n",
    "x = buf_scr_list\n",
    "for i in range(10):\n",
    "    print(np.mean(x[i]), np.std(x[i]))\n",
    "    \n",
    "print(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(np.mean(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = baseline_data_dict['FollowBest_indv']['scr_buf']\n",
    "x = buf_scr_list\n",
    "for i in range(10):\n",
    "    print(np.mean(x[i]), np.std(x[i]))\n",
    "    \n",
    "print(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_ret_list = []\n",
    "for i in range(len(buf_list)):\n",
    "    buf_ret_list.append(buf_list[i].ret_buf)\n",
    "buf_ret_list = np.array(buf_ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_scr_list2 = []\n",
    "for i in range(len(buf_list)):\n",
    "    buf_scr_list2.append(buf_list[i].scr_buf)\n",
    "buf_scr_list2 = np.array(buf_scr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = buf_scr_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/baseline_data/baseline_complete_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/baseline_complete_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(baseline_data_dict['FollowBest_random']['scr_buf'][:, :, :, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowBest_random', 'FollowBest_prob',\n",
    "             'FollowMajor', 'FollowMajor_indv', 'FollowMajor_random', 'FollowMajor_prob',\n",
    "            'IndvLearning', 'IndvRandom', 'IndvProb', 'RandomCopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color_list = ['red', 'blue', 'orange', 'yellow', 'black', 'gray', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "marker_list = ['o', 'x', 's', 'p', '*', '<', '>', 'd']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowBest_prob':'BI-P',\n",
    "              'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R', 'FollowMajor_prob':'CF-P',\n",
    "             'IndvLearning':'PI', 'IndvRandom':'PI-R', 'IndvProb':'PI-P', 'RandomCopy':'RI'}\n",
    "\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], ls=(0, (3, 2)), label=label_dict[baseline_name])\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "x = buf_scr_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='r', label='RL')\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Payoff')\n",
    "ax.legend(fontsize=8, loc=4)\n",
    "fig_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_disc_g99_I100_L200_RST_TMT'\n",
    "#plt.savefig(f'./result/figure/{fig_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in baseline_data_dict2.keys():\n",
    "    if key != 'keys':\n",
    "        print(key)\n",
    "        for key2 in baseline_data_dict2['keys']:\n",
    "            print(baseline_data_dict2[key][key2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {'CF-I':[64.77, 78.64], 'BI-I': [55.65, 55.53], 'BI':[31.31, 31.51], 'PI':[32.76, 35.95], 'RI':[31.01, 31.53], 'CF':[4.33, 4.39]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(complete_dict)\n",
    "if length%2:\n",
    "    # odd\n",
    "    start = -(length//2)*width\n",
    "else:\n",
    "    # even\n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i*width for i in range(length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,3), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "complete_dict = {'RL':[70, 80], 'CF-I':[64.77, 78.64], 'BI-I': [55.65, 55.53], 'BI':[31.31, 31.51], 'PI':[32.76, 35.95], 'RI':[31.01, 31.53], 'CF':[4.33, 4.39]}\n",
    "color_list = ['red', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "center  = np.array([0., 3.])\n",
    "width = 0.2\n",
    "length = len(complete_dict)\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "for i, key in enumerate(complete_dict.keys()):\n",
    "    ax.bar(center+offset[i], complete_dict[key], width, label=key, color = color_list[i])\n",
    "        \n",
    "#BI_rect = ax.bar(x - width/2, con, width, label='CN', color = 'salmon')\n",
    "#BI_rect = ax.bar(x + width/2, siam, width, label='SNN', color = 'skyblue')\n",
    "\n",
    "ax.set_ylabel('Payoff', fontsize=12)\n",
    "ax.set_xticks(center)\n",
    "ax.set_xticklabels(labels, fontsize=12)\n",
    "ax.legend(loc=8, ncol=2, fontsize = 8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = unq_buf_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='black', lw=3, label='RL_TT')\n",
    "\n",
    "x = baseline_data['FollowMajor_indv']['unq_buf']\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='FollowMajor_indv')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "counter+=1\n",
    "\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c='black', lw=3, label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "\n",
    "\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend(fontsize=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def test1(s1=widgets.IntSlider(min=0, max=100, step=1, value=40, description='Score_1:'), \n",
    "            s2=widgets.IntSlider(min=0, max=100, step=1, value=10, description='Score_2:'),\n",
    "            s3=widgets.IntSlider(min=0, max=100, step=1, value=20, description='Score_3:'),\n",
    "            s4=widgets.IntSlider(min=0, max=100, step=1, value=60, description='Score_4:')\n",
    "             ):\n",
    "    %matplotlib inline\n",
    "    norm_const = 1\n",
    "    fig = plt.figure(figsize = (12, 4), dpi=200, constrained_layout=True)\n",
    "    widths = [0.5, 0.2, 0.2, 0.2]\n",
    "    heights = [1]\n",
    "    gs = fig.add_gridspec(nrows=1, ncols=4, width_ratios=widths, height_ratios=heights)\n",
    "\n",
    "    ax10 = fig.add_subplot(gs[0])\n",
    "    s1 /= norm_const\n",
    "    s2 /= norm_const\n",
    "    s3 /= norm_const\n",
    "    s4 /= norm_const\n",
    "    \n",
    "    #'''\n",
    "    indv_obs_data = np.array([\n",
    "                  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, s1, 1],\n",
    "                [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, s2, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, s3, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_data = np.array([[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s1, 1], \n",
    "              [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s2, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s3, 0],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_score = [s1, s2, s3, s4]\n",
    "    ax10.imshow(indv_obs_data[..., :-2], cmap=cm.binary)\n",
    "    ax10.set_title(f'Observation')\n",
    "    #ax10.set_xticks([])\n",
    "    #ax10.set_yticks([])\n",
    "\n",
    "    ax10.annotate(\"score\", (15, -0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[0], (15, 0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[1], (15, 1.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[2], (15, 2.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[3], (15, 3.5), fontsize=10, annotation_clip=False)\n",
    "\n",
    "    ax11 = fig.add_subplot(gs[1])\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(indv_obs_data, dtype=torch.float32, device='cuda').unsqueeze(0), return_pi=True)\n",
    "    prob_data = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    ax11.imshow(prob_data, cmap=cm.binary, vmin=0, vmax=1)\n",
    "    ax11.set_title('Prob.')\n",
    "    ax11.set_xticks([])\n",
    "    ax11.set_yticks([])\n",
    "\n",
    "    ax12 = fig.add_subplot(gs[2])\n",
    "    act_data = a\n",
    "    ax12.imshow(act_data, cmap=cm.binary)\n",
    "    #action_score = env_list[0].get_score(act_data.reshape(1, 1, -1)).item()\n",
    "    ax12.set_title('Action')\n",
    "    ax12.set_xticks([])\n",
    "    ax12.set_yticks([])\n",
    "\n",
    "# 1등 점수, 2등과 3등 점수의 합 (대충?), 2등과 1등의 점수 차가 영향을 미침\n",
    "# 내 점수가 20 이상인데 다른 개체들과의 차이가 심하면 (최저 -10?) 메이저 베낌\n",
    "# 자기보다 다들 높으면 확실히 best로 가려고 함 (2등과 1등 점수차가 상대적으로 작아도)\n",
    "# 반대로 2, 3등이 고만고만하면 1등과의 점수차가 압도적이어야 바꿈\n",
    "# 자기 점수가 높을 수록 2등, 3등 점수와 1등 점수차도 더 벌어짐 (+상수보다는 선형?)\n",
    "# 자기가 꼴찌가 아니면 전략 안 바꿈! (하지만 극단적으로 높은 점수는 가끔 받음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(inspection, buf_list=fixed(buf_list), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "if baselines:\n",
    "    baseline_name = 'FollowMajor_indv'\n",
    "    x = baseline_data[baseline_name]['scr_buf'][:20, :20]\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action\n",
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "insp_dict = {}\n",
    "insp_dict['RL'] = [[] for i in range(env_num)]\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = [[] for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    for j in range(trj_len):\n",
    "        o = buf_list[i].obs_buf[:, :, j]\n",
    "        insp_dict['RL'][i].append((ac.pi.module._distribution(torch.as_tensor(o, dtype=torch.float32, device='cuda')).probs[..., 1]).detach().cpu().numpy())\n",
    "        for baseline_name in baselines:\n",
    "            insp_dict[baseline_name][i].append(core.__dict__[baseline_name](env_base, action_type, extra_type).step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(buf_list[0].obs_buf[0][:, 50, 0, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(buf_list[0].act_buf[0][70, :, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_dict['RL'] = np.array(insp_dict['RL'])\n",
    "insp_dict['RL_flatten'] = (insp_dict['RL']>=0.5).astype(np.long)\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = np.array(insp_dict[baseline_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist\n",
    "\n",
    "rl2b_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowBest_indv'])**2, axis=-1))\n",
    "rl2m_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowMajor_indv'])**2, axis=-1))\n",
    "rl2i_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['IndvLearning'])**2, axis=-1))\n",
    "rl2r_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['RandomCopy'])**2, axis=-1))\n",
    "m2b_dist = np.sqrt(np.sum((insp_dict['FollowBest_indv'] - insp_dict['FollowMajor_indv'])**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(np.mean(rl2b_dist[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(np.mean(rl2m_dist[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(np.mean(rl2i_dist[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(np.mean(rl2r_dist[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(np.mean(m2b_dist[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_cosine(x, y):\n",
    "    return np.einsum('ij,ij->i', x, y) / (\n",
    "              np.linalg.norm(x, axis=1) * np.linalg.norm(y, axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl2b_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2m_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowMajor_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2i_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['IndvLearning'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2r_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['RandomCopy'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "m2b_cos = matrix_cosine(insp_dict['FollowMajor_indv'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(1 - np.mean(rl2b_cos[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(1 - np.mean(rl2m_cos[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(1 - np.mean(rl2i_cos[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(1 - np.mean(rl2r_cos[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(1 - np.mean(m2b_cos[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "insp_dict = {}\n",
    "insp_dict['RL'] = [[] for i in range(env_num)]\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = [[] for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    for j in range(trj_len):\n",
    "        o = buf_list[i].obs_buf[:, :, j]\n",
    "        a, v, logp = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'))\n",
    "        next_o, r, s = env_base.step(a)\n",
    "        insp_dict['RL'][i].append(next_o[:, :, 0, :-2])\n",
    "        for baseline_name in baselines:\n",
    "            insp_dict[baseline_name][i].append(core.__dict__[baseline_name](env_base, action_type, extra_type).step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_dict['RL'] = np.array(insp_dict['RL'])\n",
    "insp_dict['RL_flatten'] = (insp_dict['RL']>=0.5).astype(np.long)\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = np.array(insp_dict[baseline_name])\n",
    "# dist\n",
    "\n",
    "rl2b_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowBest_indv'])**2, axis=-1))\n",
    "rl2m_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowMajor_indv'])**2, axis=-1))\n",
    "rl2i_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['IndvLearning'])**2, axis=-1))\n",
    "rl2r_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['RandomCopy'])**2, axis=-1))\n",
    "m2b_dist = np.sqrt(np.sum((insp_dict['FollowBest_indv'] - insp_dict['FollowMajor_indv'])**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(np.mean(rl2b_dist[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(np.mean(rl2m_dist[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(np.mean(rl2i_dist[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(np.mean(rl2r_dist[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(np.mean(m2b_dist[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl2b_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2m_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowMajor_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2i_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['IndvLearning'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2r_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['RandomCopy'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "m2b_cos = matrix_cosine(insp_dict['FollowMajor_indv'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(1 - np.mean(rl2b_cos[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(1 - np.mean(rl2m_cos[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(1 - np.mean(rl2i_cos[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(1 - np.mean(rl2r_cos[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(1 - np.mean(m2b_cos[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def coord_triplet(s):\n",
    "    x = []  # np.zeros((int(s*(s+1)*(s+2)/6), 3))\n",
    "\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):\n",
    "            for k in range(j, s):\n",
    "                x.append([i, j, k])\n",
    "                \n",
    "                \n",
    "    return np.array(x)\n",
    "\n",
    "def fixed_point(ac):\n",
    "    data = np.array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 99, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 99, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 99, 0]]])\n",
    "\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    return np.round(x)[0].astype(np.int)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def make_cube(s, fp_dist, sp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                x[i, j, k] = [fp_dist[c], sp_dist[c], hp_dist[c]]\n",
    "                c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors(pi_list, fp, sp, hp, fp_show, sp_show, hp_show, max_s):\n",
    "    fp_dist = (np.sum((pi_list-fp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    sp_dist = (np.sum((pi_list-sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list-hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube(max_s, fp_dist, sp_dist, hp_dist)\n",
    "    if fp_show:\n",
    "        facecolors[..., 0] = 1 - mc[:, :, :, 0]   # Red : fp_dist\n",
    "    if sp_show:\n",
    "        facecolors[..., 1] = 1 - mc[:, :, :, 1]   # Red : fp_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = 1 - mc[:, :, :, 2]   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [fp_show, sp_show, hp_show]], axis=-1))**2 * 0.8 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, fp_dist, sp_dist, hp_dist\n",
    "\n",
    "def plot_cube(facecolors, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    ax.set_xlabel(r'$n_1$')\n",
    "    ax.set_ylabel(r'$n_2$')\n",
    "    ax.set_zlabel(r'$n_3 (highest)$')\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2*stride, z/2*stride, filled, facecolors=facecolors, shade=False)\n",
    "    if save:\n",
    "        plt.savefig(f'cube_{name}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "for s in range(5, 101, 5):  # 5, 10, ..., 95, 100\n",
    "    print(s)\n",
    "    max_s = 100\n",
    "    '''\n",
    "    data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "    '''\n",
    "    template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "    tc = coord_triplet(max_s)\n",
    "    data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "    data[:, :, -2] = tc\n",
    "    pi_list = []\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        pi_list.append(x)\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    fp = fixed_point(ac)\n",
    "    sp = template[0][:-2]\n",
    "    hp = template[-1][:-2]\n",
    "    facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, False, True, max_s)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    plot_cube(facecolors, stride = 5, angle=-75, name = f'complete_L200_E500_S{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "s = 40\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = fixed_point(ac)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, False, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def coord_triplet(s):\n",
    "    x = []  # np.zeros((int(s*(s+1)*(s+2)/6), 3))\n",
    "\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):\n",
    "            for k in range(j, s):\n",
    "                x.append([i, j, k])\n",
    "                \n",
    "                \n",
    "    return np.array(x)\n",
    "\n",
    "def fixed_point(ac):\n",
    "    data = np.array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 99, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 99, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 99, 0]]])\n",
    "\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    return np.round(x)[0].astype(np.int)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def make_cube(s, fp_dist, sp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                x[i, j, k] = [fp_dist[c], sp_dist[c], hp_dist[c]]\n",
    "                c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors(pi_list, fp, sp, hp, fp_show, sp_show, hp_show, max_s):\n",
    "    fp_dist = (np.sum((pi_list-fp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    sp_dist = (np.sum((pi_list-sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list-hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube(max_s, fp_dist, sp_dist, hp_dist)\n",
    "    if fp_show:\n",
    "        facecolors[..., 0] = 1 - mc[:, :, :, 0]   # Red : fp_dist\n",
    "    if sp_show:\n",
    "        facecolors[..., 1] = 1 - mc[:, :, :, 1]   # Red : fp_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = 1 - mc[:, :, :, 2]   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [fp_show, sp_show, hp_show]], axis=-1))**2 * 0.8 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, fp_dist, sp_dist, hp_dist\n",
    "\n",
    "def plot_cube(facecolors, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    ax.set_xlabel(r'$n_1$')\n",
    "    ax.set_ylabel(r'$n_2$')\n",
    "    ax.set_zlabel(r'$n_3 (highest)$')\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2*stride, z/2*stride, filled, facecolors=facecolors, shade=False)\n",
    "    if save:\n",
    "        plt.savefig(f'./result/cube_figure/cube_{name}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "for s in range(5, 101, 5):  # 5, 10, ..., 95, 100\n",
    "    print(s)\n",
    "    max_s = 100\n",
    "    '''\n",
    "    data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "    '''\n",
    "    template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "    tc = coord_triplet(max_s)\n",
    "    data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "    data[:, :, -2] = tc\n",
    "    pi_list = []\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        pi_list.append(x)\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    fp = fixed_point(ac)\n",
    "    hp = template[-1][:-2]\n",
    "    facecolors, fp_dist, hp_dist = assign_facecolors(pi_list, fp, hp, max_s)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    plot_cube(facecolors, stride = 5, angle=-75, name = str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2820\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "exp_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_pretrainFB'\n",
    "epoch = 0\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'st_complete_total_FollowBest_SI_N15K7NN3_CE_sptest'\n",
    "checkpoint = torch.load(f'./data/runs/{exp_name}/{exp_name}_s42/pyt_save/model.pth')\n",
    "checkpoint = OrderedDict((f'logits_net.{key}', value) for (key, value) in checkpoint.items())\n",
    "ac.pi.module.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "s = 40\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = fixed_point(ac)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, True, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 70\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "mod_name = '70SF'\n",
    "baseline_name = 'RL_Inspired_SLSs'\n",
    "ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT', mod_type=mod_name)\n",
    "\n",
    "%matplotlib notebook\n",
    "s = 60\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a = ac_base.step(data[i*10000:(i+1)*10000].reshape(2, -1, 4, 17))\n",
    "    x = a.reshape(-1, 15)\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = np.zeros(15)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, False, True, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "baseline_name = 'FollowBest'\n",
    "env_base = envs.__dict__[env_name](**env_kwargs)\n",
    "ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT')\n",
    "\n",
    "%matplotlib notebook\n",
    "s = 60\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a = ac_base.step(data[i*10000:(i+1)*10000].reshape(2, -1, 4, 17))\n",
    "    x = a.reshape(-1, 15)\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = np.zeros(15)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, False, True, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pi_list, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.argsort()[:, -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def coord_triplet(s):\n",
    "    x = []  # np.zeros((int(s*(s+1)*(s+2)/6), 3))\n",
    "\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):\n",
    "            for k in range(j, s):\n",
    "                x.append([i, j, k])\n",
    "                \n",
    "                \n",
    "    return np.array(x)\n",
    "\n",
    "def fixed_point(ac):\n",
    "    data = np.array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 99, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 99, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 99, 0]]])\n",
    "\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    return np.round(x)[0].astype(np.int)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def make_cube(s, fp_dist, sp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                x[i, j, k] = [fp_dist[c], sp_dist[c], hp_dist[c]]\n",
    "                c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors(pi_list, fp, sp, hp, fp_show, sp_show, hp_show, max_s):\n",
    "    fp_dist = (np.sum((pi_list-fp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    sp_dist = (np.sum((pi_list-sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list-hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube(max_s, fp_dist, sp_dist, hp_dist)\n",
    "    if fp_show:\n",
    "        facecolors[..., 0] = 1 - mc[:, :, :, 0]   # Red : fp_dist\n",
    "    if sp_show:\n",
    "        facecolors[..., 1] = 1 - mc[:, :, :, 1]   # Red : fp_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = 1 - mc[:, :, :, 2]   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [fp_show, sp_show, hp_show]], axis=-1))**2 * 0.8 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, fp_dist, sp_dist, hp_dist\n",
    "\n",
    "def plot_cube(facecolors, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    ax.set_xlabel(r'$n_1$')\n",
    "    ax.set_ylabel(r'$n_2$')\n",
    "    ax.set_zlabel(r'$n_3 (highest)$')\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2*stride, z/2*stride, filled, facecolors=facecolors, shade=False)\n",
    "    if save:\n",
    "        plt.savefig(f'./result/cube_figure/cube_{name}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "for s in range(5, 101, 5):  # 5, 10, ..., 95, 100\n",
    "    print(s)\n",
    "    max_s = 100\n",
    "    '''\n",
    "    data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "    '''\n",
    "    template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "    tc = coord_triplet(max_s)\n",
    "    data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "    data[:, :, -2] = tc\n",
    "    pi_list = []\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        pi_list.append(x)\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    fp = fixed_point(ac)\n",
    "    hp = template[-1][:-2]\n",
    "    facecolors, fp_dist, hp_dist = assign_facecolors(pi_list, fp, hp, max_s)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    plot_cube(facecolors, stride = 5, angle=-75, name = str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2820\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "exp_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_new_rand200'\n",
    "epoch = 2820\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "s = 10\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = fixed_point(ac)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, False, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 40\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pi_list, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 70\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pi_list, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_num = 1\n",
    "test_ensemble_num = 10\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")\n",
    "# score histogram\n",
    "env = env_list[0]\n",
    "plt.hist(np.array(list(env.landscape.get_all_state_values().values()))/env.landscape.get_global_max()[1], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_buf = buf_list[0].obs_buf\n",
    "score_pairs = np.round(obs_buf[:, :, :, :, -2]).reshape(-1, obs_buf.shape[-2]).astype(np.int)\n",
    "self_scores = score_pairs[:, 0].reshape(-1, 1)\n",
    "neighbor_scores = np.sort(score_pairs[:, 1:], axis=-1)\n",
    "score_pairs = np.concatenate((self_scores, neighbor_scores), axis=-1)\n",
    "score_pairs = score_pairs[np.lexsort(list(score_pairs[:, -(i+1)] for i in range(score_pairs.shape[-1])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = make_cube_dd(score_pairs, s, max_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_list[81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "h_list = np.zeros(101)\n",
    "for i in range(100):\n",
    "    h_list[i] = len(score_pairs[score_pairs[:, 0]==i])\n",
    "plt.plot(h_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cube_dd(score_pairs, s, max_s):\n",
    "    states_unique, freq_states = np.unique(score_pairs, axis=0, return_counts=True)\n",
    "    s_filter = states_unique[:, 0]==s\n",
    "    states_unique = states_unique[s_filter][:, 1:]\n",
    "    freq_states = freq_states[s_filter]\n",
    "    \n",
    "    cube = np.zeros((max_s+1, max_s+1, max_s+1)).astype(np.int)\n",
    "    for a, b in zip(states_unique, freq_states):\n",
    "        cube[a[0], a[1], a[2]] = b\n",
    "    return cube\n",
    "\n",
    "def assign_facecolors_dd(score_pairs, s, max_s):\n",
    "    \n",
    "    facecolors = np.zeros((max_s+1, max_s+1, max_s+1, 4)) # R, G, B, alpha\n",
    "    mc = make_cube_dd(score_pairs, s, max_s)\n",
    "    facecolors[..., -1] = mc / np.max(mc)\n",
    "    print(np.max(mc))\n",
    "    return facecolors, np.max(mc)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "def plot_cube_dd(facecolors, max_mc, s, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    ax.set_xlabel(r'$n_1$')\n",
    "    ax.set_ylabel(r'$n_2$')\n",
    "    ax.set_zlabel(r'$n_3 (highest)$')\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2*stride, z/2*stride, filled, facecolors=facecolors, shade=False)\n",
    "    \n",
    "    xx, yy = np.meshgrid(range(IMG_DIM*stride), range(IMG_DIM*stride))\n",
    "    z = xx * 0 + s\n",
    "    # plot the plane\n",
    "    ax.plot_surface(xx, yy, z, color = 'r', alpha=0.3)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'./result/cube_figure/data_{name}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "s = 80\n",
    "max_s = 100\n",
    "\n",
    "facecolors, max_mc= assign_facecolors_dd(score_pairs, s, max_s)\n",
    "stride = 1\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube_dd(facecolors, max_mc, s, stride=stride, angle=-75, name = str(s), save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import envs\n",
    "import ppo.core as core\n",
    "from utils.utils import DataGen\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import ppo.net as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_type = 'FollowBest'\n",
    "exp_name = 'test'\n",
    "\n",
    "batch_size = 16\n",
    "batch_num = 2\n",
    "total_size = batch_num * batch_size\n",
    "train_ratio = 0.8\n",
    "\n",
    "generator = DataGen(env, baseline_type, batch_size, batch_num)\n",
    "if not os.path.isfile('./data/' + exp_name + '_train.pkl'):\n",
    "    generator.run(exp_name, total_size, batch_size, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/' + exp_name + '_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./data/' + exp_name + '_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'complete_total_FollowBest_SIR_N10K3NN3'\n",
    "with open('./data/supervised/' + exp_name + '_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./data/supervised/' + exp_name + '_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_image = np.concatenate(train_data['Image'], axis=0)\n",
    "train_data_image = train_data_image.reshape(-1, *train_data_image.shape[-2:])\n",
    "train_data_label = np.concatenate(train_data['Label'], axis=0)\n",
    "train_data_label = train_data_label.reshape(-1, *train_data_label.shape[-1:])\n",
    "test_data_image = np.concatenate(test_data['Image'], axis=0)\n",
    "test_data_image = test_data_image.reshape(-1, *test_data_image.shape[-2:])\n",
    "test_data_label = np.concatenate(test_data['Label'], axis=0)\n",
    "test_data_label = test_data_label.reshape(-1, *test_data_label.shape[-1:])\n",
    "\n",
    "train_data = TensorDataset(torch.FloatTensor(train_data_image), torch.FloatTensor(train_data_label))\n",
    "test_data = TensorDataset(torch.FloatTensor(test_data_image), torch.FloatTensor(test_data_label))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "test_loader = DataLoader(\n",
    "            test_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.__dict__['ds']((4, 13), 20).cuda()\n",
    "exp_name = 'complete_total_FollowBest_SIR_N10K3NN3_CE_sptest'\n",
    "checkpoint = torch.load(f'./data/runs/{exp_name}/{exp_name}_s42/pyt_save/model.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape).cuda()\n",
    "    return -Variable(torch.log(-torch.log(U + eps) + eps))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature):\n",
    "    \"\"\"\n",
    "    input: [*, n_class]\n",
    "    return: [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return (y_hard - y).detach() + y\n",
    "\n",
    "import math\n",
    "print(gumbel_softmax(torch.cuda.FloatTensor([[math.log(0.1), math.log(0.4), math.log(0.3), math.log(0.2)]] * 20000), 1).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_preserving_randomization(edges):\n",
    "    '''\n",
    "    Randomizes a network provided by an edge list \n",
    "    producing neither self links nor duplicate links.\n",
    "    The degree sequence will stay the same.\n",
    "    INPUT:\n",
    "    --- edges: list or set containing node pairs (tuples or lists of two nodes)\n",
    "         \n",
    "    OUTPUT:\n",
    "    --- new_edges: new list containing new node pairs (tuples of two nodes)\n",
    "    '''\n",
    "    \n",
    "    # make new set copy from edgelist\n",
    "    edges = set( [tuple(e) for e in edges ]) \n",
    "\n",
    "    # get list of stubs\n",
    "    stubs = [ ]\n",
    "    [ stubs.extend(e) for e in edges ]\n",
    "\n",
    "    # get a Counter object that counts the stubs for every node\n",
    "    stub_counter = Counter(stubs)\n",
    "\n",
    "    # initialize the new edge list\n",
    "    new_edges = set()\n",
    "\n",
    "    # get available nodes (nodes that have nonzero stub count)\n",
    "    nodes = np.array([ stub for stub,count in stub_counter.items() if count!=0 ])\n",
    "\n",
    "    # loop till the number of available nodes is zero\n",
    "    while len(nodes)>0:\n",
    "\n",
    "        # initialize dummy values for new edge\n",
    "        first,second = -1,-1\n",
    "\n",
    "        # choose edges that are not self-links (only possible if len(nodes)>1)\n",
    "        while first == second and len(nodes)>1:\n",
    "            first,second = np.random.choice(nodes,size=(2,),replace=False)\n",
    "\n",
    "        # if the chosen (source,target) is are not the same\n",
    "        # and not yet connected \n",
    "        # and there is more than one node with available stubs\n",
    "        if first!=second and \\\n",
    "           (first,second) not in new_edges and \\\n",
    "           (second,first) not in new_edges and \\\n",
    "           len(nodes)>1:\n",
    "            new_edges.add((first,second))\n",
    "            stub_counter[first] -= 1\n",
    "            stub_counter[second] -= 1\n",
    "        else:\n",
    "            # if not, pop a random edge and put its nodes \n",
    "            # back in the stub pool\n",
    "            edge = random.sample(new_edges,1)[0]\n",
    "            new_edges.remove(edge)\n",
    "            stub_counter[edge[0]] += 1\n",
    "            stub_counter[edge[1]] += 1\n",
    "\n",
    "        # get available nodes (nodes that have nonzero stub count)\n",
    "        nodes = np.array([ stub for stub,count in stub_counter.items() if count!=0 ])\n",
    "\n",
    "        \n",
    "    return list(new_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 9\n",
    "exp = 8\n",
    "trj_len = 100\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw'\n",
    "action_type = 'total'\n",
    "extra_type = 'SI'\n",
    "env_name = 'SL_NK_' + action_type\n",
    "\n",
    "nx_dict = {'complete': nx.complete_graph, 'ba': nx.barabasi_albert_graph, 'er': nx.erdos_renyi_graph} \n",
    "nx_arg_dict = {'complete': {'n': M}, 'ba': {'n': M, 'm': 19}, 'er': {'n': M, 'p': 0.3}}\n",
    "\n",
    "env_kwargs = {\n",
    "        'E': E,\n",
    "        'M': M,\n",
    "        'N': N,\n",
    "        'K': K,\n",
    "        'neighbor_num': NN,\n",
    "        'exp': exp,\n",
    "        'graph': nx_dict[graph_type],\n",
    "        'graph_dict': nx_arg_dict[graph_type],\n",
    "        'reward_type': reward_type,\n",
    "        'action_type': action_type,\n",
    "        'extra_type': extra_type,\n",
    "    'corr_type': 'TT'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_num = 1\n",
    "test_ensemble_num = 1000\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo.core import Baseline\n",
    "class FollowMajor_indv_test(Baseline):\n",
    "    def __init__(self, env, action_type, extra_type, corr_type):\n",
    "        super().__init__(env, action_type, extra_type, corr_type)\n",
    "        print('test')\n",
    "        self.landscape = env.landscape\n",
    "        self.score_max = env.score_max\n",
    "\n",
    "    def step(self, obs):\n",
    "        with torch.no_grad():\n",
    "            states_input = obs\n",
    "            if self.action_type == 'total':\n",
    "                E = obs.shape[0]\n",
    "                M = obs.shape[1]\n",
    "                N = obs.shape[3] - self.extra_num\n",
    "                states = states_input[:, :, :, :N]\n",
    "                states_neighbor = states[:, :, 1:, :]\n",
    "                states = states[:, :, 0, :]\n",
    "                scores = np.expand_dims(states_input[:, :, 0, N], axis=-1)\n",
    "                scores_neighbor = states_input[:, :, 1:, N]\n",
    "            elif self.action_type == 'split':\n",
    "                E = obs.shape[0]\n",
    "                M = obs.shape[1]\n",
    "                N = obs.shape[2]\n",
    "                states = states_input[:, :, :, :, 0]\n",
    "                states_neighbor = states[:, :, :, 1:].transpose(0, 1, 3, 2)\n",
    "                states = states[:, :, :, 0]\n",
    "                scores = np.expand_dims(states_input[:, :, 0, 0, 1], axis=-1)\n",
    "                scores_neighbor = states_input[:, :, 0, 1:, 1]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            #states_social = np.copy(states)\n",
    "            states_social = np.zeros_like(states)\n",
    "            for i in range(E):\n",
    "                for j in range(M):\n",
    "                    states_unique, freq_states = np.unique(states_neighbor[i][j], axis=0, return_counts=True)\n",
    "                    if len(freq_states) < self.env.neighbor_num:  # At least one 'most requent' state\n",
    "                        #print(freq_states, freq_states.max(), freq_states==freq_states.max())\n",
    "                        states_most_frequent = states_unique[freq_states == freq_states.max()]\n",
    "                        \n",
    "                        if len(states_most_frequent) == 1 :  # Single 'most frequent' state\n",
    "                            states_social[i][j] = states_most_frequent[0]\n",
    "                        else:  # Multiple 'most frequent' solutions\n",
    "                            states_social[i][j] = states_most_frequent[np.random.randint(len(states_most_frequent))]\n",
    "                    else:  # No frequent state\n",
    "                        states_social[i][j] = states[i][j]\n",
    "                        #print(states[i][j])\n",
    "                        #indv_index = np.random.randint(N)\n",
    "                        #states_social[i][j] = states[i][j]\n",
    "                        #states_social[i][j][indv_index] = (states_social[i][j][indv_index] + 1) % 2\n",
    "            '''\n",
    "            scores_social = self.env.get_score(states=states_social)\n",
    "            better_social = (scores_social > scores).astype(np.long)\n",
    "            print(states_social, scores_social, better_social)\n",
    "            \n",
    "            '''\n",
    "            print(states_social.shape)\n",
    "            for e in range(test_ensemble_num):\n",
    "                print(state_social[e])\n",
    "                freq = np.unique(states_social[e], axis=0)\n",
    "                print(freq)\n",
    "\n",
    "            scores_social = self.env.get_score(states=states_social)\n",
    "            better_social = (scores_social > scores).astype(np.long)\n",
    "            \n",
    "            index_indv = np.zeros_like(states)\n",
    "            np.put_along_axis(index_indv, np.random.randint(0, N, (E, M, 1)), 1, axis=-1)\n",
    "            states_indv = (states + index_indv) % 2\n",
    "            scores_indv = self.env.get_score(states=states_indv)\n",
    "            \n",
    "            better_indv = (scores_indv > scores).astype(np.long) * (1 - better_social)  # not better social but better indv\n",
    "            \n",
    "            stay = (1 - better_social) * (1 - better_indv)\n",
    "            if self.state_correction:\n",
    "                states = (better_social * states_social) + (better_indv * states_indv) + stay * states\n",
    "            else:\n",
    "                states = states_social\n",
    "\n",
    "            if self.reward_correction:\n",
    "                scores = (scores_social * better_social) + (scores_indv * better_indv) + stay * scores\n",
    "            else:\n",
    "                scores = scores_social\n",
    "                \n",
    "            \n",
    "            #states = better_social * states_social + (1 - better_social) * states\n",
    "            #scores = better_social * scores_social + (1 - better_social) * scores\n",
    "            #print(states, scores)\n",
    "\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data['act_buf'][0][0][:, :, 0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data['unq_buf'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = {}\n",
    "baseline_data['Ret'] = []\n",
    "baseline_data['FinalScore'] = []\n",
    "baseline_data['scr_buf'] = []\n",
    "baseline_data['unq_buf'] = []\n",
    "baseline_data['act_buf'] = []\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    ac_base = FollowMajor_indv_test(env_base, action_type, extra_type, corr_type='TT')\n",
    "    scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "    unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "    act_buf = np.zeros((test_ensemble_num, M, N, trj_len), dtype=np.float32)\n",
    "\n",
    "    o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "    for t in range(2):\n",
    "        print(t)\n",
    "        a = ac_base.step(o)\n",
    "        next_o, r, s = env_base.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        scr_buf[..., t] = s\n",
    "        act_buf[..., t] = a\n",
    "        for e in range(test_ensemble_num):\n",
    "            freq = np.unique(a[e], axis=0)\n",
    "            unq_buf[e][t] = freq.shape[0]\n",
    "        o = next_o\n",
    "\n",
    "    baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "    baseline_data['FinalScore'].append(np.mean(s))\n",
    "    baseline_data['scr_buf'].append(scr_buf)\n",
    "    baseline_data['unq_buf'].append(unq_buf)\n",
    "    baseline_data['act_buf'].append(act_buf)\n",
    "baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "baseline_data['act_buf'] = np.array(baseline_data['act_buf'])\n",
    "print(\"Baseline finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = baseline_data['unq_buf']\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter])\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "counter+=1\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_base = env_list[0]\n",
    "ac_base = FollowMajor_indv_test(env_base, action_type, extra_type, corr_type='TT')\n",
    "\n",
    "o = np.array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.83, 1], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0], \n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0], \n",
    "              [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6.29, 0]]]])\n",
    "\n",
    "'''\n",
    "o = np.array([[[[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3.83, 1], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.13, 0],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.13, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 10.15, 0]]]])\n",
    "\n",
    "'''\n",
    "\n",
    "for i in range(10):\n",
    "    print(ac_base.step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils import nodes_or_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmeanclustering(n):\n",
    "    assert n%5==0\n",
    "    s = int(n/5)\n",
    "    A = 1 - np.eye(s)\n",
    "    B = np.zeros((s, s))\n",
    "    C = np.block([[A, B, B, B, B],\n",
    "                 [B, A, B, B, B],\n",
    "                 [B, B, A, B, B],\n",
    "                 [B, B, B, A, B],\n",
    "                 [B, B, B, B, A]])\n",
    "    for i in range(5):\n",
    "        j = s * i\n",
    "        C[j][j+s-1] = 0\n",
    "        C[j+s-1][j] = 0\n",
    "        C[j][j-1] = 1\n",
    "        C[j-1][j] = 1\n",
    "\n",
    "    G = nx.from_numpy_matrix(C)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T02:48:02.560846Z",
     "start_time": "2021-04-04T02:48:02.517939Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as RLRP\n",
    "from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.nn.init import xavier_normal\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch_geometric as tg\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network\n",
    "import envs\n",
    "import json\n",
    "from itertools import product\n",
    "from functools import reduce  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 200\n",
    "graph_type = 'maxmc'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SI'\n",
    "env_name = 'SL_NK_' + action_type\n",
    "\n",
    "nx_dict = {'complete': nx.complete_graph, 'ba': nx.barabasi_albert_graph, 'er': nx.erdos_renyi_graph, 'maxmc':max_mean_clustering_network} \n",
    "nx_arg_dict = {'complete': {'n': M}, 'ba': {'n': M, 'm': 19}, 'er': {'n': M, 'p': 0.3}, 'maxmc': {'n': M}}\n",
    "\n",
    "env_kwargs = {\n",
    "        'E': E,\n",
    "        'M': M,\n",
    "        'N': N,\n",
    "        'K': K,\n",
    "        'neighbor_num': NN,\n",
    "        'exp': exp,\n",
    "        'graph': nx_dict[graph_type],\n",
    "        'graph_dict': nx_arg_dict[graph_type],\n",
    "        'reward_type': reward_type,\n",
    "        'action_type': action_type,\n",
    "        'extra_type': extra_type,\n",
    "    'corr_type': 'TT'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict = {}\n",
    "baseline_data_dict['keys'] = ['Ret', 'FinalScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_num = 10\n",
    "test_ensemble_num = 50\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "#baselines = ['FollowMajor', 'FollowMajor_indv']\n",
    "for baseline_name in baselines:\n",
    "    print(f\"Baseline : {baseline_name}\")\n",
    "    baseline_data = {}\n",
    "    baseline_data['Ret'] = []\n",
    "    baseline_data['FinalScore'] = []\n",
    "    baseline_data['scr_buf'] = []\n",
    "    baseline_data['unq_buf'] = []\n",
    "    \n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        env_base = env_list[i]\n",
    "        ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT')\n",
    "        scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "        unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "        \n",
    "        o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "        for t in range(trj_len):\n",
    "            a = ac_base.step(o)\n",
    "            next_o, r, s = env_base.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "            scr_buf[..., t] = s\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "            o = next_o\n",
    "\n",
    "        baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "        baseline_data['FinalScore'].append(np.mean(s))\n",
    "        baseline_data['scr_buf'].append(scr_buf)\n",
    "        baseline_data['unq_buf'].append(unq_buf)\n",
    "    baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "    baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "    baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "    baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "    baseline_data_dict[baseline_name] = baseline_data\n",
    "    print(\"Baseline finished\")\n",
    "    \n",
    "with open('baseline_maxmc_N15K7NN3L200.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline construction initiated\n"
     ]
    }
   ],
   "source": [
    "env_num = 10\n",
    "test_ensemble_num = 100\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10SF20', '10SF40', '10SF60', '10SF80', '10SF100']\n",
      "Baseline : RL_Inspired_SLSs_10SF20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Baseline : RL_Inspired_SLSs_10SF40\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Baseline : RL_Inspired_SLSs_10SF60\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Baseline : RL_Inspired_SLSs_10SF80\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Baseline : RL_Inspired_SLSs_10SF100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Baseline finished\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(core)\n",
    "# Complete에서 볼 것 \n",
    "# S2 전략이 50에서 제일 좋다는 것\n",
    "# Max\n",
    "\n",
    "baseline_data_dict = {}\n",
    "baseline_data_dict['keys'] = ['Ret', 'FinalScore']\n",
    "\n",
    "#names_list = [['30', '50', '70'], ['E','S'], ['T', 'F'], ['', '50', '80']]\n",
    "names_list = [['10'], ['S'], ['F'], ['20', '40', '60', '80', '100']]\n",
    "name_combination = (list(product(*names_list)))\n",
    "mod_type_list = [''.join(name_combination[i]) for i in range(len(name_combination))]\n",
    "#mod_type_list = ['50SF', '30SF', '70SF', '50SF80', '50EF', '30EF', '70EF', '50EF80']\n",
    "print(mod_type_list)\n",
    "baseline_name = 'RL_Inspired_SLSs'\n",
    "\n",
    "for mod_name in mod_type_list:\n",
    "    print(f\"Baseline : {baseline_name}_{mod_name}\")\n",
    "    baseline_data = {}\n",
    "    baseline_data['Ret'] = []\n",
    "    baseline_data['FinalScore'] = []\n",
    "    baseline_data['scr_buf'] = []\n",
    "    baseline_data['unq_buf'] = []\n",
    "    \n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        env_base = env_list[i]\n",
    "        ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT', mod_type=mod_name)\n",
    "        scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "        unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "        \n",
    "        o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "        for t in range(trj_len):\n",
    "            a = ac_base.step(o)\n",
    "            next_o, r, s = env_base.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "            scr_buf[..., t] = s\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "            o = next_o\n",
    "\n",
    "        baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "        baseline_data['FinalScore'].append(np.mean(s))\n",
    "        baseline_data['scr_buf'].append(scr_buf)\n",
    "        baseline_data['unq_buf'].append(unq_buf)\n",
    "    baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "    baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "    baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "    baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "    baseline_data_dict[mod_name] = baseline_data\n",
    "    \n",
    "print(\"Baseline finished\")\n",
    "with open('baseline_maxmc_tweak1_N15K7NN3L200_RL.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(core)\n",
    "\n",
    "#names_list = [['30', '50', '70'], ['E','S'], ['T', 'F'], ['', '50', '80']]\n",
    "#names_list = [['30', '50', '70'], ['S'], ['F'], ['', '50', '80']]\n",
    "#name_combination = (list(product(*names_list)))\n",
    "#mod_type_list = [''.join(name_combination[i]) for i in range(len(name_combination))]\n",
    "mod_type_list = ['50SF80', '50SF60', '50SF', '50EF80', '50EF60', '50EF']\n",
    "print(mod_type_list)\n",
    "baseline_name = 'RL_Inspired_SLSs'\n",
    "\n",
    "for mod_name in mod_type_list:\n",
    "    print(f\"Baseline : {baseline_name}_{mod_name}\")\n",
    "    baseline_data = {}\n",
    "    baseline_data['Ret'] = []\n",
    "    baseline_data['FinalScore'] = []\n",
    "    baseline_data['scr_buf'] = []\n",
    "    baseline_data['unq_buf'] = []\n",
    "    \n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        env_base = env_list[i]\n",
    "        ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT', mod_type=mod_name)\n",
    "        scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "        unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "        \n",
    "        o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "        for t in range(trj_len):\n",
    "            a = ac_base.step(o)\n",
    "            next_o, r, s = env_base.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "            scr_buf[..., t] = s\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "            o = next_o\n",
    "\n",
    "        baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "        baseline_data['FinalScore'].append(np.mean(s))\n",
    "        baseline_data['scr_buf'].append(scr_buf)\n",
    "        baseline_data['unq_buf'].append(unq_buf)\n",
    "    baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "    baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "    baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "    baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "    baseline_data_dict[mod_name] = baseline_data\n",
    "    \n",
    "print(\"Baseline finished\")\n",
    "with open('baseline_maxmc_N15K7NN3L200_RL.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in baseline_data_dict.keys():\n",
    "    if key != 'keys':\n",
    "        print(key)\n",
    "        print(baseline_data_dict[key]['Ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/baseline_data/baseline_maxmc_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data_dict2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline_maxmc_N15K7NN3L200_RL.pkl', 'rb') as f:\n",
    "    baseline_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing (RL_Inspired_SLSs)\n",
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "for baseline_name in baselines:\n",
    "    x = baseline_data_dict2[baseline_name]['scr_buf']\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "        \n",
    "#names_list = [['30', '50', '70'], ['E','S'], ['T', 'F'], ['', '50', '80']]\n",
    "names_list = [['50', '70'], ['S'], ['T', 'F'], ['50', '80']]\n",
    "\n",
    "name_combination = (list(product(*names_list)))\n",
    "mod_type_list = [''.join(name_combination[i]) for i in range(len(name_combination))]\n",
    "mod_type_list = ['50SF80', '50SF60', '50SF']\n",
    "#mod_type_list = ['45ST2', '20ST2', '70ST2', '45ST1']\n",
    "baseline_name = 'RL_Inspired_SLSs'   \n",
    "\n",
    "for i, mod_name in enumerate(mod_type_list):\n",
    "    x = baseline_data_dict[mod_name]['scr_buf'][..., :200]\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    #ls = '-' if i<4 else '--'\n",
    "    ls = '--'\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, label=mod_name, ls=ls)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor='black', alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend(loc=4, fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline_complete_N15K7NN9.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/baseline_data/baseline_maxmc_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/baseline_data/baseline_maxmc_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data['FollowMajor_indv']['unq_buf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline_complete_N15K7NN3_new.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan']\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf'][:20, :20]\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_name, epoch):\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = nx.complete_graph\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2820\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "exp_name = 'st_maxmc_indv_raw_full_total_random_SI_TT_N15K7NN3_new_rand200'\n",
    "epoch = 3761\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buf_list = []\n",
    "final_score_list = []\n",
    "unq_buf_list = []\n",
    "prob_buf_list = []\n",
    "Ret_list = []\n",
    "env_num = 10\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    test_ensemble_num = 10\n",
    "    buf = PPOBuffer(\n",
    "        obs_dim, \n",
    "        act_dim, \n",
    "        test_ensemble_num, \n",
    "        env_kwargs['M'], \n",
    "        dim_len, \n",
    "        trj_len, \n",
    "        gamma, \n",
    "        lam, \n",
    "        split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "    unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "    prob_buf = []\n",
    "    \n",
    "    env = env_list[i]\n",
    "    o, _ = env.reset(test_ensemble_num) \n",
    "    ep_ret, ep_len = 0, 0\n",
    "    best_ep_ret = -np.inf\n",
    "    env.scores.flatten().max()\n",
    "    \n",
    "    for t in range(trj_len):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "        \n",
    "        next_o, r, s = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        #print(np.mean(r), np.mean(s))\n",
    "        # save and log\n",
    "        buf.store(o, a, r, v, s, logp)\n",
    "\n",
    "        # Update obs (critical!)\n",
    "        o = next_o\n",
    "        epoch_ended = t == trj_len - 1\n",
    "        for e in range(test_ensemble_num):\n",
    "            freq = np.unique(a[e], axis=0)\n",
    "            unq_buf[e][t] = freq.shape[0]\n",
    "        \n",
    "        if epoch_ended:\n",
    "            a, v, logp, pi = ac.step(\n",
    "                torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                return_pi=True\n",
    "            )\n",
    "            _, _, s = env.step(a)\n",
    "            buf.finish_path(v)\n",
    "            prob_buf.append(pi.probs[..., 1].detach().cpu().numpy())\n",
    "            for e in range(test_ensemble_num):\n",
    "                freq = np.unique(a[e], axis=0)\n",
    "                unq_buf[e][t] = freq.shape[0]\n",
    "    \n",
    "    unq_buf_list.append(unq_buf)\n",
    "    prob_buf_list.append(prob_buf)\n",
    "    Ret=ep_ret / ep_len\n",
    "    Ret_list.append(Ret)\n",
    "    EpLen=ep_len\n",
    "    FinalScore=np.mean(s)\n",
    "    buf_list.append(buf)\n",
    "    final_score_list.append(FinalScore)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "\n",
    "unq_buf_list = np.array(unq_buf_list)\n",
    "prob_buf_list = np.array(prob_buf_list)\n",
    "Ret_list = np.array(Ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_dict = {'buf_list': buf_list, 'unq_buf_list': unq_buf_list, 'prob_buf_list': prob_buf_list}\n",
    "with open('./result/inspection_dict/buf_list_maxmc_N15K7NN3L200.pkl', 'wb') as f:\n",
    "    pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/inspection_dict/buf_list_maxmc_N15K7NN3L200.pkl', 'rb') as f:\n",
    "    inspection_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_list = inspection_dict['buf_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_scr_list = []\n",
    "for i in range(len(buf_list)):\n",
    "    buf_scr_list.append(buf_list[i].scr_buf)\n",
    "buf_scr_list = np.array(buf_scr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = buf_scr_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(buf_list[0].act_buf[0][:, 14, :]) # ensemble / agent / traj_len / N+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(buf_list[0].obs_buf[0][:, 14, 0, :-2]) # ensemble / agent / traj_len / neighbor+1 / N+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    ax.plot(buf_list[0].scr_buf[0][i])\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/baseline_data/baseline_maxmc_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_list[0].act_buf[0][2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'RandomCopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(2,2), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan']\n",
    "counter=0\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "x = buf_scr_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='k', lw=3, label='RL_TT')\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend(fontsize=4, loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = unq_buf_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='black', lw=3, label='RL_TT')\n",
    "\n",
    "x = baseline_data['FollowMajor_indv']['unq_buf']\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='FollowMajor_indv')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "counter+=1\n",
    "\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = buf_scr_list\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='black', lw=3, label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "\n",
    "\n",
    "if baselines:\n",
    "    for baseline_name in baselines:\n",
    "        x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "        avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "        ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "        #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend(fontsize=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def inspect(i=widgets.IntSlider(min=0, max=env_num-1, step=1, value=0, description='Environment: '), \n",
    "            j=widgets.IntSlider(min=0, max=ensemble_num-1, step=1, value=0, description='Ensemble: '),\n",
    "            k=widgets.IntSlider(min=0, max=agent_num-1, step=1, value=0, description='Agent: '),\n",
    "            t=widgets.IntSlider(min=0, max=trj_len-1, step=1, value=0, description='Time:'),\n",
    "           ):\n",
    "    fig = plt.figure(figsize = (12, 4), dpi=200, constrained_layout=True)\n",
    "    widths = [0.5, 0.2, 0.2, 0.2]\n",
    "    heights = [3, 1]\n",
    "    gs = fig.add_gridspec(nrows=2, ncols=4, width_ratios=widths, height_ratios=heights)\n",
    "\n",
    "    ax00 = fig.add_subplot(gs[0, 0])\n",
    "    indv_scr_data = buf_list[i].scr_buf[j][k]\n",
    "    ax00.plot(indv_scr_data, c='k')\n",
    "    ax00.plot(t, indv_scr_data[t], marker='o', ms=5, c='r')\n",
    "    ax00.set_ylim(0, 100)\n",
    "\n",
    "    ax01 = fig.add_subplot(gs[0, 1])\n",
    "    prob_data = prob_buf_list[i][t, j, :]\n",
    "    ax01.imshow(prob_data, cmap=cm.binary, aspect=0.3)\n",
    "    ax01.set_title('Prob.')\n",
    "\n",
    "    ax02 = fig.add_subplot(gs[0, 2])\n",
    "    act_data = buf_list[i].act_buf[j,:, t]\n",
    "    ax02.imshow(act_data, cmap=cm.binary, aspect=0.3)\n",
    "    ax02.set_title('Action')\n",
    "\n",
    "    ax03 = fig.add_subplot(gs[0, 3])\n",
    "    next_state_data = buf_list[i].obs_buf[j,:, t+1, 0, :-2]\n",
    "    ax03.imshow(next_state_data, cmap=cm.binary, aspect=0.3)\n",
    "    next_state_score = env_list[0].get_score(next_state_data.reshape(1, agent_num, env_kwargs['N']))\n",
    "    ax03.set_title(f'State (max : {np.max(next_state_score):.2f}, {np.argmax(next_state_score)}))')\n",
    "    ax00.plot(buf_list[i].scr_buf[j][np.argmax(next_state_score)], c='r', alpha=0.5)\n",
    "\n",
    "    ax10 = fig.add_subplot(gs[1, 0])\n",
    "    indv_obs_data = buf_list[i].obs_buf[j, k, t, :, :-2]\n",
    "    indv_obs_score = env_list[0].get_score(indv_obs_data.reshape(1, env_kwargs['neighbor_num']+1, env_kwargs['N'])).squeeze()\n",
    "    ax10.imshow(indv_obs_data, cmap=cm.binary)\n",
    "    ax10.set_title(f'Obs. (T={t}, Agent No.{k})')\n",
    "    #ax10.set_xticks([])\n",
    "    #ax10.set_yticks([])\n",
    "\n",
    "    ax10.annotate(\"score\", (15, -0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[0], (15, 0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[1], (15, 1.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[2], (15, 2.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[3], (15, 3.5), fontsize=10, annotation_clip=False)\n",
    "\n",
    "    ax11 = fig.add_subplot(gs[1, 1])\n",
    "    prob_data = prob_buf_list[i][t, j, k].reshape(1, -1)\n",
    "    ax11.imshow(prob_data, cmap=cm.binary)\n",
    "    ax11.set_title('Prob.')\n",
    "    ax11.set_xticks([])\n",
    "    ax11.set_yticks([])\n",
    "\n",
    "    ax12 = fig.add_subplot(gs[1, 2])\n",
    "    act_data = buf_list[i].act_buf[j, k, t].reshape(1, -1)\n",
    "    ax12.imshow(act_data, cmap=cm.binary)\n",
    "    action_score = env_list[0].get_score(act_data.reshape(1, 1, -1)).item()\n",
    "    ax12.annotate(\"%0.2f\" % action_score, (5, 2), fontsize=10, annotation_clip=False)\n",
    "    ax12.set_title('Action')\n",
    "    ax12.set_xticks([])\n",
    "    ax12.set_yticks([])\n",
    "\n",
    "    ax13 = fig.add_subplot(gs[1, 3])\n",
    "    next_state_data = buf_list[i].obs_buf[j,k, t+1, 0, :-2].reshape(1, -1)\n",
    "    ax13.imshow(next_state_data, cmap=cm.binary)\n",
    "    next_state_score = env_list[0].get_score(next_state_data.reshape(1, 1, -1)).item()\n",
    "    ax13.annotate(\"%0.2f\" % next_state_score, (5, 2), fontsize=10, annotation_clip=False)\n",
    "    ax13.set_title(f'State (T={t+1})')\n",
    "    ax13.set_xticks([])\n",
    "    ax13.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def operation(s1=widgets.IntSlider(min=0, max=100, step=1, value=15, description='Score_1:'), \n",
    "            s2=widgets.IntSlider(min=0, max=100, step=1, value=10, description='Score_2:'),\n",
    "            s3=widgets.IntSlider(min=0, max=100, step=1, value=5, description='Score_3:'),\n",
    "            s4=widgets.IntSlider(min=0, max=100, step=1, value=20, description='Score_4:')\n",
    "             ):\n",
    "    fig = plt.figure(figsize = (12, 4), dpi=200, constrained_layout=True)\n",
    "    widths = [0.5, 0.2, 0.2, 0.2]\n",
    "    heights = [1]\n",
    "    gs = fig.add_gridspec(nrows=1, ncols=4, width_ratios=widths, height_ratios=heights)\n",
    "\n",
    "    ax10 = fig.add_subplot(gs[0])\n",
    "    \n",
    "    #'''\n",
    "    indv_obs_data = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, s1, 1], \n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, s2, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s3, 0],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_data = np.array([[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s1, 1], \n",
    "              [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s2, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s3, 0],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_score = [s1, s2, s3, s4]\n",
    "    ax10.imshow(indv_obs_data[..., :-2], cmap=cm.binary)\n",
    "    ax10.set_title(f'Observation')\n",
    "    #ax10.set_xticks([])\n",
    "    #ax10.set_yticks([])\n",
    "\n",
    "    ax10.annotate(\"score\", (15, -0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[0], (15, 0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[1], (15, 1.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[2], (15, 2.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[3], (15, 3.5), fontsize=10, annotation_clip=False)\n",
    "\n",
    "    ax11 = fig.add_subplot(gs[1])\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(indv_obs_data, dtype=torch.float32, device='cuda').unsqueeze(0), pi=True)\n",
    "    prob_data = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    ax11.imshow(prob_data, cmap=cm.binary, vmin=0, vmax=1)\n",
    "    ax11.set_title('Prob.')\n",
    "    ax11.set_xticks([])\n",
    "    ax11.set_yticks([])\n",
    "\n",
    "    ax12 = fig.add_subplot(gs[2])\n",
    "    act_data = a\n",
    "    ax12.imshow(act_data, cmap=cm.binary)\n",
    "    action_score = env_list[0].get_score(act_data.reshape(1, 1, -1)).item()\n",
    "    ax12.set_title('Action')\n",
    "    ax12.set_xticks([])\n",
    "    ax12.set_yticks([])\n",
    "\n",
    "# 1등 점수, 2등과 3등 점수의 합 (대충?), 2등과 1등의 점수 차가 영향을 미침\n",
    "# 내 점수가 20 이상인데 다른 개체들과의 차이가 심하면 (최저 -10?) 메이저 베낌\n",
    "# 자기보다 다들 높으면 확실히 best로 가려고 함 (2등과 1등 점수차가 상대적으로 작아도)\n",
    "# 반대로 2, 3등이 고만고만하면 1등과의 점수차가 압도적이어야 바꿈\n",
    "# 자기 점수가 높을 수록 2등, 3등 점수와 1등 점수차도 더 벌어짐 (+상수보다는 선형?)\n",
    "# 자기가 꼴찌가 아니면 전략 안 바꿈! (하지만 극단적으로 높은 점수는 가끔 받음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def test1(s1=widgets.IntSlider(min=0, max=100, step=1, value=15, description='Score_1:'), \n",
    "            s2=widgets.IntSlider(min=0, max=100, step=1, value=10, description='Score_2:'),\n",
    "            s3=widgets.IntSlider(min=0, max=100, step=1, value=5, description='Score_3:'),\n",
    "            s4=widgets.IntSlider(min=0, max=100, step=1, value=20, description='Score_4:')\n",
    "             ):\n",
    "    %matplotlib inline\n",
    "    fig = plt.figure(figsize = (12, 4), dpi=200, constrained_layout=True)\n",
    "    widths = [0.5, 0.2, 0.2, 0.2]\n",
    "    heights = [1]\n",
    "    gs = fig.add_gridspec(nrows=1, ncols=4, width_ratios=widths, height_ratios=heights)\n",
    "\n",
    "    ax10 = fig.add_subplot(gs[0])\n",
    "    \n",
    "    #'''\n",
    "    indv_obs_data = np.array([\n",
    "                  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, s1, 1],\n",
    "                [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, s2, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, s3, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_data = np.array([[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s1, 1], \n",
    "              [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s2, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, s3, 0],\n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, s4, 0]])\n",
    "    '''\n",
    "    indv_obs_score = [s1, s2, s3, s4]\n",
    "    ax10.imshow(indv_obs_data[..., :-2], cmap=cm.binary)\n",
    "    ax10.set_title(f'Observation')\n",
    "    #ax10.set_xticks([])\n",
    "    #ax10.set_yticks([])\n",
    "\n",
    "    ax10.annotate(\"score\", (15, -0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[0], (15, 0.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[1], (15, 1.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[2], (15, 2.5), fontsize=10, annotation_clip=False)\n",
    "    ax10.annotate(\"%0.2f\" % indv_obs_score[3], (15, 3.5), fontsize=10, annotation_clip=False)\n",
    "\n",
    "    ax11 = fig.add_subplot(gs[1])\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(indv_obs_data, dtype=torch.float32, device='cuda').unsqueeze(0), return_pi=True)\n",
    "    prob_data = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    ax11.imshow(prob_data, cmap=cm.binary, vmin=0, vmax=1)\n",
    "    ax11.set_title('Prob.')\n",
    "    ax11.set_xticks([])\n",
    "    ax11.set_yticks([])\n",
    "\n",
    "    ax12 = fig.add_subplot(gs[2])\n",
    "    act_data = a\n",
    "    ax12.imshow(act_data, cmap=cm.binary)\n",
    "    #action_score = env_list[0].get_score(act_data.reshape(1, 1, -1)).item()\n",
    "    ax12.set_title('Action')\n",
    "    ax12.set_xticks([])\n",
    "    ax12.set_yticks([])\n",
    "\n",
    "# 1등 점수, 2등과 3등 점수의 합 (대충?), 2등과 1등의 점수 차가 영향을 미침\n",
    "# 내 점수가 20 이상인데 다른 개체들과의 차이가 심하면 (최저 -10?) 메이저 베낌\n",
    "# 자기보다 다들 높으면 확실히 best로 가려고 함 (2등과 1등 점수차가 상대적으로 작아도)\n",
    "# 반대로 2, 3등이 고만고만하면 1등과의 점수차가 압도적이어야 바꿈\n",
    "# 자기 점수가 높을 수록 2등, 3등 점수와 1등 점수차도 더 벌어짐 (+상수보다는 선형?)\n",
    "# 자기가 꼴찌가 아니면 전략 안 바꿈! (하지만 극단적으로 높은 점수는 가끔 받음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(inspection, buf_list=fixed(buf_list), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "if baselines:\n",
    "    baseline_name = 'FollowMajor_indv'\n",
    "    x = baseline_data[baseline_name]['scr_buf'][:20, :20]\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Performance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action\n",
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "insp_dict = {}\n",
    "insp_dict['RL'] = [[] for i in range(env_num)]\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = [[] for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    for j in range(trj_len):\n",
    "        o = buf_list[i].obs_buf[:, :, j]\n",
    "        insp_dict['RL'][i].append((ac.pi.module._distribution(torch.as_tensor(o, dtype=torch.float32, device='cuda')).probs[..., 1]).detach().cpu().numpy())\n",
    "        for baseline_name in baselines:\n",
    "            insp_dict[baseline_name][i].append(core.__dict__[baseline_name](env_base, action_type, extra_type).step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(buf_list[0].obs_buf[0][:, 50, 0, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(buf_list[0].act_buf[0][70, :, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_dict['RL'] = np.array(insp_dict['RL'])\n",
    "insp_dict['RL_flatten'] = (insp_dict['RL']>=0.5).astype(np.long)\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = np.array(insp_dict[baseline_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist\n",
    "\n",
    "rl2b_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowBest_indv'])**2, axis=-1))\n",
    "rl2m_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowMajor_indv'])**2, axis=-1))\n",
    "rl2i_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['IndvLearning'])**2, axis=-1))\n",
    "rl2r_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['RandomCopy'])**2, axis=-1))\n",
    "m2b_dist = np.sqrt(np.sum((insp_dict['FollowBest_indv'] - insp_dict['FollowMajor_indv'])**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(np.mean(rl2b_dist[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(np.mean(rl2m_dist[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(np.mean(rl2i_dist[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(np.mean(rl2r_dist[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(np.mean(m2b_dist[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_cosine(x, y):\n",
    "    return np.einsum('ij,ij->i', x, y) / (\n",
    "              np.linalg.norm(x, axis=1) * np.linalg.norm(y, axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl2b_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2m_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowMajor_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2i_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['IndvLearning'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2r_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['RandomCopy'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "m2b_cos = matrix_cosine(insp_dict['FollowMajor_indv'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(1 - np.mean(rl2b_cos[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(1 - np.mean(rl2m_cos[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(1 - np.mean(rl2i_cos[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(1 - np.mean(rl2r_cos[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(1 - np.mean(m2b_cos[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "insp_dict = {}\n",
    "insp_dict['RL'] = [[] for i in range(env_num)]\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = [[] for i in range(env_num)]\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    for j in range(trj_len):\n",
    "        o = buf_list[i].obs_buf[:, :, j]\n",
    "        a, v, logp = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'))\n",
    "        next_o, r, s = env_base.step(a)\n",
    "        insp_dict['RL'][i].append(next_o[:, :, 0, :-2])\n",
    "        for baseline_name in baselines:\n",
    "            insp_dict[baseline_name][i].append(core.__dict__[baseline_name](env_base, action_type, extra_type).step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_dict['RL'] = np.array(insp_dict['RL'])\n",
    "insp_dict['RL_flatten'] = (insp_dict['RL']>=0.5).astype(np.long)\n",
    "for baseline_name in baselines:\n",
    "    insp_dict[baseline_name] = np.array(insp_dict[baseline_name])\n",
    "# dist\n",
    "\n",
    "rl2b_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowBest_indv'])**2, axis=-1))\n",
    "rl2m_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['FollowMajor_indv'])**2, axis=-1))\n",
    "rl2i_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['IndvLearning'])**2, axis=-1))\n",
    "rl2r_dist = np.sqrt(np.sum((insp_dict['RL_flatten'] - insp_dict['RandomCopy'])**2, axis=-1))\n",
    "m2b_dist = np.sqrt(np.sum((insp_dict['FollowBest_indv'] - insp_dict['FollowMajor_indv'])**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(np.mean(rl2b_dist[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(np.mean(rl2m_dist[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(np.mean(rl2i_dist[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(np.mean(rl2r_dist[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(np.mean(m2b_dist[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl2b_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2m_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['FollowMajor_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2i_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['IndvLearning'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "rl2r_cos = matrix_cosine(insp_dict['RL'].reshape(-1, 15), insp_dict['RandomCopy'].reshape(-1, 15)).reshape(5, 100, 5, 100)\n",
    "m2b_cos = matrix_cosine(insp_dict['FollowMajor_indv'].reshape(-1, 15), insp_dict['FollowBest_indv'].reshape(-1, 15)).reshape(5, 100, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "i=4\n",
    "ax.plot(1 - np.mean(rl2b_cos[i], axis=(1, 2)), label = 'rl2b')\n",
    "ax.plot(1 - np.mean(rl2m_cos[i], axis=(1, 2)), label = 'rl2m')\n",
    "ax.plot(1 - np.mean(rl2i_cos[i], axis=(1, 2)), label = 'rl2i')\n",
    "ax.plot(1 - np.mean(rl2r_cos[i], axis=(1, 2)), label = 'rl2r')\n",
    "ax.plot(1 - np.mean(m2b_cos[i], axis=(1, 2)), label = 'm2b')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def coord_triplet(s):\n",
    "    x = []  # np.zeros((int(s*(s+1)*(s+2)/6), 3))\n",
    "\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):\n",
    "            for k in range(j, s):\n",
    "                x.append([i, j, k])\n",
    "                \n",
    "                \n",
    "    return np.array(x)\n",
    "\n",
    "def fixed_point(ac):\n",
    "    data = np.array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 99, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 99, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 99, 0]]])\n",
    "\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    return np.round(x)[0].astype(np.int)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def make_cube(s, fp_dist, sp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                x[i, j, k] = [fp_dist[c], sp_dist[c], hp_dist[c]]\n",
    "                c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors(pi_list, fp, sp, hp, fp_show, sp_show, hp_show, max_s):\n",
    "    fp_dist = (np.sum((pi_list-fp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    sp_dist = (np.sum((pi_list-sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list-hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube(max_s, fp_dist, sp_dist, hp_dist)\n",
    "    if fp_show:\n",
    "        facecolors[..., 0] = 1 - mc[:, :, :, 0]   # Red : fp_dist\n",
    "    if sp_show:\n",
    "        facecolors[..., 1] = 1 - mc[:, :, :, 1]   # Red : fp_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = 1 - mc[:, :, :, 2]   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [fp_show, sp_show, hp_show]], axis=-1))**2 * 0.8 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, fp_dist, sp_dist, hp_dist\n",
    "\n",
    "def plot_cube(facecolors, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    ax.set_xlabel(r'$n_1$')\n",
    "    ax.set_ylabel(r'$n_2$')\n",
    "    ax.set_zlabel(r'$n_3 (highest)$')\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2*stride, z/2*stride, filled, facecolors=facecolors, shade=False)\n",
    "    if save:\n",
    "        plt.savefig(f'./result/cube_figure/cube_{name}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "for s in range(5, 101, 5):  # 5, 10, ..., 95, 100\n",
    "    print(s)\n",
    "    max_s = 100\n",
    "    '''\n",
    "    data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "    '''\n",
    "    template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "    tc = coord_triplet(max_s)\n",
    "    data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "    data[:, :, -2] = tc\n",
    "    pi_list = []\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        pi_list.append(x)\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    fp = fixed_point(ac)\n",
    "    hp = template[-1][:-2]\n",
    "    facecolors, fp_dist, hp_dist = assign_facecolors(pi_list, fp, hp, max_s)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    plot_cube(facecolors, stride = 5, angle=-75, name = f'maxmc_L200_E3761_S{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2820\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "exp_name = 'st_maxmc_indv_raw_full_total_random_SI_TT_N15K7NN3_new_rand200'\n",
    "epoch = 3761\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "s = 20\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = fixed_point(ac)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, False, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 70\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "mod_name = '50SF80'\n",
    "baseline_name = 'RL_Inspired_SLSs'\n",
    "ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT', mod_type=mod_name)\n",
    "\n",
    "%matplotlib notebook\n",
    "s = 60\n",
    "max_s = 100\n",
    "'''\n",
    "data = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, -1, 0],\n",
    "                [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0]])\n",
    "'''\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "              [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc] \n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a = ac_base.step(data[i*10000:(i+1)*10000].reshape(2, -1, 4, 17))\n",
    "    x = a.reshape(-1, 15)\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = np.zeros(15)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, False, True, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "plot_cube(facecolors, stride = 5, angle=-75, name = str(s), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pi_list, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import envs\n",
    "import ppo.core as core\n",
    "from utils.utils import DataGen\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import ppo.net as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_type = 'FollowBest'\n",
    "exp_name = 'test'\n",
    "\n",
    "batch_size = 16\n",
    "batch_num = 2\n",
    "total_size = batch_num * batch_size\n",
    "train_ratio = 0.8\n",
    "\n",
    "generator = DataGen(env, baseline_type, batch_size, batch_num)\n",
    "if not os.path.isfile('./data/' + exp_name + '_train.pkl'):\n",
    "    generator.run(exp_name, total_size, batch_size, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/' + exp_name + '_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./data/' + exp_name + '_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'complete_total_FollowBest_SIR_N10K3NN3'\n",
    "with open('./data/supervised/' + exp_name + '_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./data/supervised/' + exp_name + '_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_image = np.concatenate(train_data['Image'], axis=0)\n",
    "train_data_image = train_data_image.reshape(-1, *train_data_image.shape[-2:])\n",
    "train_data_label = np.concatenate(train_data['Label'], axis=0)\n",
    "train_data_label = train_data_label.reshape(-1, *train_data_label.shape[-1:])\n",
    "test_data_image = np.concatenate(test_data['Image'], axis=0)\n",
    "test_data_image = test_data_image.reshape(-1, *test_data_image.shape[-2:])\n",
    "test_data_label = np.concatenate(test_data['Label'], axis=0)\n",
    "test_data_label = test_data_label.reshape(-1, *test_data_label.shape[-1:])\n",
    "\n",
    "train_data = TensorDataset(torch.FloatTensor(train_data_image), torch.FloatTensor(train_data_label))\n",
    "test_data = TensorDataset(torch.FloatTensor(test_data_image), torch.FloatTensor(test_data_label))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "test_loader = DataLoader(\n",
    "            test_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.__dict__['ds']((4, 13), 20).cuda()\n",
    "exp_name = 'complete_total_FollowBest_SIR_N10K3NN3_CE_sptest'\n",
    "checkpoint = torch.load(f'./data/runs/{exp_name}/{exp_name}_s42/pyt_save/model.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape).cuda()\n",
    "    return -Variable(torch.log(-torch.log(U + eps) + eps))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature):\n",
    "    \"\"\"\n",
    "    input: [*, n_class]\n",
    "    return: [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return (y_hard - y).detach() + y\n",
    "\n",
    "import math\n",
    "print(gumbel_softmax(torch.cuda.FloatTensor([[math.log(0.1), math.log(0.4), math.log(0.3), math.log(0.2)]] * 20000), 1).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_preserving_randomization(edges):\n",
    "    '''\n",
    "    Randomizes a network provided by an edge list \n",
    "    producing neither self links nor duplicate links.\n",
    "    The degree sequence will stay the same.\n",
    "    INPUT:\n",
    "    --- edges: list or set containing node pairs (tuples or lists of two nodes)\n",
    "         \n",
    "    OUTPUT:\n",
    "    --- new_edges: new list containing new node pairs (tuples of two nodes)\n",
    "    '''\n",
    "    \n",
    "    # make new set copy from edgelist\n",
    "    edges = set( [tuple(e) for e in edges ]) \n",
    "\n",
    "    # get list of stubs\n",
    "    stubs = [ ]\n",
    "    [ stubs.extend(e) for e in edges ]\n",
    "\n",
    "    # get a Counter object that counts the stubs for every node\n",
    "    stub_counter = Counter(stubs)\n",
    "\n",
    "    # initialize the new edge list\n",
    "    new_edges = set()\n",
    "\n",
    "    # get available nodes (nodes that have nonzero stub count)\n",
    "    nodes = np.array([ stub for stub,count in stub_counter.items() if count!=0 ])\n",
    "\n",
    "    # loop till the number of available nodes is zero\n",
    "    while len(nodes)>0:\n",
    "\n",
    "        # initialize dummy values for new edge\n",
    "        first,second = -1,-1\n",
    "\n",
    "        # choose edges that are not self-links (only possible if len(nodes)>1)\n",
    "        while first == second and len(nodes)>1:\n",
    "            first,second = np.random.choice(nodes,size=(2,),replace=False)\n",
    "\n",
    "        # if the chosen (source,target) is are not the same\n",
    "        # and not yet connected \n",
    "        # and there is more than one node with available stubs\n",
    "        if first!=second and \\\n",
    "           (first,second) not in new_edges and \\\n",
    "           (second,first) not in new_edges and \\\n",
    "           len(nodes)>1:\n",
    "            new_edges.add((first,second))\n",
    "            stub_counter[first] -= 1\n",
    "            stub_counter[second] -= 1\n",
    "        else:\n",
    "            # if not, pop a random edge and put its nodes \n",
    "            # back in the stub pool\n",
    "            edge = random.sample(new_edges,1)[0]\n",
    "            new_edges.remove(edge)\n",
    "            stub_counter[edge[0]] += 1\n",
    "            stub_counter[edge[1]] += 1\n",
    "\n",
    "        # get available nodes (nodes that have nonzero stub count)\n",
    "        nodes = np.array([ stub for stub,count in stub_counter.items() if count!=0 ])\n",
    "\n",
    "        \n",
    "    return list(new_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 9\n",
    "exp = 8\n",
    "trj_len = 100\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw'\n",
    "action_type = 'total'\n",
    "extra_type = 'SI'\n",
    "env_name = 'SL_NK_' + action_type\n",
    "\n",
    "nx_dict = {'complete': nx.complete_graph, 'ba': nx.barabasi_albert_graph, 'er': nx.erdos_renyi_graph} \n",
    "nx_arg_dict = {'complete': {'n': M}, 'ba': {'n': M, 'm': 19}, 'er': {'n': M, 'p': 0.3}}\n",
    "\n",
    "env_kwargs = {\n",
    "        'E': E,\n",
    "        'M': M,\n",
    "        'N': N,\n",
    "        'K': K,\n",
    "        'neighbor_num': NN,\n",
    "        'exp': exp,\n",
    "        'graph': nx_dict[graph_type],\n",
    "        'graph_dict': nx_arg_dict[graph_type],\n",
    "        'reward_type': reward_type,\n",
    "        'action_type': action_type,\n",
    "        'extra_type': extra_type,\n",
    "    'corr_type': 'TT'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_num = 1\n",
    "test_ensemble_num = 1000\n",
    "env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "state_list = []\n",
    "for i in range(env_num):\n",
    "    _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "    state_list.append(deepcopy(fixed_state))\n",
    "print(\"Baseline construction initiated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo.core import Baseline\n",
    "class FollowMajor_indv_test(Baseline):\n",
    "    def __init__(self, env, action_type, extra_type, corr_type):\n",
    "        super().__init__(env, action_type, extra_type, corr_type)\n",
    "        print('test')\n",
    "        self.landscape = env.landscape\n",
    "        self.score_max = env.score_max\n",
    "\n",
    "    def step(self, obs):\n",
    "        with torch.no_grad():\n",
    "            states_input = obs\n",
    "            if self.action_type == 'total':\n",
    "                E = obs.shape[0]\n",
    "                M = obs.shape[1]\n",
    "                N = obs.shape[3] - self.extra_num\n",
    "                states = states_input[:, :, :, :N]\n",
    "                states_neighbor = states[:, :, 1:, :]\n",
    "                states = states[:, :, 0, :]\n",
    "                scores = np.expand_dims(states_input[:, :, 0, N], axis=-1)\n",
    "                scores_neighbor = states_input[:, :, 1:, N]\n",
    "            elif self.action_type == 'split':\n",
    "                E = obs.shape[0]\n",
    "                M = obs.shape[1]\n",
    "                N = obs.shape[2]\n",
    "                states = states_input[:, :, :, :, 0]\n",
    "                states_neighbor = states[:, :, :, 1:].transpose(0, 1, 3, 2)\n",
    "                states = states[:, :, :, 0]\n",
    "                scores = np.expand_dims(states_input[:, :, 0, 0, 1], axis=-1)\n",
    "                scores_neighbor = states_input[:, :, 0, 1:, 1]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            #states_social = np.copy(states)\n",
    "            states_social = np.zeros_like(states)\n",
    "            for i in range(E):\n",
    "                for j in range(M):\n",
    "                    states_unique, freq_states = np.unique(states_neighbor[i][j], axis=0, return_counts=True)\n",
    "                    if len(freq_states) < self.env.neighbor_num:  # At least one 'most requent' state\n",
    "                        #print(freq_states, freq_states.max(), freq_states==freq_states.max())\n",
    "                        states_most_frequent = states_unique[freq_states == freq_states.max()]\n",
    "                        \n",
    "                        if len(states_most_frequent) == 1 :  # Single 'most frequent' state\n",
    "                            states_social[i][j] = states_most_frequent[0]\n",
    "                        else:  # Multiple 'most frequent' solutions\n",
    "                            states_social[i][j] = states_most_frequent[np.random.randint(len(states_most_frequent))]\n",
    "                    else:  # No frequent state\n",
    "                        states_social[i][j] = states[i][j]\n",
    "                        #print(states[i][j])\n",
    "                        #indv_index = np.random.randint(N)\n",
    "                        #states_social[i][j] = states[i][j]\n",
    "                        #states_social[i][j][indv_index] = (states_social[i][j][indv_index] + 1) % 2\n",
    "            '''\n",
    "            scores_social = self.env.get_score(states=states_social)\n",
    "            better_social = (scores_social > scores).astype(np.long)\n",
    "            print(states_social, scores_social, better_social)\n",
    "            \n",
    "            '''\n",
    "            print(states_social.shape)\n",
    "            for e in range(test_ensemble_num):\n",
    "                print(state_social[e])\n",
    "                freq = np.unique(states_social[e], axis=0)\n",
    "                print(freq)\n",
    "\n",
    "            scores_social = self.env.get_score(states=states_social)\n",
    "            better_social = (scores_social > scores).astype(np.long)\n",
    "            \n",
    "            index_indv = np.zeros_like(states)\n",
    "            np.put_along_axis(index_indv, np.random.randint(0, N, (E, M, 1)), 1, axis=-1)\n",
    "            states_indv = (states + index_indv) % 2\n",
    "            scores_indv = self.env.get_score(states=states_indv)\n",
    "            \n",
    "            better_indv = (scores_indv > scores).astype(np.long) * (1 - better_social)  # not better social but better indv\n",
    "            \n",
    "            stay = (1 - better_social) * (1 - better_indv)\n",
    "            if self.state_correction:\n",
    "                states = (better_social * states_social) + (better_indv * states_indv) + stay * states\n",
    "            else:\n",
    "                states = states_social\n",
    "\n",
    "            if self.reward_correction:\n",
    "                scores = (scores_social * better_social) + (scores_indv * better_indv) + stay * scores\n",
    "            else:\n",
    "                scores = scores_social\n",
    "                \n",
    "            \n",
    "            #states = better_social * states_social + (1 - better_social) * states\n",
    "            #scores = better_social * scores_social + (1 - better_social) * scores\n",
    "            #print(states, scores)\n",
    "\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data['act_buf'][0][0][:, :, 0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data['unq_buf'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = {}\n",
    "baseline_data['Ret'] = []\n",
    "baseline_data['FinalScore'] = []\n",
    "baseline_data['scr_buf'] = []\n",
    "baseline_data['unq_buf'] = []\n",
    "baseline_data['act_buf'] = []\n",
    "\n",
    "for i in range(env_num):\n",
    "    print(i)\n",
    "    env_base = env_list[i]\n",
    "    ac_base = FollowMajor_indv_test(env_base, action_type, extra_type, corr_type='TT')\n",
    "    scr_buf = np.zeros((test_ensemble_num, M, trj_len), dtype=np.float32)\n",
    "    unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "    act_buf = np.zeros((test_ensemble_num, M, N, trj_len), dtype=np.float32)\n",
    "\n",
    "    o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "    ep_ret, ep_len = 0, 0\n",
    "    for t in range(2):\n",
    "        print(t)\n",
    "        a = ac_base.step(o)\n",
    "        next_o, r, s = env_base.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "        scr_buf[..., t] = s\n",
    "        act_buf[..., t] = a\n",
    "        for e in range(test_ensemble_num):\n",
    "            freq = np.unique(a[e], axis=0)\n",
    "            unq_buf[e][t] = freq.shape[0]\n",
    "        o = next_o\n",
    "\n",
    "    baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "    baseline_data['FinalScore'].append(np.mean(s))\n",
    "    baseline_data['scr_buf'].append(scr_buf)\n",
    "    baseline_data['unq_buf'].append(unq_buf)\n",
    "    baseline_data['act_buf'].append(act_buf)\n",
    "baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "baseline_data['act_buf'] = np.array(baseline_data['act_buf'])\n",
    "print(\"Baseline finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['green', 'blue','orangered', 'gold', 'purple', 'cyan', 'black']\n",
    "counter=0\n",
    "\n",
    "x = baseline_data['unq_buf']\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter])\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "counter+=1\n",
    "\n",
    "#x = buf_scr_list\n",
    "#avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "#ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label='RL_TT')\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Unique states')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_base = env_list[0]\n",
    "ac_base = FollowMajor_indv_test(env_base, action_type, extra_type, corr_type='TT')\n",
    "\n",
    "o = np.array([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.83, 1], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 9.48, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0], \n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21, 0], \n",
    "              [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6.29, 0]]]])\n",
    "\n",
    "'''\n",
    "o = np.array([[[[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3.83, 1], \n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.13, 0],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.13, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 10.15, 0]]]])\n",
    "\n",
    "'''\n",
    "\n",
    "for i in range(10):\n",
    "    print(ac_base.step(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils import nodes_or_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmeanclustering(n):\n",
    "    assert n%5==0\n",
    "    s = int(n/5)\n",
    "    A = 1 - np.eye(s)\n",
    "    B = np.zeros((s, s))\n",
    "    C = np.block([[A, B, B, B, B],\n",
    "                 [B, A, B, B, B],\n",
    "                 [B, B, A, B, B],\n",
    "                 [B, B, B, A, B],\n",
    "                 [B, B, B, B, A]])\n",
    "    for i in range(5):\n",
    "        j = s * i\n",
    "        C[j][j+s-1] = 0\n",
    "        C[j+s-1][j] = 0\n",
    "        C[j][j-1] = 1\n",
    "        C[j-1][j] = 1\n",
    "\n",
    "    G = nx.from_numpy_matrix(C)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python37264bitmlenvconda8ad7197524cc41d09f1a49c22ce337f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

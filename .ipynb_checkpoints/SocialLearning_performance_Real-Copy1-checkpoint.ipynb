{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ad368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as RLRP\n",
    "from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.nn.init import xavier_normal\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "import time\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network\n",
    "import envs\n",
    "import json\n",
    "from itertools import product\n",
    "from functools import reduce  \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e52c4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/OLP_updated.pickle', 'rb') as f:\n",
    "    real_network = pickle.load(f)\n",
    "\n",
    "candidate = {}\n",
    "max_node_threshold = 1200\n",
    "\n",
    "for network_index in (real_network.network_index):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    if graph2.number_of_nodes() > 0:\n",
    "        if nx.is_connected(graph2) and graph2.number_of_nodes()/graph.number_of_nodes() > 0.95:\n",
    "            candidate[network_index] = graph2.number_of_nodes()\n",
    "        \n",
    "network_data = real_network[np.isin(real_network['network_index'], list(candidate.keys()))]\n",
    "network_filter = np.logical_and(network_data['networkDomain'] == 'Social', network_data['number_nodes'].values < max_node_threshold )\n",
    "network_data = network_data[network_filter]\n",
    "network_index = network_data.network_index.values\n",
    "network_nodes = [candidate[i] for i in network_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b862d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dd7918a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(network_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0683778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'index', 'network_index', 'network_name', 'title',\n",
       "       'description', 'networkDomain', 'subDomain', 'citation', 'sourceUrl',\n",
       "       'hostedBy', 'graphProperties', 'nodeType', 'edgeType', 'nodes_id',\n",
       "       'edges_id', 'number_nodes', 'number_edges', 'ave_degree', 'labels_Q',\n",
       "       'labels_Q_MR', 'labels_Q_MP', 'labels_Q_GMP', 'labels_B_NR_SBM',\n",
       "       'labels_B_NR_DCSBM', 'labels_B_HKK_SBM', 'labels_cICL_HKK_SBM',\n",
       "       'labels_Infomap', 'labels_MDL_SBM', 'labels_MDL_DCSBM', 'labels_S_NB',\n",
       "       'labels_S_cBHm', 'labels_S_cBHa', 'labels_AMOS',\n",
       "       'labels_AMOS_reliablity', 'labels_LRT_WB_DCSBM', 'Q_score',\n",
       "       'Q_MR_score', 'Q_MP_score', 'Q_GMP_score', 'B_NR_SBM_score',\n",
       "       'B_NR_DCSBM_score', 'B_HKK_SBM_score', 'cICL_HKK_SBM_score',\n",
       "       'Infomap_score', 'MDL_SBM_score', 'MDL_DCSBM_score', 'S_NB_score',\n",
       "       'S_cBHm_score', 'S_cBHa_score', 'AMOS_score', 'LRT_WB_DCSBM_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OLP_selected.pickle', 'wb') as f:\n",
    "    pickle.dump(real_network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac606084",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_index = network_data.network_index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a1f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_name, epoch):\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = nx.complete_graph\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'E': env_kwargs['E'],\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb39011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125,\n",
       " 178,\n",
       " 39,\n",
       " 115,\n",
       " 152,\n",
       " 144,\n",
       " 137,\n",
       " 142,\n",
       " 306,\n",
       " 319,\n",
       " 322,\n",
       " 336,\n",
       " 331,\n",
       " 333,\n",
       " 332,\n",
       " 334,\n",
       " 332,\n",
       " 330,\n",
       " 352,\n",
       " 367,\n",
       " 377,\n",
       " 380,\n",
       " 389,\n",
       " 378,\n",
       " 363,\n",
       " 373,\n",
       " 384,\n",
       " 425,\n",
       " 433,\n",
       " 409,\n",
       " 435,\n",
       " 439,\n",
       " 425,\n",
       " 437,\n",
       " 431,\n",
       " 450,\n",
       " 440,\n",
       " 440,\n",
       " 443,\n",
       " 454,\n",
       " 459,\n",
       " 449,\n",
       " 424,\n",
       " 379,\n",
       " 390,\n",
       " 387,\n",
       " 393,\n",
       " 455,\n",
       " 474,\n",
       " 478,\n",
       " 468,\n",
       " 477,\n",
       " 506,\n",
       " 524,\n",
       " 540,\n",
       " 541,\n",
       " 569,\n",
       " 589,\n",
       " 610,\n",
       " 621,\n",
       " 626,\n",
       " 627,\n",
       " 643,\n",
       " 654,\n",
       " 678,\n",
       " 794,\n",
       " 763,\n",
       " 781,\n",
       " 800,\n",
       " 779,\n",
       " 786,\n",
       " 819,\n",
       " 771,\n",
       " 764,\n",
       " 792,\n",
       " 779,\n",
       " 776,\n",
       " 781,\n",
       " 752,\n",
       " 747,\n",
       " 734,\n",
       " 744,\n",
       " 739,\n",
       " 746,\n",
       " 739,\n",
       " 715,\n",
       " 715,\n",
       " 766]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_data[network_data['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc770fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(network_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610d8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2025\n",
    "# complete_L200_2 2269\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "# 79, 177inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400_E550\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400'\n",
    "epoch = 550\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "reward_supply_type = 'full'\n",
    "env_kwargs['rescale'] = False\n",
    "terminate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "492dbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 200\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SIRF'\n",
    "env_name = 'SL_NK_' + action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d29b8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_num = 0\n",
    "index_list = [i*11 + copy_num for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6eef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# normal test, without unique/prob\n",
    "\n",
    "for index in index_list:\n",
    "\n",
    "    scr_buf_list = []\n",
    "    final_score_list = []\n",
    "    Ret_list = []\n",
    "    \n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index[index]]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    graph3 = nx.convert_node_labels_to_integers(graph2)\n",
    "\n",
    "    env_kwargs = {\n",
    "            'E': E,\n",
    "            'M': network_nodes[index],\n",
    "            'N': N,\n",
    "            'K': K,\n",
    "            'neighbor_num': NN,\n",
    "            'exp': exp,\n",
    "            'graph': nx.from_edgelist,\n",
    "            'graph_dict': {'edgelist': graph3.edges},\n",
    "            'reward_type': reward_type,\n",
    "            'action_type': action_type,\n",
    "            'extra_type': extra_type,\n",
    "        'corr_type': 'TT'\n",
    "        }\n",
    "    \n",
    "    env_num = 5\n",
    "    env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "    start_time = time.time()\n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        test_ensemble_num = 20\n",
    "        buf = PPOBuffer(\n",
    "            obs_dim, \n",
    "            act_dim, \n",
    "            test_ensemble_num, \n",
    "            env_kwargs['M'], \n",
    "            dim_len, \n",
    "            trj_len, \n",
    "            gamma, \n",
    "            lam, \n",
    "            split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "\n",
    "\n",
    "        env = env_list[i]\n",
    "        o, _ = env.reset(test_ensemble_num, base=True) \n",
    "        ep_ret, ep_len = 0, 0\n",
    "        best_ep_ret = -np.inf\n",
    "\n",
    "        for t in range(trj_len):\n",
    "            epoch_ended = t == trj_len - 1\n",
    "            a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "\n",
    "            next_o, r, s = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "\n",
    "            if reward_supply_type == 'full':\n",
    "                buf.store(o, a, r, v, s, logp)\n",
    "            else:\n",
    "                if epoch_ended:\n",
    "                    if reward_supply_type == 'final':\n",
    "                        buf.store(o, a, r * trj_len, v, s, logp)\n",
    "                    elif reward_supply_type == 'finalmean':\n",
    "                        buf.store(o, a, ep_ret, v, s, logp)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                else:\n",
    "                    buf.store(o, a, 0, v, s, logp)\n",
    "\n",
    "            # Update obs (critical!)\n",
    "            o = next_o\n",
    "\n",
    "            if epoch_ended:\n",
    "                a, v, logp, pi = ac.step(\n",
    "                    torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                    return_pi=True\n",
    "                )\n",
    "                _, _, s = env.step(a)\n",
    "                if terminate:\n",
    "                    buf.finish_path(np.zeros_like(v))\n",
    "                else:\n",
    "                    buf.finish_path(v)\n",
    "\n",
    "        Ret=ep_ret / ep_len\n",
    "        Ret_list.append(Ret)\n",
    "        EpLen=ep_len\n",
    "        FinalScore=np.mean(s)\n",
    "        scr_buf_list.append(buf.scr_buf)\n",
    "        final_score_list.append(FinalScore)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "\n",
    "    Ret_list = np.array(Ret_list)\n",
    "    final_score_list = np.array(final_score_list)\n",
    "    scr_buf_list = np.array(scr_buf_list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'[Network {index}, ({network_index[index]}, M={network_nodes[index]}), (Time : {elapsed_time})]: {np.mean(Ret_list)}, {np.mean(final_score_list)}', )\n",
    "    inspection_dict = {}\n",
    "    inspection_dict['scr_buf_list'] = scr_buf_list\n",
    "    \n",
    "    with open(f'./result/real_network_{index}_RL.pkl', 'wb') as f:\n",
    "        pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/real_network_{index}.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "for key in data.keys():\n",
    "    if key != 'keys':\n",
    "        print(key)\n",
    "        for key2 in data['keys']:\n",
    "            print(data[key][key2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

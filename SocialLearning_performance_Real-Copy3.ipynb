{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as RLRP\n",
    "from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.nn.init import xavier_normal\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "import time\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network\n",
    "import envs\n",
    "import json\n",
    "from itertools import product\n",
    "from functools import reduce  \n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52c4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/OLP_updated.pickle', 'rb') as f:\n",
    "    real_network = pickle.load(f)\n",
    "\n",
    "candidate = {}\n",
    "max_node_threshold = 1200\n",
    "\n",
    "for network_index in (real_network.network_index):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    if graph2.number_of_nodes() > 0:\n",
    "        if nx.is_connected(graph2) and graph2.number_of_nodes()/graph.number_of_nodes() > 0.95:\n",
    "            candidate[network_index] = graph2.number_of_nodes()\n",
    "        \n",
    "network_data = real_network[np.isin(real_network['network_index'], list(candidate.keys()))]\n",
    "network_filter = np.logical_and(network_data['networkDomain'] == 'Social', network_data['number_nodes'].values < max_node_threshold )\n",
    "network_data = network_data[network_filter]\n",
    "network_index = network_data.network_index.values\n",
    "network_nodes = [candidate[i] for i in network_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OLP_selected.pickle', 'wb') as f:\n",
    "    pickle.dump(real_network, f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
   "id": "a3a1f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_name, epoch):\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = nx.complete_graph\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'E': env_kwargs['E'],\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_L200 2025\n",
    "# complete_L200_2 2269\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "# 79, 177inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400_E550\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400'\n",
    "epoch = 550\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "reward_supply_type = 'full'\n",
    "env_kwargs['rescale'] = False\n",
    "terminate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 32\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 200\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SIRF'\n",
    "env_name = 'SL_NK_' + action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_num = 1\n",
    "index_list = [i*11 + copy_num for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_num = 6\n",
    "index_list += [i*11 + copy_num for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_num = 7\n",
    "index_list += [i*11 + copy_num for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c700389",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6eef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normal test, without unique/prob\n",
    "\n",
    "for index in index_list:\n",
    "\n",
    "    scr_buf_list = []\n",
    "    final_score_list = []\n",
    "    Ret_list = []\n",
    "    \n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index[index]]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    graph3 = nx.convert_node_labels_to_integers(graph2)\n",
    "\n",
    "    env_kwargs = {\n",
    "            'E': E,\n",
    "            'M': network_nodes[index],\n",
    "            'N': N,\n",
    "            'K': K,\n",
    "            'neighbor_num': NN,\n",
    "            'exp': exp,\n",
    "            'graph': nx.from_edgelist,\n",
    "            'graph_dict': {'edgelist': graph3.edges},\n",
    "            'reward_type': reward_type,\n",
    "            'action_type': action_type,\n",
    "            'extra_type': extra_type,\n",
    "        'corr_type': 'TT'\n",
    "        }\n",
    "    \n",
    "    env_num = 5\n",
    "    env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "    start_time = time.time()\n",
    "    for i in range(env_num):\n",
    "        print(i)\n",
    "        test_ensemble_num = 20\n",
    "        buf = PPOBuffer(\n",
    "            obs_dim, \n",
    "            act_dim, \n",
    "            test_ensemble_num, \n",
    "            env_kwargs['M'], \n",
    "            dim_len, \n",
    "            trj_len, \n",
    "            gamma, \n",
    "            lam, \n",
    "            split=True if env_kwargs['action_type'] == 'split' else False)\n",
    "\n",
    "\n",
    "        env = env_list[i]\n",
    "        o, _ = env.reset(test_ensemble_num, base=True) \n",
    "        ep_ret, ep_len = 0, 0\n",
    "        best_ep_ret = -np.inf\n",
    "\n",
    "        for t in range(trj_len):\n",
    "            epoch_ended = t == trj_len - 1\n",
    "            a, v, logp, pi = ac.step(torch.as_tensor(o, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "\n",
    "            next_o, r, s = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "\n",
    "            if reward_supply_type == 'full':\n",
    "                buf.store(o, a, r, v, s, logp)\n",
    "            else:\n",
    "                if epoch_ended:\n",
    "                    if reward_supply_type == 'final':\n",
    "                        buf.store(o, a, r * trj_len, v, s, logp)\n",
    "                    elif reward_supply_type == 'finalmean':\n",
    "                        buf.store(o, a, ep_ret, v, s, logp)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                else:\n",
    "                    buf.store(o, a, 0, v, s, logp)\n",
    "\n",
    "            # Update obs (critical!)\n",
    "            o = next_o\n",
    "\n",
    "            if epoch_ended:\n",
    "                a, v, logp, pi = ac.step(\n",
    "                    torch.as_tensor(o, dtype=torch.float32, device='cuda' ),\n",
    "                    return_pi=True\n",
    "                )\n",
    "                _, _, s = env.step(a)\n",
    "                if terminate:\n",
    "                    buf.finish_path(np.zeros_like(v))\n",
    "                else:\n",
    "                    buf.finish_path(v)\n",
    "\n",
    "        Ret=ep_ret / ep_len\n",
    "        Ret_list.append(Ret)\n",
    "        EpLen=ep_len\n",
    "        FinalScore=np.mean(s)\n",
    "        scr_buf_list.append(buf.scr_buf)\n",
    "        final_score_list.append(FinalScore)\n",
    "        ep_ret, ep_len = 0, 0\n",
    "\n",
    "    Ret_list = np.array(Ret_list)\n",
    "    final_score_list = np.array(final_score_list)\n",
    "    scr_buf_list = np.array(scr_buf_list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'[Network {index}, ({network_index[index]}, M={network_nodes[index]}), (Time : {elapsed_time})]: {np.mean(Ret_list)}, {np.mean(final_score_list)}', )\n",
    "    inspection_dict = {}\n",
    "    inspection_dict['scr_buf_list'] = scr_buf_list\n",
    "    \n",
    "    with open(f'./result/real_network_{index}_RL.pkl', 'wb') as f:\n",
    "        pickle.dump(inspection_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b7327",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
   "id": "f38dac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict = {}\n",
    "baseline_data_dict['keys'] = ['Ret', 'FinalScore']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
   "id": "5e3d616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_num = 2\n",
    "index_list = [i*4 + copy_num for i in range(22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "5ce697a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [52]"
=======
   "id": "a9423e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 6,\n",
       " 10,\n",
       " 14,\n",
       " 18,\n",
       " 22,\n",
       " 26,\n",
       " 30,\n",
       " 34,\n",
       " 38,\n",
       " 42,\n",
       " 46,\n",
       " 50,\n",
       " 54,\n",
       " 58,\n",
       " 62,\n",
       " 66,\n",
       " 70,\n",
       " 74,\n",
       " 78,\n",
       " 82,\n",
       " 86]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d56c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 20\n",
    "M = 100\n",
    "N = 15\n",
    "K = 7\n",
    "NN = 3\n",
    "exp = 8\n",
    "trj_len = 200\n",
    "graph_type = 'complete'\n",
    "reward_type = 'indv_raw_full'\n",
    "action_type = 'total'\n",
    "extra_type = 'SIRF'\n",
    "env_name = 'SL_NK_' + action_type"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
   "id": "7ff6cdff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline construction initiated\n",
      "Baseline : FollowBest_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, FollowBest_random, (191.0, M=506, (Time : 5376.234416484833)]: 0.8955600585714564, 0.9939144246748925\n",
=======
      "[Network 2, FollowBest_random, (116.0, M=39, (Time : 398.4650297164917)]: 0.6668825087160147, 0.7766937872220472\n",
      "Baseline : FollowBest_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 2, FollowBest_prob, (116.0, M=39, (Time : 413.72767543792725)]: 0.6240271727097529, 0.6741883724367606\n",
      "Baseline : FollowMajor_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 2, FollowMajor_random, (116.0, M=39, (Time : 498.18405532836914)]: 0.39240077083214653, 0.5395718003723997\n",
      "Baseline : FollowMajor_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 2, FollowMajor_prob, (116.0, M=39, (Time : 514.5488941669464)]: 0.5152916035434022, 0.7033380377530347\n",
      "Baseline : IndvRandom\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 2, IndvRandom, (116.0, M=39, (Time : 346.2765483856201)]: 0.32267217359840616, 0.4100426743997369\n",
      "Baseline : IndvProb\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 2, IndvProb, (116.0, M=39, (Time : 347.6495506763458)]: 0.3636754917873153, 0.45947174663830365\n",
      "Baseline construction initiated\n",
      "Baseline : FollowBest_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, FollowBest_random, (145.0, M=137, (Time : 1275.3945748806)]: 0.792490763751307, 0.9264973580454627\n",
      "Baseline : FollowBest_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, FollowBest_prob, (145.0, M=137, (Time : 1290.4909365177155)]: 0.7383482435903035, 0.7806855943467537\n",
      "Baseline : FollowMajor_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, FollowMajor_random, (145.0, M=137, (Time : 1658.1923847198486)]: 0.3585750175202336, 0.483575792681114\n",
      "Baseline : FollowMajor_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, FollowMajor_prob, (145.0, M=137, (Time : 1698.5000674724579)]: 0.4440739924133904, 0.6057903753580387\n",
      "Baseline : IndvRandom\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, IndvRandom, (145.0, M=137, (Time : 1183.2432675361633)]: 0.3297572479587113, 0.4156636369916056\n",
      "Baseline : IndvProb\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 6, IndvProb, (145.0, M=137, (Time : 1076.587583065033)]: 0.36576469433712133, 0.45665922769900896\n",
      "Baseline construction initiated\n",
      "Baseline : FollowBest_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 10, FollowBest_random, (149.0, M=322, (Time : 2935.7079887390137)]: 0.8637457581127821, 0.9801179198249013\n",
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
      "Baseline : FollowBest_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, FollowBest_prob, (191.0, M=506, (Time : 5786.256821155548)]: 0.8817267289239277, 0.9236892957431563\n",
=======
      "[Network 10, FollowBest_prob, (149.0, M=322, (Time : 3020.926227092743)]: 0.8387762021274673, 0.8831341164751688\n",
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
      "Baseline : FollowMajor_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, FollowMajor_random, (191.0, M=506, (Time : 7632.7251398563385)]: 0.3408144468258647, 0.4506548604734825\n",
=======
      "[Network 10, FollowMajor_random, (149.0, M=322, (Time : 3867.824787378311)]: 0.34022880932563454, 0.4465769425443035\n",
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
      "Baseline : FollowMajor_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, FollowMajor_prob, (191.0, M=506, (Time : 7488.758439779282)]: 0.4289367388059662, 0.6116644169639935\n",
=======
      "[Network 10, FollowMajor_prob, (149.0, M=322, (Time : 3922.4902777671814)]: 0.4028904151992213, 0.5445090684839975\n",
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
      "Baseline : IndvRandom\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, IndvRandom, (191.0, M=506, (Time : 5300.558317899704)]: 0.3279043073019716, 0.4177208971424151\n",
=======
      "[Network 10, IndvRandom, (149.0, M=322, (Time : 2746.1279122829437)]: 0.3280749234720931, 0.4165114283117705\n",
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
      "Baseline : IndvProb\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
<<<<<<< HEAD
      "[Network 52, IndvProb, (191.0, M=506, (Time : 4885.0153222084045)]: 0.3683260806625893, 0.4682869341900521\n"
=======
      "[Network 10, IndvProb, (149.0, M=322, (Time : 3025.347106695175)]: 0.36382417710921133, 0.4575919120695575\n",
      "Baseline construction initiated\n",
      "Baseline : FollowBest_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 14, FollowBest_random, (153.0, M=332, (Time : 3117.389276742935)]: 0.8572571683335031, 0.9820994716570505\n",
      "Baseline : FollowBest_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 14, FollowBest_prob, (153.0, M=332, (Time : 3224.2022335529327)]: 0.8412847513734494, 0.8935717413071405\n",
      "Baseline : FollowMajor_random\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 14, FollowMajor_random, (153.0, M=332, (Time : 4417.1552946567535)]: 0.3231313857752282, 0.4252170560396945\n",
      "Baseline : FollowMajor_prob\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 14, FollowMajor_prob, (153.0, M=332, (Time : 4522.025090456009)]: 0.4013891001541647, 0.562755206680962\n",
      "Baseline : IndvRandom\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[Network 14, IndvRandom, (153.0, M=332, (Time : 3116.5163147449493)]: 0.31067654362812547, 0.3953223118672728\n",
      "Baseline : IndvProb\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
>>>>>>> dde5dc8cbccfb8f69a7cc138085d8127184de059
     ]
    }
   ],
   "source": [
    "#baselines = ['FollowBest', 'FollowBest_indv', 'FollowMajor', 'FollowMajor_indv', 'IndvLearning', 'RandomCopy']\n",
    "baselines = ['FollowBest_random', 'FollowBest_prob', 'FollowMajor_random', 'FollowMajor_prob', 'IndvRandom', 'IndvProb',]\n",
    "\n",
    "for index in index_list:\n",
    "\n",
    "    scr_buf_list = []\n",
    "    final_score_list = []\n",
    "    Ret_list = []\n",
    "    \n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index[index]]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    graph3 = nx.convert_node_labels_to_integers(graph2)\n",
    "\n",
    "    env_kwargs = {\n",
    "            'E': E,\n",
    "            'M': network_nodes[index],\n",
    "            'N': N,\n",
    "            'K': K,\n",
    "            'neighbor_num': NN,\n",
    "            'exp': exp,\n",
    "            'graph': nx.from_edgelist,\n",
    "            'graph_dict': {'edgelist': graph3.edges},\n",
    "            'reward_type': reward_type,\n",
    "            'action_type': action_type,\n",
    "            'extra_type': extra_type,\n",
    "        'corr_type': 'TT'\n",
    "        }\n",
    "    \n",
    "    env_num = 5\n",
    "    test_ensemble_num = 20\n",
    "    env_list = [envs.__dict__[env_name](**env_kwargs) for i in range(env_num)]\n",
    "    state_list = []\n",
    "    for i in range(env_num):\n",
    "        _, fixed_state = env_list[i].reset(E=test_ensemble_num, base=True)\n",
    "        state_list.append(deepcopy(fixed_state))\n",
    "    print(\"Baseline construction initiated\")\n",
    "    \n",
    "    baseline_data_dict = {}\n",
    "    baseline_data_dict['keys'] = ['Ret', 'FinalScore']\n",
    "\n",
    "    for baseline_name in baselines:\n",
    "        if baseline_name not in baseline_data_dict.keys():\n",
    "            print(f\"Baseline : {baseline_name}\")\n",
    "            start_time = time.time()\n",
    "            baseline_data = {}\n",
    "            baseline_data['Ret'] = []\n",
    "            baseline_data['FinalScore'] = []\n",
    "            baseline_data['scr_buf'] = []\n",
    "            baseline_data['unq_buf'] = []\n",
    "\n",
    "            for i in range(env_num):\n",
    "                print(i)\n",
    "                env_base = env_list[i]\n",
    "                ac_base = core.__dict__[baseline_name](env_base, action_type, extra_type, corr_type='TT')\n",
    "                scr_buf = np.zeros((test_ensemble_num, network_nodes[index], trj_len), dtype=np.float32)\n",
    "                unq_buf = np.zeros((test_ensemble_num, trj_len), dtype=np.float32)\n",
    "\n",
    "                o, _ = env_base.reset(states=state_list[i], state_only=True, base=True)\n",
    "                ep_ret, ep_len = 0, 0\n",
    "                for t in range(trj_len):\n",
    "                    a = ac_base.step(o)\n",
    "                    next_o, r, s = env_base.step(a)\n",
    "                    ep_ret += r\n",
    "                    ep_len += 1\n",
    "                    scr_buf[..., t] = s\n",
    "                    for e in range(test_ensemble_num):\n",
    "                        freq = np.unique(a[e], axis=0)\n",
    "                        unq_buf[e][t] = freq.shape[0]\n",
    "                    o = next_o\n",
    "\n",
    "                baseline_data['Ret'].append(np.mean(ep_ret / ep_len))\n",
    "                baseline_data['FinalScore'].append(np.mean(s))\n",
    "                baseline_data['scr_buf'].append(scr_buf)\n",
    "                baseline_data['unq_buf'].append(unq_buf)\n",
    "            baseline_data['Ret'] = np.mean(baseline_data['Ret'])\n",
    "            baseline_data['FinalScore'] = np.mean(baseline_data['FinalScore'])\n",
    "            baseline_data['scr_buf'] = np.array(baseline_data['scr_buf'])\n",
    "            baseline_data['unq_buf'] = np.array(baseline_data['unq_buf'])\n",
    "            baseline_data_dict[baseline_name] = baseline_data\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f'[Network {index}, {baseline_name}, ({network_index[index]}, M={network_nodes[index]}, (Time : {elapsed_time})]: {baseline_data_dict[baseline_name][\"Ret\"]}, {baseline_data_dict[baseline_name][\"FinalScore\"]}')\n",
    "    \n",
    "    with open(f'real_network_{index}_base2.pkl', 'wb') as f:\n",
    "        pickle.dump(baseline_data_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ce9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/real_network_{index}.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "for key in data.keys():\n",
    "    if key != 'keys':\n",
    "        print(key)\n",
    "        for key2 in data['keys']:\n",
    "            print(data[key][key2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

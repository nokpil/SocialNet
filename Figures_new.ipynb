{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292eb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader # (testset, batch_size=4,shuffle=False, num_workers=4)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as RLRP\n",
    "from torch.nn.parallel import DistributedDataParallel, DataParallel\n",
    "from torch.nn.init import xavier_normal\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import nkmodel as nk\n",
    "import ppo.core as core\n",
    "from ppo.ppo import PPOBuffer\n",
    "from utils.utils import max_mean_clustering_network, real_network\n",
    "import envs\n",
    "import json\n",
    "import scipy\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "from scipy.stats import rankdata, multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dict1 = {'FollowBest' : 'BI',\n",
    "                    'FollowBest_indv': 'BI-I',\n",
    "                    'FollowBest_prob': 'BI-P',\n",
    "                    'FollowBest_random': 'BI-R',\n",
    "                    'FollowMajor': 'CF', \n",
    "                    'FollowMajor_indv': 'CF-I',\n",
    "                    'FollowMajor_prob': 'CF-P',\n",
    "                    'FollowMajor_random': 'CF-R',\n",
    "                    'IndvLearning': 'PI-I',\n",
    "                    'IndvProb': 'PI-P',\n",
    "                    'IndvRandom': 'PI-R',\n",
    "                    'RandomCopy': 'RI'\n",
    "                   }\n",
    "\n",
    "conversion_dict2 = dict((v,k) for k,v in conversion_dict1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8194fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_name, epoch):\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = nx.complete_graph\n",
    "\n",
    "    #rel_path = f'data/runs/ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand/{exp_name}/{exp_name}_s42/'\n",
    "    rel_path = f'data/runs/{exp_name}/{exp_name}_s42/'\n",
    "\n",
    "    with open(rel_path + \"config.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    env_kwargs = json_data['env_kwargs']\n",
    "    env_name = json_data['env_name']\n",
    "    env_kwargs['graph'] = max_mean_clustering_network if json_data['env_kwargs']['graph_type'] == 'maxmc' else nx.complete_graph\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'E': env_kwargs['E'],\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs\n",
    "    ac_kwargs = json_data['ac_kwargs']\n",
    "    ac_kwargs['activation'] = nn.Tanh()\n",
    "    arch = json_data['arch']\n",
    "    trj_len = json_data['trj_len']\n",
    "    gamma = json_data['gamma']\n",
    "    lam = json_data['lam']\n",
    "    epochs = json_data['epochs']\n",
    "    seed = json_data['seed']\n",
    "    ensemble_num = env_kwargs['E']\n",
    "    agent_num = env_kwargs['M']\n",
    "    env_scheduler_kwargs = {\n",
    "            'local_rank': 0,\n",
    "            'exp_name': exp_name,\n",
    "            'E': env_kwargs['E'],\n",
    "            'N': env_kwargs['N'],\n",
    "            'K': env_kwargs['K'],\n",
    "            'exp': env_kwargs['exp'],\n",
    "            'NGPU': 1, #'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs\\\\ds_complete_indv_raw_random_SIR_N10K3NN3_new_rand'\n",
    "        'data_dir': 'D:\\\\OneDrive\\\\연구\\\\ML\\\\MyProject\\\\SocialNet\\\\SocialNet\\\\data\\\\runs'\n",
    "    }\n",
    "    env_kwargs['env_scheduler'] = envs.__dict__['random_env_scheduler'](**env_scheduler_kwargs)\n",
    "    json_data['corr_type'] = 'TT'\n",
    "    env_kwargs['corr_type'] = 'TT'\n",
    "    if len(env_kwargs['reward_type']) < 9:\n",
    "        print('modify')\n",
    "        env_kwargs['reward_type'] = env_kwargs['reward_type'] + '_full'\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    env = envs.__dict__[env_name](**env_kwargs)\n",
    "    action_type = env_kwargs['action_type']\n",
    "    extra_type = env_kwargs['extra_type']\n",
    "    extra_num = len(extra_type)\n",
    "    # Instantiate environment\n",
    "    if action_type == 'total':\n",
    "        obs_dim = (env.neighbor_num + 1, env.N + extra_num)  # (3+1, 15+2)\n",
    "        act_dim = env.action_space.n\n",
    "        dim_len = env.N\n",
    "    elif action_type == 'split':\n",
    "        obs_dim = (env.neighbor_num + 1, 1 + extra_num)\n",
    "        act_dim = (2,)\n",
    "        dim_len = env.N\n",
    "        \n",
    "    checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "    ac = core.ActorCritic(obs_dim, act_dim, arch, **ac_kwargs)\n",
    "    ac.pi.load_state_dict(checkpoint['pi'])\n",
    "    ac.v.load_state_dict(checkpoint['v'])\n",
    "\n",
    "    Parallel = DataParallel\n",
    "    parallel_args = {\n",
    "        'device_ids': list(range(1)),\n",
    "        'output_device': 0\n",
    "    } \n",
    "\n",
    "    ac.pi = Parallel(ac.pi, **parallel_args)\n",
    "    ac.v = Parallel(ac.v, **parallel_args)\n",
    "    ac.eval()\n",
    "    return ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs\n",
    "\n",
    "def ema(data, alpha = 0.99):\n",
    "    ema_data = np.zeros_like(data)\n",
    "    ema_data[0] = data[0]\n",
    "    for i in range(len(ema_data)-1):\n",
    "        ema_data[i+1] = alpha * ema_data[i] + (1 - alpha) * data[i+1]\n",
    "    return ema_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def coord_triplet(s):\n",
    "    x = []  # np.zeros((int(s*(s+1)*(s+2)/6), 3))\n",
    "\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):\n",
    "            for k in range(j, s):\n",
    "                x.append([i, j, k])\n",
    "                \n",
    "                \n",
    "    return np.array(x)\n",
    "\n",
    "def fixed_point(ac):\n",
    "    data = np.array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 1], \n",
    "                  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 100, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 100, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 100, 0]]])\n",
    "\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data, dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    return np.round(x)[0].astype(np.int)\n",
    "\n",
    "def explode(data):\n",
    "    shape_arr = np.array(data.shape)\n",
    "    size = shape_arr[:3]*2 - 1\n",
    "    exploded = np.zeros(np.concatenate([size, shape_arr[3:]]), dtype=data.dtype)\n",
    "    exploded[::2, ::2, ::2] = data\n",
    "    return exploded\n",
    "\n",
    "def expand_coordinates(indices):\n",
    "    x, y, z = indices\n",
    "    x[1::2, :, :] += 1\n",
    "    y[:, 1::2, :] += 1\n",
    "    z[:, :, 1::2] += 1\n",
    "    return x, y, z\n",
    "\n",
    "def make_cube(s, sp_dist, cp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                x[i, j, k] = [sp_dist[c], cp_dist[c], hp_dist[c]]\n",
    "                c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors(pi_list, sp, cp, hp, sp_show, cp_show, hp_show, max_s):\n",
    "    N = pi_list.shape[-1]\n",
    "    sp_dist = (np.sum((pi_list - sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    cp_dist = (np.sum((pi_list -cp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list - hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube(max_s, sp_dist, cp_dist, hp_dist)\n",
    "    if sp_show:\n",
    "        facecolors[..., 0] = (1 - mc[:, :, :, 0])**2   # Red : sp_dist\n",
    "    if cp_show:\n",
    "        facecolors[..., 1] = (1 - mc[:, :, :, 1])**2   # Blue : np_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = (1 - mc[:, :, :, 2])**2   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [sp_show, cp_show, hp_show]], axis=-1))**2 * 0.3 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, sp_dist, cp_dist, hp_dist\n",
    "\n",
    "def make_cube_freq(s, sp_dist, cp_dist, hp_dist):\n",
    "    x = np.ones((s, s, s, 3))\n",
    "    c = 0\n",
    "    for i in range(s):\n",
    "        for j in range(i, s):  # i+1\n",
    "            for k in range(j, s):  # j+1\n",
    "                if i==j and j<k:\n",
    "                    x[i, j, k] = [sp_dist[c], cp_dist[c], hp_dist[c]]\n",
    "                    c+=1\n",
    "    return x\n",
    "\n",
    "def assign_facecolors_freq(pi_list, sp, cp, hp, sp_show, cp_show, hp_show, max_s):\n",
    "    N = pi_list.shape[-1]\n",
    "    sp_dist = (np.sum((pi_list - sp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    cp_dist = (np.sum((pi_list -cp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    hp_dist = (np.sum((pi_list - hp)**2, axis=-1)**0.5)/np.sqrt(N)\n",
    "    \n",
    "    facecolors = np.zeros((max_s, max_s, max_s, 4)) # R, G, B, alpha\n",
    "    mc = make_cube_freq(max_s, sp_dist, cp_dist, hp_dist)\n",
    "    if sp_show:\n",
    "        facecolors[..., 0] = (1 - mc[:, :, :, 0])**2   # Red : sp_dist\n",
    "    if cp_show:\n",
    "        facecolors[..., 1] = (1 - mc[:, :, :, 1])**2   # Blue : np_dist\n",
    "    if hp_show:\n",
    "        facecolors[..., 2] = (1 - mc[:, :, :, 2])**2   # Blue : hp_dist\n",
    "    #facecolors[..., -1] = (np.maximum((1 - np.min(mc, axis=-1)), 0.5)-0.5)*2\n",
    "    facecolors[..., -1] = (1 - np.min(mc[..., [sp_show, cp_show, hp_show]], axis=-1))**2 * 0.3 # maximum opacity : 0.8 * 0.8 \n",
    "    return facecolors, sp_dist, cp_dist, hp_dist\n",
    "\n",
    "def plot_cube(facecolors, stride, angle=320, name = '', save=True):\n",
    "    IMG_DIM = len(facecolors)\n",
    "    facecolors = explode(facecolors)\n",
    "    \n",
    "    filled = facecolors[:,:,:,-1] != 0\n",
    "    #print(filled.shape)\n",
    "    #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "    x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, angle)\n",
    "    ax.set_xlim(right=IMG_DIM*stride)\n",
    "    ax.set_ylim(top=IMG_DIM*stride)\n",
    "    ax.set_zlim(top=IMG_DIM*stride)\n",
    "    \n",
    "    #ax.set_xlabel(r'$p_3$', fontsize=18)\n",
    "    #ax.set_ylabel(r'$p_2$', fontsize=18)\n",
    "    #ax.set_zlabel(r'$p_1$', fontsize=18)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    #ax.set_xticks([0, 50, 100])\n",
    "    #ax.set_yticks([0, 50, 100])\n",
    "    #ax.set_zticks([0, 50, 100])\n",
    "    #ax.tick_params(axis = 'x', labelsize=12)\n",
    "    #ax.tick_params(axis = 'y', labelsize=12)\n",
    "    #ax.tick_params(axis = 'z', labelsize=12)\n",
    "    \n",
    "    ax.voxels(x/2*stride, y/2 * stride, z/2 * stride, filled, facecolors=facecolors, shade=False)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'./result/cube_figure/cube_{name}.png', transparent=True, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "template_a1 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0]])\n",
    "\n",
    "template_a2 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "template_b1 = np.array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "          [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0]])\n",
    "\n",
    "template_c1 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "            [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0]])\n",
    "\n",
    "template_c2 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "            [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "          [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0d00d",
   "metadata": {},
   "source": [
    "# Fig.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74f462",
   "metadata": {},
   "source": [
    "## Fig.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "# Generate torus mesh\n",
    "\n",
    "fig = plt.figure(figsize = (6, 6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "ax = fig.gca(projection = '3d')\n",
    "\n",
    "def gauss2d(mu, sigma):\n",
    "    w, h = 100, 100\n",
    "    std = [np.sqrt(sigma[0]), np.sqrt(sigma[1])]\n",
    "    #x = np.linspace(mu[0] - 3 * std[0], mu[0] + 3 * std[0], w)\n",
    "    #y = np.linspace(mu[1] - 3 * std[1], mu[1] + 3 * std[1], h)\n",
    "    x = np.linspace(-5, 5, w)\n",
    "    y = np.linspace(-5, 5, h)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    x_ = x.flatten()\n",
    "    y_ = y.flatten()\n",
    "    xy = np.vstack((x_, y_)).T\n",
    "\n",
    "    normal_rv = multivariate_normal(mu, sigma)\n",
    "    z = normal_rv.pdf(xy)\n",
    "    return x, y, z.reshape(w, h, order='F').T\n",
    "\n",
    "X, Y, z1 = gauss2d(mu = np.array([0, 0]), sigma = np.array([3, 3]))\n",
    "for i in range(30):\n",
    "    _, _, z = gauss2d(mu = np.array([np.random.uniform(-5, 5), np.random.uniform(-5, 5)]), \n",
    "                      sigma = np.array([np.random.uniform(0.2, 1.5), np.random.uniform(0.2, 1.5)]))\n",
    "    z1 += z\n",
    "    \n",
    "surf = ax.plot_surface(X, Y, z1, cmap=\"YlGn\", vmin=-0.1, vmax=0.9, linewidth=5, antialiased=False, rcount=200, ccount=200, alpha=0.8)\n",
    "#traj = traj[-50:]\n",
    "#traj_noise = traj_noise[-50:]\n",
    "#ax.plot3D(traj[:, 0], traj[:, 1], traj[:, 2], marker='o', ms=2, linewidth=1, color='r')\n",
    "#ax.plot3D(traj_noise[:, 0], traj_noise[:, 1], traj_noise[:, 2], marker='o', ms=1, linewidth=2, color='b')\n",
    "#ax.set_xlim3d(-1, 1)\n",
    "#ax.set_ylim3d(-1, 1)\n",
    "#ax.set_zlim3d(-1, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "#plt.savefig('rugged.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd91070",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('rugged2.png', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7344c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea70b978",
   "metadata": {},
   "source": [
    "# Fig.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923884d5",
   "metadata": {},
   "source": [
    "## Fig.2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "#exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "exp_name = 'test_test'\n",
    "epoch = 3891\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    print(ent)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    #facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)\n",
    "    #plt.savefig(f'./Fig2b_5.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c14e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "#ax.set_yticks([0, 83140, 176851])\n",
    "#ax.set_yticklabels(['(50, 0, \\n0, 0)', '(50, 20, \\n20, 20)', '(50, 100, \\n100, 100)',], fontsize=14)\n",
    "#ax.set_yticklabels(['', '', ''])\n",
    "\n",
    "#ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "\n",
    "#ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig2b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696c2a1",
   "metadata": {},
   "source": [
    "## Fig.2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b933b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency test\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "# complete_L200 2025\n",
    "# complete_L200_2 2269\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "graph_type = 'complete'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "epoch = 900\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template_f1 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 0], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0, -1, 2 / neighbor_num],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0, -1, 2 / neighbor_num],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num]])\n",
    "\n",
    "template_f2 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 0], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num]])\n",
    "\n",
    "template = template_f1\n",
    "\n",
    "for s in s_list:\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    mask = [True if ((tc[i][1]<tc[i][2]) and (tc[i][0]==tc[i][1])) else False for i in range(len(tc))]\n",
    "    tc = tc[mask]\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors_freq(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    #facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac57321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Major'], fontsize=14)\n",
    "\n",
    "\n",
    "#ax.set_yticklabels(['(50, 0, \\n0, 0)', '(50, 20, \\n20, 20)', '(50, 100, \\n100, 100)',], fontsize=14)\n",
    "ax.set_yticks([])\n",
    "\n",
    "#ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "\n",
    "#ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax, ticks=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "#cbar.ax.set_xticklabels(['0.3', '0.4', '0.5', '0.6'])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig2c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f186688",
   "metadata": {},
   "source": [
    "# Fig.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdaad5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f'./result/baseline_complete_N15K7NN3_tot.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400_E550.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15631993",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "complete_sem_dict = {}\n",
    "for key in baseline_complete_dict.keys():\n",
    "    if key != 'keys':\n",
    "        result = []\n",
    "        np.mean(baseline_complete_dict[key]['scr_buf'])\n",
    "        complete_dict[conversion_dict1[key]] = [np.mean(baseline_complete_dict[key]['scr_buf']*100), \n",
    "                                                     np.mean(baseline_complete_dict[key]['scr_buf'][..., -1])*100]\n",
    "        complete_sem_dict[conversion_dict1[key]] = [np.std(np.mean(baseline_complete_dict[key]['scr_buf'], axis=(-2, -1)))/np.sqrt(5000)*100, \n",
    "                                                     np.std(np.mean(baseline_complete_dict[key]['scr_buf'][..., -1], axis=-1))/np.sqrt(5000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "    FinalScore_list.append(inspection_complete_dict['scr_buf_list'][i][:, :, -1])\n",
    "    \n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c6cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_dict['RL'] = [np.mean(Ret_list)*100, \n",
    "                       np.mean(FinalScore_list)*100]\n",
    "complete_sem_dict['RL'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(5000)*100, \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(5000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae10476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73d369",
   "metadata": {},
   "source": [
    "## Fig.3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e357a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./result/progress/progress_default.txt', sep = \"\\t\")\n",
    "y1 = ema(data['AvgRet'].values, 0.99) * 100\n",
    "y1_max = ema(data['MaxRet'].values, 0.999)\n",
    "y1_min = ema(data['MinRet'].values, 0.999)\n",
    "y2 = ema(data['Entropy'].values, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twinx() \n",
    "ax1.plot(y1, lw=2, c='#FC4F4F', label='Payoff')\n",
    "#ax1.plot(y1_max, lw=2, ls=(0, (5, 5)), c='#FC4F4F', alpha=0.5)\n",
    "#ax1.plot(y1_min, lw=2, ls=(0, (5, 5)), c='#FC4F4F', alpha=0.5)\n",
    "ax1.plot(data['AvgRet'].values*100, lw=1, alpha=0.3, c='#FC4F4F')\n",
    "ax2.plot(y2, lw=2, c='#5D8BF4', label='Entropy')\n",
    "ax2.plot(data['Entropy'].values, lw=1, alpha=0.3, c='#5D8BF4')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax2.set_ylabel('Entropy', fontsize=18)\n",
    "\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "ax2.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig3a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56280ad",
   "metadata": {},
   "source": [
    "## Fig.3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e399a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474'] \n",
    "counter=0\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "for baseline_name in order_dict:\n",
    "    if baseline_name == 'RL':\n",
    "        x = np.array([inspection_complete_dict['scr_buf_list'][i]*100 for i in range(len(inspection_complete_dict['scr_buf_list']))])\n",
    "        ls = '-'\n",
    "        lw = 3\n",
    "    else:\n",
    "        x = baseline_complete_dict[conversion_dict2[baseline_name]]['scr_buf']*100\n",
    "        ls = (0, (2, 1.5))\n",
    "        lw = 2\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name, ls=ls, lw=lw)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "ax.plot(np.arange(0), np.arange(0), ls=(0, (2, 1.5)), lw=2.5, c=color_list[counter], label='Baselines')\n",
    "ax.set_xlabel('Time', fontsize=18)\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [0, -1]\n",
    "#ax.legend(loc='lower right', fontsize=11, ncol=2)\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc=(0.4, 0.1), fontsize=14, ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig3b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096a286",
   "metadata": {},
   "source": [
    "## Fig.3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(6,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474']\n",
    "f = 0  # 0 : mean, 1 : final\n",
    "width = 0.1\n",
    "length = len(complete_dict)\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "offset[0] -= width/2\n",
    "\n",
    "for i in range(5):\n",
    "    offset[i] -= width/2\n",
    "\n",
    "for i in range(9, length):\n",
    "    offset[i] += width/2\n",
    "    \n",
    "offset[-1] += width/2\n",
    "\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], complete_dict[key][f], width, label=key, color = color_list[i], yerr = 5 * np.array(complete_sem_dict[key])[f])\n",
    "\n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_xticks([-width * 7, -width * 4, width / 2, width * 4.5, width * 7])\n",
    "ax.set_xticklabels(['RL', 'BI', 'CF', 'PI', 'RI'], fontsize=14)\n",
    "ax.set_yticks([0, 20, 40, 60, 80])\n",
    "ax.set_yticklabels(['0', '20', '40', '60', '80'], fontsize=14)\n",
    "#ax.set_xlim(-1, 2)\n",
    "#ax.legend(loc='lower right', ncol=3, fontsize=10)\n",
    "ax.set_xlim(-0.8, 1.2)\n",
    "ax.legend(loc='upper right', ncol=2, fontsize=12)\n",
    "best_baseline = 'BI-R'\n",
    "ax.hlines(complete_dict[best_baseline][f], offset[0]-width, offset[5], ls=(0, (3, 2)), color='#444444', lw=1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig3c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4808768",
   "metadata": {},
   "source": [
    "## Fig.3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d1aad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "#exp_name = 'test_test'\n",
    "epoch = 4500\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    print(ent)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)\n",
    "    #plt.savefig(f'./Fig2d_4.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da60557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small version\n",
    "\n",
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=0.8, cmap='viridis', origin='lower')\n",
    "#im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='plasma')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "#plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig3d_4a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency test\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "# complete_L200 2025\n",
    "# complete_L200_2 2269\n",
    "# complete_L300 2593\n",
    "# maxmc_L100 4483\n",
    "# maxmc_L200 3761\n",
    "graph_type = 'complete'\n",
    "#exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "#epoch = 900\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template_f1 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 0], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0, -1, 2 / neighbor_num],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0, -1, 2 / neighbor_num],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num]])\n",
    "\n",
    "template_f2 = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 0], \n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num],\n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 1 / neighbor_num]])\n",
    "\n",
    "template = template_f1\n",
    "\n",
    "for s in s_list:\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    mask = [True if ((tc[i][1]<tc[i][2]) and (tc[i][0]==tc[i][1])) else False for i in range(len(tc))]\n",
    "    tc = tc[mask]\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors_freq(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    #facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=0.8, cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "#plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#pl.gca().set_visible(False)\n",
    "plt.savefig('Fig3d_4b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e331b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=0.8, cmap='viridis')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.gca().set_visible(False)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax, ticks=[0.0, 0.4, 0.8])\n",
    "cbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "#cbar.ax.set_xticklabels(['0.3', '0.4', '0.5', '0.6'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig3d_colorbar.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5e721",
   "metadata": {},
   "source": [
    "# Fig.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [70]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400'\n",
    "#exp_name = 'test_test'\n",
    "epoch = 550\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    print(ent)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    #facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)\n",
    "    #plt.savefig(f'./Fig3b_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacee8f",
   "metadata": {},
   "source": [
    "## Fig. 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "#ax.set_yticks([0, 83140, 176851])\n",
    "#ax.set_yticklabels(['(50, 0, \\n0, 0)', '(50, 20, \\n20, 20)', '(50, 100, \\n100, 100)',], fontsize=14)\n",
    "#ax.set_yticklabels(['', '', ''])\n",
    "\n",
    "#ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "\n",
    "#ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig4a_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small version\n",
    "\n",
    "fig = plt.figure(figsize=(4, 2), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list[:101], aspect='auto', vmin=0, vmax=1.0, cmap='viridis', origin='lower')\n",
    "#im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='plasma')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.set_ylim(0, 101)\n",
    "#plt.axis('off')\n",
    "ax.hlines(70, -0.5, 10, lw=3, ls='--', color='w')\n",
    "ax.tick_params(axis = 'both', labelsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig4c_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3ae6d",
   "metadata": {},
   "source": [
    "# Fig. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxMC\n",
    "\n",
    "with open(f'./result/baseline_maxmc_N15K7NN3.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/inspection_dict_maxmc_E6250_maxmc.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L50R4\n",
    "\n",
    "with open(f'./result/baseline_complete_N15K7NN3_exp8_L50R4.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/inspection_dict_L50R4_E5200_L50R4.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59167e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L400\n",
    "\n",
    "with open(f'./result/baseline_complete_N15K3NN3_exp8_L400.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/inspection_dict_L400_E4300_L400.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN9\n",
    "\n",
    "with open(f'./result/XX.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/XX.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "complete_sem_dict = {}\n",
    "for key in baseline_complete_dict.keys():\n",
    "    if key != 'keys':\n",
    "        complete_dict[conversion_dict1[key]] = [np.mean(baseline_complete_dict[key]['scr_buf']*100), \n",
    "                                                     np.mean(baseline_complete_dict[key]['scr_buf'][..., -1])*100]\n",
    "        complete_sem_dict[conversion_dict1[key]] = [np.std(np.mean(baseline_complete_dict[key]['scr_buf'], axis=(-2, -1)))/np.sqrt(5000)*100, \n",
    "                                                     np.std(np.mean(baseline_complete_dict[key]['scr_buf'][..., -1], axis=-1))/np.sqrt(5000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list.append(inspection_complete_dict['scr_buf_list'][i]*100)\n",
    "    FinalScore_list.append(inspection_complete_dict['scr_buf_list'][i][:, :, -1]*100)\n",
    "\n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)\n",
    "\n",
    "complete_dict['RL'] = [np.mean(Ret_list), \n",
    "                       np.mean(FinalScore_list)]\n",
    "complete_sem_dict['RL'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(5000), \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5ce53",
   "metadata": {},
   "source": [
    "## Fig. 5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a931a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474'] \n",
    "counter=0\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "for baseline_name in order_dict:\n",
    "    if baseline_name == 'RL':\n",
    "        x = np.array([inspection_complete_dict['scr_buf_list'][i]*100 for i in range(len(inspection_complete_dict['scr_buf_list']))])\n",
    "        ls = '-'\n",
    "        lw = 3\n",
    "    else:\n",
    "        x = baseline_complete_dict[conversion_dict2[baseline_name]]['scr_buf']*100\n",
    "        ls = (0, (2, 1.5))\n",
    "        lw = 2\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name, ls=ls, lw=lw)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "ax.plot(np.arange(0), np.arange(0), ls=(0, (2, 1.5)), lw=2.5, c=color_list[counter], label='Baselines')\n",
    "\n",
    "ax.set_xlabel('Time', fontsize=18)\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [0, -1]\n",
    "#ax.legend(loc='lower right', fontsize=11, ncol=2)\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc=(0.4, 0.1), fontsize=14, ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig5c_1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0ddf8",
   "metadata": {},
   "source": [
    "## Fig. 5-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(6,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474']\n",
    "f = 0  # 0 : mean, 1 : final\n",
    "width = 0.1\n",
    "length = len(complete_dict)\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "offset[0] -= width/2\n",
    "\n",
    "for i in range(5):\n",
    "    offset[i] -= width/2\n",
    "\n",
    "for i in range(9, length):\n",
    "    offset[i] += width/2\n",
    "    \n",
    "offset[-1] += width/2\n",
    "\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], complete_dict[key][f], width, label=key, color = color_list[i], yerr = 5 * np.array(complete_sem_dict[key])[f])\n",
    "\n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_xticks([-width * 7, -width * 4, width / 2, width * 4.5, width * 7])\n",
    "ax.set_xticklabels(['RL', 'BI', 'CF', 'PI', 'RI'], fontsize=14)\n",
    "ax.set_yticks([0, 20, 40, 60, 80])\n",
    "ax.set_yticklabels(['0', '20', '40', '60', '80'], fontsize=14)\n",
    "#ax.set_xlim(-1, 2)\n",
    "#ax.legend(loc='lower right', ncol=3, fontsize=10)\n",
    "ax.set_xlim(-0.8, 1.3)\n",
    "ax.legend(loc='center right', ncol=1, fontsize=12)\n",
    "best_baseline = 'CF-I'\n",
    "ax.hlines(complete_dict[best_baseline][f], offset[0]-width, offset[7], ls=(0, (3, 2)), color='#444444', lw=1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig5c_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f5b57",
   "metadata": {},
   "source": [
    "## Fig.5-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca12c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "#exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L50R4'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L400'\n",
    "#exp_name = 'test_test'\n",
    "#epoch = 5200\n",
    "epoch = 4300\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    print(ent)\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s+1)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)\n",
    "    #plt.savefig(f'./Fig5b_3.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72cf89",
   "metadata": {},
   "source": [
    "## Fig.5-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335c73d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "#ax.set_yticks([0, 83140, 176851])\n",
    "#ax.set_yticklabels(['(50, 0, \\n0, 0)', '(50, 20, \\n20, 20)', '(50, 100, \\n100, 100)',], fontsize=14)\n",
    "#ax.set_yticklabels(['', '', ''])\n",
    "\n",
    "#ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "\n",
    "#ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig5c_4.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add55320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small version\n",
    "\n",
    "fig = plt.figure(figsize=(4, 2), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list[:101], aspect='auto', vmin=0, vmax=1.0, cmap='viridis', origin='lower')\n",
    "#im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='plasma')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.set_ylim(0, 100)\n",
    "#plt.axis('off')\n",
    "ax.hlines(50, -0.5, 10, lw=3, ls='--', color='w')\n",
    "ax.tick_params(axis = 'both', labelsize=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig4c_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e64cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small version\n",
    "\n",
    "fig = plt.figure(figsize=(2, 2), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "im = ax.imshow(pi_list[:100], aspect='auto', vmin=0, vmax=1.0, cmap='viridis', origin='lower')\n",
    "#im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='plasma')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.set_ylim(0, 100)\n",
    "#plt.axis('off')\n",
    "ax.hlines(50, -0.5, 10, lw=3, ls='--', color='w')\n",
    "ax.tick_params(axis = 'both', labelsize=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig4c_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cc57c",
   "metadata": {},
   "source": [
    "### props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from utils.utils import max_mean_clustering_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(100)\n",
    "fig = plt.figure(figsize=(4, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "nx.draw_networkx(G, pos = nx.nx_pydot.graphviz_layout(G), ax = ax, with_labels=False, \n",
    "                 node_size=30, node_color = '#0476D0',\n",
    "                width=1, edge_color='#0476D0', edgecolors='k')\n",
    "plt.axis('off')\n",
    "plt.savefig('complete_network.png', dpi=150, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ae314",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = max_mean_clustering_network(100)\n",
    "fig = plt.figure(figsize=(4, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "nx.draw_networkx(G, pos = nx.nx_pydot.graphviz_layout(G), ax = ax, with_labels=False, \n",
    "                 node_size=30, node_color = '#43B0F1',\n",
    "                width=1, edge_color='#43B0F1', edgecolors='k')\n",
    "plt.axis('off')\n",
    "plt.savefig('maxmc_network.png', dpi=150, transparent=True)\n",
    "# '#041F60', '#0476D0', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a572b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341fe72",
   "metadata": {},
   "source": [
    "# Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "exp_list = [('SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400', 550),\n",
    "           ('maxmc_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98', 6400),\n",
    "           ('SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L50R4', 5200),\n",
    "           ('SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L400', 4300)]\n",
    "\n",
    "zoom_list_dict = {'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400': np.zeros((101, 101, 15)),\n",
    "                 'maxmc_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98': np.zeros((101, 101, 15)),\n",
    "                 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L50R4': np.zeros((101, 101, 15)),\n",
    "                 'SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L400': np.zeros((101, 101, 15))}\n",
    "\n",
    "for exp_name, epoch in exp_list:\n",
    "    print(exp_name)\n",
    "    label = ''\n",
    "    rescale = False\n",
    "    extra_type = 'SIRF'\n",
    "    offset = 4\n",
    "    ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "    neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "    template = template_a1\n",
    "    template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "    \n",
    "    for s in range(0, 101):\n",
    "        print(s)\n",
    "        tc = coord_triplet(max_s+1)\n",
    "        data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "        tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "        if rescale:\n",
    "            data[:, :, -offset] = tc\n",
    "        else:\n",
    "            data[:, :, -offset] = tc / 100.\n",
    "\n",
    "        score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "        data[:, :, -2] = score_rank\n",
    "        ent = 0\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[:101], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        zoom_list_dict[exp_name][s] = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        \n",
    "with open('zoom_list_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(zoom_list_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_list_dict['SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6aa6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zoom_data = np.zeros((4, 4))\n",
    "for c, key in enumerate(zoom_list_dict):\n",
    "    zoom_list = zoom_list_dict[key]\n",
    "    lo, lb, uo, ub = 0., 0., 0., 0.\n",
    "    c1 = 5050 * 12.\n",
    "    c2 = 5050 * 3\n",
    "    for s in range(101):\n",
    "        if s != 0:\n",
    "            lo += np.sum(zoom_list[s, :s][..., [0, 1, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14]])\n",
    "            lb += np.sum(zoom_list[s, :s][..., [4, 5, 6]])\n",
    "        if s != 100:\n",
    "            uo += np.sum(zoom_list[s, s:][..., [0, 1, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14]])\n",
    "            ub += np.sum(zoom_list[s, s:][..., [4, 5, 6]])\n",
    "        \n",
    "    zoom_data[c] = [lo/c1, lb/c2, uo/c1, ub/c2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08454bf1",
   "metadata": {},
   "source": [
    "# Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9561c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1\n",
    "zoom_data = np.array([[0.40586082, 0.52620681, 0.06327645, 0.95621061],\n",
    "       [0.46419271, 0.52527308, 0.0420202 , 0.98633699],\n",
    "       [0.41291709, 0.51331983, 0.05412487, 0.9940865 ],\n",
    "       [0.46855582, 0.51602802, 0.065714  , 0.92687745]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(6,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color_list = ['#46244C', '#712B75', '#C74B50', '#D49B54']\n",
    "\n",
    "width = 0.1\n",
    "length = 16\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "    \n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "for i in range(4, length):\n",
    "    offset[i] += width/2\n",
    "    \n",
    "for i in range(8, length):\n",
    "    offset[i] += width\n",
    "    \n",
    "for i in range(12, length):\n",
    "    offset[i] += width/2\n",
    "    \n",
    "offset = np.array(offset).reshape(4, 4).T\n",
    "    \n",
    "order_dict = ['Plain', 'MaxMC', 'L50R4', 'K3L400']\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], zoom_data[i], width, label=key, color = color_list[i], )\n",
    "    \n",
    "ax.legend(loc='upper left', ncol=1, fontsize=10)\n",
    "ax.set_ylabel('Average model output', fontsize=18)\n",
    "ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.0', '0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=14)\n",
    "\n",
    "ax.set_xticks([-width * 6, -width * 1.5, width * 3.5, width * 8])\n",
    "ax.set_xticklabels(['I', 'II', 'III', 'IV'], fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig6a_1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d562e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2,2), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar([i], zoom_data[i, -1], 1, label=key, color = color_list[i])\n",
    "\n",
    "color_list = ['#46244C', '#712B75', '#C74B50', '#D49B54']\n",
    "ax.set_ylim(0.9, 1.0)\n",
    "ax.set_yticks([0.9, 1.0])\n",
    "ax.set_yticklabels(['0.9', '1.0'], fontsize=14)\n",
    "ax.set_xticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed22da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small version\n",
    "\n",
    "fig = plt.figure(figsize=(4, 2), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list_list[2][:100], aspect='auto', vmin=0, vmax=1.0, cmap='viridis', origin='lower')\n",
    "#im = ax.imshow(pi_list, aspect='auto', vmin=0, vmax=1, cmap='plasma')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.set_ylim(0, 100)\n",
    "#plt.axis('off')\n",
    "ax.hlines(50, -0.5, 14.5, lw=3, ls='--', color='w')\n",
    "\n",
    "ax.vlines(3.5, 0, 100, lw=3, ls='--', color='w')\n",
    "ax.vlines(6.5, 0, 100, lw=3, ls='--', color='w')\n",
    "ax.tick_params(axis = 'both', labelsize=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig4c_2.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/inspection_dict/inspection_dict_basic_E550_L50R4.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)\n",
    "complete_dict = {}\n",
    "complete_sem_dict = {}\n",
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "    FinalScore_list.append(inspection_complete_dict['scr_buf_list'][i][:, :, -1])\n",
    "    \n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)\n",
    "\n",
    "complete_dict['RL'] = [np.mean(Ret_list), \n",
    "                       np.mean(FinalScore_list)]\n",
    "complete_sem_dict['RL'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(5000), \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(5000)]\n",
    "complete_dict, complete_sem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic basic : 83.01\n",
    "maxmc basic : 81.4\n",
    "L50 basic : 81.78\n",
    "L400 basic : 82.7\n",
    "\n",
    "maxmc maxmc : 78.60\n",
    "basic maxmc : 77.73608\n",
    "L50 maxmc : 80.56\n",
    "L400 maxmc : 79.7\n",
    "\n",
    "basic L50 : 65.31\n",
    "maxmc L50 : 64.62\n",
    "L50 L50 : 65.144\n",
    "L400 L50 : 63.87\n",
    "    \n",
    "basic L400 : 95.3809\n",
    "maxmc L400 : 95.3043\n",
    "L50 L400 : 94.6618\n",
    "L400 L400 : 95.80624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "L50_data = np.array([[65.31], [64.62], [65.144], [63.877]])\n",
    "L50_sem_data = np.array([0.0009821489591534552, 0.0009412244746164983, 0.0009540506035553335, 0.0010379409552368722]) * 5 * 100\n",
    "L400_data = np.array([[95.3809], [95.3043], [94.6618], [95.80624]])\n",
    "L400_sem_data = np.array([0.0007140659212986966, 0.0008333406596475564, 0.000869253146326719, 0.0006401335001477053]) * 5 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ab77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list_1 = []\n",
    "Ret_list_2 = []\n",
    "with open('./result/inspection_dict/inspection_dict_L400_E4300_L50R4.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)\n",
    "    \n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list_1.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "\n",
    "Ret_list_1 = np.array(Ret_list_1)\n",
    "\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L50R4_E5200.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)\n",
    "    \n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list_2.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "\n",
    "Ret_list_2 = np.array(Ret_list_2)\n",
    "\n",
    "scipy.stats.ttest_ind(Ret_list_1.flatten(), Ret_list_2.flatten())  # p vlaue less than 0.001 (near zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(3, 3.2), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color_list = ['#46244C', '#712B75', '#C74B50', '#D49B54']\n",
    "\n",
    "width = 0.1\n",
    "length = 4\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "    \n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "offset = np.array(offset).reshape(1, 4).T\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], L50_data[i], width, color = color_list[i], yerr = L50_sem_data[i], capsize=3.0)\n",
    "    \n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_yticks([62, 64, 66])\n",
    "ax.set_yticklabels(['62', '64', '66'], fontsize=14)\n",
    "ax.set_ylim(62, 66.5)\n",
    "\n",
    "ax.set_xticks([0])\n",
    "ax.set_xticklabels(['L50R4'], fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig6b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list_1 = []\n",
    "Ret_list_2 = []\n",
    "with open('./result/inspection_dict/inspection_dict_L50R4_E5200_L400.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)\n",
    "    \n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list_1.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "\n",
    "Ret_list_1 = np.array(Ret_list_1)\n",
    "\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_L400_E4300.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)\n",
    "    \n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list_2.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "\n",
    "Ret_list_2 = np.array(Ret_list_2)\n",
    "\n",
    "scipy.stats.ttest_ind(Ret_list_1.flatten(), Ret_list_2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6660d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(3, 3.2), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color_list = ['#46244C', '#712B75', '#C74B50', '#D49B54']\n",
    "\n",
    "width = 0.1\n",
    "length = 4\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "    \n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "offset = np.array(offset).reshape(1, 4).T\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], L400_data[i], width, color = color_list[i], yerr = L400_sem_data[i], capsize=3.0)\n",
    "    \n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_yticks([94, 95, 96])\n",
    "ax.set_yticklabels(['94', '95', '96'], fontsize=14)\n",
    "ax.set_ylim(94, 96.5)\n",
    "\n",
    "ax.set_xticks([0])\n",
    "ax.set_xticklabels(['K3L400'], fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig6c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad750e78",
   "metadata": {},
   "source": [
    "# Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc288aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('./result/progress/progress_single.txt', sep = \"\\t\")\n",
    "data_2 = pd.read_csv('./result/progress/progress_full.txt', sep = \"\\t\")\n",
    "\n",
    "y1_1 = ema(data_1['AvgRet'].values, 0.99) * 100\n",
    "y1_2 = ema(data_2['AvgRet'].values, 0.99) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax1.plot(y1_1, lw=2, c='#5D8BF4', label='1 landscape')\n",
    "#ax1.plot(y1_2, lw=2, c='#FC4F4F', label='10 landscapes')\n",
    "ax1.plot(data_1['AvgRet'].values*100, lw=1, alpha=1, c='#5D8BF4', label='1 landscape')\n",
    "ax1.plot(data_2['AvgRet'].values*100, lw=1, alpha=1, c='#FC4F4F', label='10 landscapes')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax1.set_ylim(0, 105)\n",
    "ax1.set_xlim(-50, 1000)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.4), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS1a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_single'\n",
    "#exp_name = 'test_test'\n",
    "epoch = 1000\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bc740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS1b1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_full_E1100_random.pkl', 'rb') as f:\n",
    "    inspection_complete_dict_1 = pickle.load(f)\n",
    "\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_full_E1100_multi.pkl', 'rb') as f:\n",
    "    inspection_complete_dict_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2600bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_complete_dict_1['scr_buf_list'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "complete_sem_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00974060",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    Ret_list.append(inspection_complete_dict_1['scr_buf_list'][i])\n",
    "    FinalScore_list.append(inspection_complete_dict_1['scr_buf_list'][i][:, :, -1])\n",
    "\n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171755a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_dict['RL1'] = [np.mean(Ret_list)*100, \n",
    "                       np.mean(FinalScore_list)*100]\n",
    "complete_sem_dict['RL1'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(1000)*100, \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(1000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7207d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    Ret_list.append(inspection_complete_dict_2['scr_buf_list'][i])\n",
    "    FinalScore_list.append(inspection_complete_dict_2['scr_buf_list'][i][:, :, -1])\n",
    "    \n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict['RL2'] = [np.mean(Ret_list)*100, \n",
    "                       np.mean(FinalScore_list)*100]\n",
    "complete_sem_dict['RL2'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(1000)*100, \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(1000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35beda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474'] \n",
    "counter=0\n",
    "order_dict = ['RL1', 'RL2']\n",
    "ls = '-'\n",
    "lw = 3\n",
    "\n",
    "x = np.array([inspection_complete_dict_1['scr_buf_list'][i]*100 for i in range(len(inspection_complete_dict_1['scr_buf_list']))])\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='#151D3B', label='Random enrivonment', ls=ls, lw=lw)\n",
    "\n",
    "x = np.array([inspection_complete_dict_2['scr_buf_list'][i]*100 for i in range(len(inspection_complete_dict_2['scr_buf_list']))])\n",
    "avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "ax.plot(np.arange(x.shape[-1]), avg_pf, c='#747474', label='Trained environment', ls=ls, lw=lw)\n",
    "\n",
    "ax.set_xlabel('Time', fontsize=18)\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [0, -1]\n",
    "#ax.legend(loc='lower right', fontsize=11, ncol=2)\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc=(0.15, 0.5), fontsize=12, ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS1c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d63a0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(3,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "color_list = ['#151D3B', '#747474']\n",
    "f = 0  # 0 : mean, 1 : final\n",
    "width = 0.1\n",
    "length = len(complete_dict)\n",
    "\n",
    "offset = [0, 0]\n",
    "offset[0] = -width * 0.5\n",
    "offset[1] = width * 0.5\n",
    "\n",
    "order_dict = ['RL1', 'RL2']\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], complete_dict[key][f], width, label=key, color = color_list[i], yerr = 5 * np.array(complete_sem_dict[key])[f])\n",
    "\n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([0, 20, 40, 60, 80])\n",
    "ax.set_yticklabels(['0', '20', '40', '60', '80'], fontsize=14)\n",
    "#ax.set_xlim(-1, 2)\n",
    "#ax.legend(loc='lower right', ncol=3, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS1d.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60c1a5",
   "metadata": {},
   "source": [
    "# Figure S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70410316",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('./result/progress/progress_pop.txt', sep = \"\\t\")\n",
    "data_2 = pd.read_csv('./result/progress/progress_default.txt', sep = \"\\t\")\n",
    "\n",
    "y1_1 = ema(data_1['AvgRet'].values, 0.99) * 100\n",
    "y1_2 = ema(data_2['AvgRet'].values, 0.99) * 100\n",
    "y2_1 = ema(data_1['Entropy'].values, 0.99)\n",
    "y2_2 = ema(data_2['Entropy'].values, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699deea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y1_1, lw=2, c='#5D8BF4', label='Group-averaged reward')\n",
    "ax1.plot(y1_2, lw=2, c='#FC4F4F', label='Individual reward (default)')\n",
    "ax1.plot(data_1['AvgRet'].values*100, lw=1, alpha=0.3, c='#5D8BF4')\n",
    "ax1.plot(data_2['AvgRet'].values*100, lw=1, alpha=0.3, c='#FC4F4F')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS2a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y2_1, lw=2, c='#5D8BF4', label='Group-averaged reward')\n",
    "ax1.plot(y2_2, lw=2, c='#FC4F4F', label='Individual reward (default)')\n",
    "ax1.plot(data_1['Entropy'].values, lw=1, alpha=0.3, c='#5D8BF4')\n",
    "ax1.plot(data_2['Entropy'].values, lw=1, alpha=0.3, c='#FC4F4F')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Entropy', fontsize=18)\n",
    "#ax1.set_ylim(0, 100)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS2b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda3b8b",
   "metadata": {},
   "source": [
    "# Figure S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36947e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = ['', '1', '2', '3', '4']\n",
    "default_list = []\n",
    "SIR_list = []\n",
    "default_ema_list = []\n",
    "SIR_ema_list = []\n",
    "for i, s in enumerate(suffix):\n",
    "    default_list.append(pd.read_csv(f'./result/progress/progress_default{s}.txt', sep = \"\\t\"))\n",
    "    SIR_list.append(pd.read_csv(f'./result/progress/progress_SIR{s}.txt', sep = \"\\t\"))\n",
    "    default_ema_list.append(ema(default_list[i]['AvgRet'].values, 0.99) * 100)\n",
    "    SIR_ema_list.append(ema(SIR_list[i]['AvgRet'].values, 0.99) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = np.inf\n",
    "for e in default_ema_list:\n",
    "    length = np.shape(e)[0]\n",
    "    print(length)\n",
    "    min_len = length if length < min_len else min_len \n",
    "for e in SIR_ema_list:\n",
    "    length = np.shape(e)[0]\n",
    "    print(length)\n",
    "    min_len = length if length < min_len else min_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    default_ema_list[i] = default_ema_list[i][:min_len]\n",
    "    SIR_ema_list[i] = SIR_ema_list[i][:min_len]\n",
    "    \n",
    "default_ema_array = np.vstack(default_ema_list)\n",
    "SIR_ema_array = np.vstack(SIR_ema_list)\n",
    "default_avg = np.mean(default_ema_array, axis=0)\n",
    "SIR_avg = np.mean(SIR_ema_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "for i in range(5):\n",
    "    ax1.plot(SIR_ema_array[i], lw=1, c='#5D8BF4', alpha=0.3)\n",
    "    ax1.plot(default_ema_array[i], lw=1, c='#FC4F4F', alpha=0.3)\n",
    "\n",
    "ax1.plot(SIR_avg, lw=2, c='#5D8BF4', label='PIR (no ranking & frequency)')\n",
    "ax1.plot(default_avg, lw=2, c='#FC4F4F', label='PIRF (default)')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "#ax1.set_ylim(0, 100)\n",
    "ax1.set_xlim(1500, 2700)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS3.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a62abd",
   "metadata": {},
   "source": [
    "# Figure S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('./result/progress/progress_SI.txt', sep = \"\\t\")\n",
    "data_2 = pd.read_csv('./result/progress/progress_default.txt', sep = \"\\t\")\n",
    "\n",
    "y1_1 = ema(data_1['AvgRet'].values, 0.99) * 100\n",
    "y1_2 = ema(data_2['AvgRet'].values, 0.99) * 100\n",
    "y2_1 = ema(data_1['Entropy'].values, 0.99)\n",
    "y2_2 = ema(data_2['Entropy'].values, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c150a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y1_1, lw=2, c='#5D8BF4', label='PI (no ranking & frequency)')\n",
    "ax1.plot(y1_2, lw=2, c='#FC4F4F', label='PIRF (default)')\n",
    "ax1.plot(data_1['AvgRet'].values*100, lw=1, alpha=0.3, c='#5D8BF4')\n",
    "ax1.plot(data_2['AvgRet'].values*100, lw=1, alpha=0.3, c='#FC4F4F')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS4a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1885799",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y2_1, lw=2, c='#5D8BF4', label='PI (no ranking & frequency)')\n",
    "ax1.plot(y2_2, lw=2, c='#FC4F4F', label='PIRF (default)')\n",
    "ax1.plot(data_1['Entropy'].values, lw=1, alpha=0.3, c='#5D8BF4')\n",
    "ax1.plot(data_2['Entropy'].values, lw=1, alpha=0.3, c='#FC4F4F')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Entropy', fontsize=18)\n",
    "#ax1.set_ylim(0, 100)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.25), bbox_transform=ax1.transAxes, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS4b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d49a8",
   "metadata": {},
   "source": [
    "# Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('./result/progress/progress_K11.txt', sep = \"\\t\")\n",
    "data_2 = pd.read_csv('./result/progress/progress_E1000K11.txt', sep = \"\\t\")\n",
    "data_3 = pd.read_csv('./result/progress/progress_E2500K11.txt', sep = \"\\t\")\n",
    "data_4 = pd.read_csv('./result/progress/progress_E5500K11.txt', sep = \"\\t\")\n",
    "\n",
    "y1_1 = ema(data_1['AvgRet'].values, 0.99) * 100\n",
    "y2_1 = ema(data_1['Entropy'].values, 0.99)\n",
    "y1_2 = ema(data_2['AvgRet'].values, 0.99) * 100\n",
    "y2_2 = ema(data_2['Entropy'].values, 0.99)\n",
    "y1_3 = ema(data_3['AvgRet'].values, 0.99) * 100\n",
    "y2_3 = ema(data_3['Entropy'].values, 0.99)\n",
    "y1_4 = ema(data_4['AvgRet'].values, 0.99) * 100\n",
    "y2_4 = ema(data_4['Entropy'].values, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [ '#D49B54', '#46244C', '#712B75', '#C74B50',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y1_1, lw=2, c=color_list[0], label='K11')\n",
    "ax1.plot(y1_2, lw=2, c=color_list[1], label='K3K11(E1000)')\n",
    "ax1.plot(y1_3, lw=2, c=color_list[2], label='K3K11(E2500)')\n",
    "ax1.plot(y1_4, lw=2, c=color_list[3], label='K3K11(E5500)')\n",
    "ax1.plot(data_1['AvgRet'].values*100, lw=1, alpha=0.2, c=color_list[0])\n",
    "ax1.plot(data_2['AvgRet'].values*100, lw=1, alpha=0.2, c=color_list[1])\n",
    "ax1.plot(data_3['AvgRet'].values*100, lw=1, alpha=0.2, c=color_list[2])\n",
    "ax1.plot(data_4['AvgRet'].values*100, lw=1, alpha=0.2, c=color_list[3])\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.7), bbox_transform=ax1.transAxes, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS5a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=300)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(y2_1, lw=2, c=color_list[0], label='K11')\n",
    "ax1.plot(y2_2, lw=2, c=color_list[1], label='K3K11(E1000)')\n",
    "ax1.plot(y2_3, lw=2, c=color_list[2], label='K3K11(E2500)')\n",
    "ax1.plot(y2_4, lw=2, c=color_list[3], label='K3K11(E5500)')\n",
    "ax1.plot(data_1['Entropy'].values, lw=1, alpha=0.2, c=color_list[0])\n",
    "ax1.plot(data_2['Entropy'].values, lw=1, alpha=0.2, c=color_list[1])\n",
    "ax1.plot(data_3['Entropy'].values, lw=1, alpha=0.2, c=color_list[2])\n",
    "ax1.plot(data_4['Entropy'].values, lw=1, alpha=0.2, c=color_list[3])\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=18)\n",
    "ax1.set_ylabel('Entropy', fontsize=18)\n",
    "ax1.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(0.98, 0.7), bbox_transform=ax1.transAxes, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS5b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/baseline_complete_N15K11NN3_tot.pkl', 'rb') as f:\n",
    "    baseline_complete_dict = pickle.load(f)\n",
    "with open('./result/inspection_dict/inspection_dict_SIRF_TT_gene_ent_EC0.003_N15K3NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E2500K11_E4200.pkl', 'rb') as f:\n",
    "    inspection_complete_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b39e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "complete_sem_dict = {}\n",
    "for key in baseline_complete_dict.keys():\n",
    "    if key != 'keys':\n",
    "        result = []\n",
    "        np.mean(baseline_complete_dict[key]['scr_buf'])\n",
    "        complete_dict[conversion_dict1[key]] = [np.mean(baseline_complete_dict[key]['scr_buf']*100), \n",
    "                                                     np.mean(baseline_complete_dict[key]['scr_buf'][..., -1])*100]\n",
    "        complete_sem_dict[conversion_dict1[key]] = [np.std(np.mean(baseline_complete_dict[key]['scr_buf'], axis=(-2, -1)))/np.sqrt(5000)*100, \n",
    "                                                     np.std(np.mean(baseline_complete_dict[key]['scr_buf'][..., -1], axis=-1))/np.sqrt(5000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ret_list = []\n",
    "FinalScore_list = []\n",
    "\n",
    "for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "    Ret_list.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "    FinalScore_list.append(inspection_complete_dict['scr_buf_list'][i][:, :, -1])\n",
    "    \n",
    "Ret_list = np.array(Ret_list)\n",
    "FinalScore_list = np.array(FinalScore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_dict['RL'] = [np.mean(Ret_list)*100, \n",
    "                       np.mean(FinalScore_list)*100]\n",
    "complete_sem_dict['RL'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(5000)*100, \n",
    "                           np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(5000)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb2bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474'] \n",
    "counter=0\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "for baseline_name in order_dict:\n",
    "    if baseline_name == 'RL':\n",
    "        x = np.array([inspection_complete_dict['scr_buf_list'][i]*100 for i in range(len(inspection_complete_dict['scr_buf_list']))])\n",
    "        ls = '-'\n",
    "        lw = 3\n",
    "    else:\n",
    "        x = baseline_complete_dict[conversion_dict2[baseline_name]]['scr_buf']*100\n",
    "        ls = (0, (2, 1.5))\n",
    "        lw = 2\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name, ls=ls, lw=lw)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "ax.plot(np.arange(0), np.arange(0), ls=(0, (2, 1.5)), lw=2.5, c=color_list[counter], label='Baselines')\n",
    "\n",
    "ax.set_xlabel('Time', fontsize=18)\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.tick_params(axis = 'both', labelsize=14)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [0, -1]\n",
    "#ax.legend(loc='lower right', fontsize=11, ncol=2)\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc=(0.4, 0.1), fontsize=14, ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS5c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95331dfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(6,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "color_list = ['#151D3B', \n",
    "              '#98042D', '#FF0F39', '#F16745', '#FFC65D',  \n",
    "              '#3A6351', '#019267', '#00C897', '#85C88A',  \n",
    "              '#495371', '#488FB1', '#2FA4FF',  \n",
    "              '#8267BE', '#747474']\n",
    "f = 0  # 0 : mean, 1 : final\n",
    "width = 0.1\n",
    "length = len(complete_dict)\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i * width for i in range(length)]\n",
    "\n",
    "offset[0] -= width/2\n",
    "\n",
    "for i in range(5):\n",
    "    offset[i] -= width/2\n",
    "\n",
    "for i in range(9, length):\n",
    "    offset[i] += width/2\n",
    "    \n",
    "offset[-1] += width/2\n",
    "\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(offset[i], complete_dict[key][f], width, label=key, color = color_list[i], yerr = 5 * np.array(complete_sem_dict[key])[f])\n",
    "\n",
    "ax.set_ylabel('Average Mean Payoff', fontsize=18)\n",
    "ax.set_xticks([-width * 7, -width * 4, width / 2, width * 4.5, width * 7])\n",
    "ax.set_xticklabels(['RL', 'BI', 'CF', 'PI', 'RI'], fontsize=14)\n",
    "ax.set_yticks([0, 20, 40, 60, 80])\n",
    "ax.set_yticklabels(['0', '20', '40', '60', '80'], fontsize=14)\n",
    "#ax.set_xlim(-1, 2)\n",
    "#ax.legend(loc='lower right', ncol=3, fontsize=10)\n",
    "ax.set_xlim(-0.8, 1.3)\n",
    "ax.legend(loc='center right', ncol=1, fontsize=12)\n",
    "best_baseline = 'BI-R'\n",
    "ax.hlines(complete_dict[best_baseline][f], offset[0]-width, offset[7], ls=(0, (3, 2)), color='#444444', lw=1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('FigS5d.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9b338",
   "metadata": {},
   "source": [
    "# Figure S6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/OLP_updated.pickle', 'rb') as f:\n",
    "    real_network = pickle.load(f)\n",
    "\n",
    "candidate = {}\n",
    "max_node_threshold = 1200\n",
    "\n",
    "for network_index in (real_network.network_index):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==network_index]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    if graph2.number_of_nodes() > 0:\n",
    "        if nx.is_connected(graph2) and graph2.number_of_nodes()/graph.number_of_nodes() > 0.95:\n",
    "            candidate[network_index] = graph2.number_of_nodes()\n",
    "\n",
    "network_data = real_network[np.isin(real_network['network_index'], list(candidate.keys()))]\n",
    "network_filter = np.logical_and(network_data['networkDomain'] == 'Social', network_data['number_nodes'].values < max_node_threshold )\n",
    "network_data = network_data[network_filter]\n",
    "network_index = network_data.network_index.values\n",
    "network_nodes = [candidate[i] for i in network_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa387d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_diameter = []\n",
    "for i in network_index:\n",
    "    print(i)\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from([tuple(x) for x in real_network[real_network['network_index']==i]['edges_id'].values[0]]) # add weights to the edges\n",
    "    graph2 = nx.k_core(graph, k=3)\n",
    "    network_diameter.append(nx.algorithms.distance_measures.diameter(graph2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict merger\n",
    "for i in range(51):\n",
    "    with open(f'./result/real_network_{i}_base.pkl', 'rb') as f:\n",
    "        data1 = pickle.load(f)\n",
    "    with open(f'./result/real_network_{i}_base2.pkl', 'rb') as f:\n",
    "        data2 = pickle.load(f)\n",
    "\n",
    "    data1.pop('50SF', None)\n",
    "    data1.pop('50SF80', None)\n",
    "    with open(f'./result/real_network_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump({**data1, **data2}, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743192db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(39, 51):\n",
    "    os.rename(f'./result/real_network_{i}-DESKTOP-ML3251C.pkl', f'./result/real_network_{i}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 53\n",
    "baseline_names = ['BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "\n",
    "avg_pf_dict = {names:np.zeros(200) for names in baseline_names}\n",
    "avg_pf_dict['RL'] = np.zeros(200)\n",
    "mean_dict = {}\n",
    "sem_dict = {}\n",
    "\n",
    "for ci in range(cutoff):\n",
    "    if ci != 38:\n",
    "        print(ci)\n",
    "        mean_dict[ci] = {}\n",
    "        sem_dict[ci] = {}\n",
    "        with open(f'./result/real_network_{ci}.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            data_RL = data['RL']\n",
    "        for baseline_name in baseline_names:\n",
    "            x = data[conversion_dict2[baseline_name]]['scr_buf']\n",
    "            avg_pf_dict[baseline_name] += np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "            mean_dict[ci][baseline_name] = [np.mean(x), np.mean(x[..., -1])]\n",
    "            sem_dict[ci][baseline_name] = [np.std(x, axis=(-2, -1))/np.sqrt(100), np.std(x[..., -1], axis=-1)/np.sqrt(100)]\n",
    "\n",
    "        x = np.array([data_RL['scr_buf_list'][i] for i in range(len(data_RL['scr_buf_list']))])\n",
    "        avg_pf_dict['RL'] += np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "\n",
    "        Ret_list = []\n",
    "        FinalScore_list = []\n",
    "\n",
    "        for i in range(len(inspection_complete_dict['scr_buf_list'])):\n",
    "            Ret_list.append(inspection_complete_dict['scr_buf_list'][i])\n",
    "            FinalScore_list.append(inspection_complete_dict['scr_buf_list'][i][:, :, -1])\n",
    "\n",
    "        Ret_list = np.array(Ret_list)\n",
    "        FinalScore_list = np.array(FinalScore_list)\n",
    "\n",
    "        mean_dict[ci]['RL'] = [np.mean(Ret_list), \n",
    "                               np.mean(FinalScore_list)]\n",
    "        sem_dict[ci]['RL'] = [np.std(np.mean(Ret_list, axis=(-2, -1)))/np.sqrt(100), \n",
    "                                   np.std(np.mean(FinalScore_list, axis=-1))/np.sqrt(100)]\n",
    "        del data, data_RL\n",
    "\n",
    "for key in avg_pf_dict:\n",
    "    avg_pf_dict[key] /= (cutoff-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a746ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RL['scr_buf_list'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['Average', 'Final']\n",
    "color_list = ['#FF0F39', '#0476D0', '#F16745', '#FFC65D', '#7BC8A4', '#4CC3D9', '#93648D', '#747474'] \n",
    "center  = np.array([0., 3.])\n",
    "width = 0.175\n",
    "length = len(avg_pf_dict)\n",
    "\n",
    "if length%2: \n",
    "    start = -(length//2)*width\n",
    "else: \n",
    "    start = -((length//2)-0.5)*width\n",
    "offset = [start + i * width for i in range(length)]\n",
    "offset[0] -= width/2\n",
    "offset[1] -= width/2\n",
    "\n",
    "order_dict = ['RL', 'BI', 'BI-I', 'BI-P', 'BI-R', 'CF', 'CF-I', 'CF-P', 'CF-R',  'PI-I', 'PI-P', 'PI-R', 'RI']\n",
    "\n",
    "for i, key in enumerate(order_dict):\n",
    "    ax.bar(center+offset[i], complete_dict[key], width, label=key, color = color_list[i], yerr = 2*np.array(complete_sem_dict[key]))\n",
    "#BI_rect = ax.bar(x - width/2, con, width, label='CN', color = 'salmon')\n",
    "#BI_rect = ax.bar(x + width/2, siam, width, label='SNN', color = 'skyblue')\n",
    "\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.set_xticks(center-width/2)\n",
    "ax.set_xticklabels(labels, fontsize=18)\n",
    "ax.tick_params(axis = 'y', labelsize=12)\n",
    "ax.legend(loc=8, ncol=2, fontsize=10) #8\n",
    "best_baseline = 'BI-I'\n",
    "ax.hlines(complete_dict[best_baseline][0], center[0] + offset[0]-width, center[0] + offset[5], ls=(0, (3, 2)), color='#444444', lw=1.5)\n",
    "ax.hlines(complete_dict[best_baseline][1], center[1] + offset[0]-width, center[1] + offset[5], ls=(0, (3, 2)), color='#444444', lw=1.5)\n",
    "fig.tight_layout()\n",
    "plt.savefig('Fig7a.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "for baseline_name in baseline_names:\n",
    "    result = []\n",
    "    for i in stat_dict.keys():\n",
    "        if stat_dict[i]:\n",
    "            result.append(stat_dict[i][baseline_name])\n",
    "    result = np.mean(np.array(result), axis=0)\n",
    "    complete_dict[baseline_name] = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac4469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183e261",
   "metadata": {},
   "source": [
    "### props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347935f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from utils.utils import max_mean_clustering_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = real_network(network_data, network_index=network_index.flatten()[1])\n",
    "c = [*list(np.array([139, 205, 80])/256), 0.5]\n",
    "fig = plt.figure(figsize=(4, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "nx.draw_networkx(G, pos = nx.nx_pydot.graphviz_layout(G, prog='neato'), ax = ax, with_labels=False, \n",
    "                 node_size=30, node_color=c,\n",
    "                width=1, edge_color=c, edgecolors='k', linewidths=1)\n",
    "plt.axis('off')\n",
    "plt.savefig('Fig4p1.png', dpi=150, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OLP_updated.pickle', 'rb') as f:\n",
    "    real_network_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccf29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = max_mean_clustering_network(100)\n",
    "fig = plt.figure(figsize=(4, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "nx.draw_networkx(G, pos = nx.nx_pydot.graphviz_layout(G), ax = ax, with_labels=False, \n",
    "                 node_size=30, node_color = '#43B0F1',\n",
    "                width=1, edge_color='#43B0F1', edgecolors='k')\n",
    "plt.axis('off')\n",
    "plt.savefig('maxmc_network.png', dpi=150, transparent=True)\n",
    "# '#041F60', '#0476D0', "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab19f80",
   "metadata": {},
   "source": [
    "## Figure S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_full'\n",
    "epoch = 1100\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_a1\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    sp = template[0][:-offset]\n",
    "    cp = template[-2][:-offset]\n",
    "    hp = template[-1][:-offset]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8f9b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('FigS1b1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ddb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SIRF\n",
    "max_s = 100\n",
    "s_list = [50]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'complete'\n",
    "#exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98_cp_E5400'\n",
    "exp_name = 'test_test'\n",
    "epoch = 1200\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SIRF'\n",
    "offset = 4\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "neighbor_num = env_kwargs['neighbor_num']\n",
    "\n",
    "template = template_c2\n",
    "template = np.c_[template, np.array([[-1, 0], [-1, 3 / neighbor_num], [-1, 3 / neighbor_num], [-1, 3 / neighbor_num]])]\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s+1)\n",
    "    mask = [True if ((tc[i][1]==tc[i][2]) and (tc[i][0]==tc[i][1])) else False for i in range(len(tc))]\n",
    "    tc = tc[mask]\n",
    "    data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -offset] = tc\n",
    "    else:\n",
    "        data[:, :, -offset] = tc / 100.\n",
    "        \n",
    "    score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "    data[:, :, -2] = score_rank\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5, 4), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(pi_list, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13])\n",
    "ax.set_xticklabels(['Self', 'Best', 'Second', 'Third'], fontsize=14)\n",
    "\n",
    "ax.set_yticks([])\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('FigS1b1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e269d",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001404a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEtest\n",
    "s = 50\n",
    "max_s = 100\n",
    "epoch = ''\n",
    "\n",
    "exp_name = 'st_complete_total_FollowBest_SI_N15K7NN3_CE_sptest'\n",
    "seed=42\n",
    "rel_path = f'data/runs/{exp_name}/{exp_name}_s{seed}/'\n",
    "checkpoint = torch.load(rel_path+f'pyt_save/model{epoch}.pth')\n",
    "ac_kwargs = {}\n",
    "ac_kwargs['activation'] = nn.Tanh()\n",
    "ac = core.ActorCritic(obs_dim, act_dim, 'st', **ac_kwargs)\n",
    "\n",
    "print(epoch)\n",
    "\n",
    "template = np.array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1], \n",
    "          [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, -1, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, -1, 0]])\n",
    "\n",
    "tc = coord_triplet(max_s)\n",
    "data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0)\n",
    "tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "data[:, :, -2] = tc\n",
    "pi_list = []\n",
    "\n",
    "for i in range((data.shape[0]//10000)+1):\n",
    "    a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "    x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "    pi_list.append(x)\n",
    "pi_list = np.concatenate(pi_list, axis=0)\n",
    "fp = fixed_point(ac)\n",
    "sp = template[0][:-2]\n",
    "hp = template[-1][:-2]\n",
    "facecolors, fp_dist, sp_dist, hp_dist = assign_facecolors(pi_list, fp, sp, hp, True, False, True, max_s)\n",
    "stride = 5\n",
    "assert max_s%stride == 0\n",
    "facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "#plot_cube(facecolors, stride = stride, angle=-75, name = f'complete_e{epoch}_s{s}', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b63f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self score, SI\n",
    "\n",
    "max_s = 100\n",
    "s_list = [30]\n",
    "%matplotlib inline\n",
    "\n",
    "graph_type = 'maxmc'\n",
    "exp_name = 'test_test'\n",
    "epoch = 5400\n",
    "label = ''\n",
    "rescale = False\n",
    "extra_type = 'SI'\n",
    "ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "\n",
    "template = template_a1\n",
    "print(template)\n",
    "\n",
    "for s in s_list:\n",
    "    print(s)\n",
    "    tc = coord_triplet(max_s)\n",
    "    data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0).astype(np.float)\n",
    "    tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "    if rescale:\n",
    "        data[:, :, -2] = tc\n",
    "    else:\n",
    "        data[:, :, -2] = tc / 100.\n",
    "    pi_list = []\n",
    "    ent = 0\n",
    "    for i in range((data.shape[0]//10000)+1):\n",
    "        a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "        x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "        ent += pi.entropy().sum()\n",
    "        pi_list.append(x)\n",
    "        #print(x, pi.entropy().sum())\n",
    "    pi_list = np.concatenate(pi_list, axis=0)\n",
    "    ent /= data.shape[0] * 15\n",
    "    print(ent)\n",
    "    sp = template[0][:-2]\n",
    "    cp = template[-2][:-2]\n",
    "    hp = template[-1][:-2]\n",
    "    facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s)\n",
    "    stride = 5\n",
    "    assert max_s%stride == 0\n",
    "    facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "    #plot_cube(facecolors, stride = stride, angle=-75, name = f'{graph_type}_e{epoch}_s{s}_{label}', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merger of two dictionary\n",
    "score_list = ['Ret', 'FinalScore']\n",
    "for i in range(2,15):\n",
    "    print(i)\n",
    "    with open(f'./result/baseline_complete_N15K{i}NN3.pkl', 'rb') as f:\n",
    "        baseline_complete_dict = pickle.load(f)\n",
    "    with open(f'./result/baseline_complete_N15K{i}NN3_exp8_add.pkl', 'rb') as f:\n",
    "        baseline_complete_dict2 = pickle.load(f)\n",
    "    for key1 in baseline_complete_dict.keys():\n",
    "        if key1 != 'keys':\n",
    "            print(key1)\n",
    "            for key2 in baseline_complete_dict[key1]:\n",
    "                if key2 in score_list:\n",
    "                    baseline_complete_dict[key1][key2] = baseline_complete_dict[key1][key2] * 0.4 + baseline_complete_dict2[key1][key2] * 0.6\n",
    "                    print(f'{key2}:{baseline_complete_dict[key1][key2]}')\n",
    "                else:\n",
    "                    baseline_complete_dict[key1][key2] = np.r_[baseline_complete_dict[key1][key2], baseline_complete_dict2[key1][key2]]\n",
    "                    \n",
    "    with open(f'./result/baseline_complete_N15K{i}NN3_tot.pkl', 'wb') as f:\n",
    "        pickle.dump(baseline_complete_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    del baseline_complete_dict, baseline_complete_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## p1/p2\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "im_data = facecolors[0].transpose(1, 0, 2)\n",
    "#im_data[..., -1] *= 2\n",
    "ax.imshow(im_data, origin='lower', extent=[0, 100, 0, 100])\n",
    "ax.set_xlabel(r'$p_2$', fontsize=30, labelpad=-70)\n",
    "ax.set_ylabel(r'$p_1$', fontsize=30, labelpad=-85)\n",
    "ax.set_xticks([0, 50, 100])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "#ax.set_yticks(np.arange(0, 100, 10))\n",
    "ax.tick_params(axis = 'x', labelsize=24)\n",
    "ax.tick_params(axis = 'y', labelsize=24)\n",
    "#ax.vlines(50, 30, 100, lw=2, color='r', ls='--')\n",
    "#ax.hlines(80, 0, 70, lw=2, color='darkblue', ls='--')\n",
    "#ax.annotate(r'$\\alpha = 50$', (55, 35), fontsize=24, color='r')\n",
    "#ax.annotate(r'$\\beta = 80$', (5, 87), fontsize=24, color='darkblue')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig2f_1.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791069e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#F16745', '#FFC65D', '#7BC8A4', '#4CC3D9', '#93648D', '#747474', '#FF0F39', '#0476D0']  \n",
    "counter=0\n",
    "order_dict = ['CF-I', 'BI-I', 'PI', 'RI', 'BI', 'CF', 'RLI-C', 'RLI-M']\n",
    "for baseline_name in order_dict:\n",
    "    result = []\n",
    "    for i in avg_pf_dict.keys():\n",
    "        result.append(avg_pf_dict[i][baseline_name])\n",
    "    x = np.mean(np.array(result), axis=0)\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    if baseline_name == 'RLI-C' or baseline_name== 'RLI-M':\n",
    "        ls = '-'\n",
    "        lw = 3\n",
    "    else:\n",
    "        ls = (0, (2, 1.5))\n",
    "        lw = 2\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], label=baseline_name, lw=lw, ls=ls)\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.1)\n",
    "    counter+=1\n",
    "\n",
    "ax.set_xlabel('Time', fontsize=18)\n",
    "ax.set_ylabel('Mean Payoff', fontsize=18)\n",
    "ax.tick_params(axis = 'both', labelsize=12)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [6, 7, 0, 1, 2, 3, 4, 5]\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], fontsize=10, ncol=2,loc=4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig4b.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict = {}\n",
    "for baseline_name in baseline_names:\n",
    "    result = []\n",
    "    for i in stat_dict.keys():\n",
    "        result.append(stat_dict[i][baseline_name])\n",
    "    result = np.mean(np.array(result), axis=0)\n",
    "    complete_dict[baseline_name] = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#F16745', '#0476D0', '#FFC65D']\n",
    "order_dict = ['RLI-C', 'RLI-M', 'BI-I']\n",
    "\n",
    "for c, baseline_name in enumerate(order_dict):\n",
    "    result = []\n",
    "    for i in mean_dict.keys():\n",
    "        result.append(mean_dict[i][baseline_name][0])\n",
    "    ax.scatter(list(diameter_dict.values()), result, c=color_list[c], label=baseline_name, alpha=0.7)\n",
    "    \n",
    "ax.set_xlabel('Diameter', fontsize=18)\n",
    "ax.set_ylabel('Mean Average Payoff', fontsize=18)\n",
    "ax.vlines(9, 50, 90, lw=1, ls=(1, (3, 2)), color='gray')\n",
    "ax.tick_params(axis = 'both', labelsize=12)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10, loc=4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig4c.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64263062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short diameter bar plot\n",
    "fig = plt.figure(figsize=(1, 1), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['#F16745', '#0476D0', '#FFC65D']\n",
    "order_dict = ['RLI-C', 'RLI-M', 'BI-I']\n",
    "bar_data = []\n",
    "\n",
    "for c, baseline_name in enumerate(order_dict):\n",
    "    result = []\n",
    "    for i in mean_dict.keys():\n",
    "        if diameter_dict[i] < 10:\n",
    "            result.append(mean_dict[i][baseline_name][0])\n",
    "    print(len(result))\n",
    "    bar_data.append([np.mean(np.array(result)), np.std(np.array(result))/np.sqrt(len(result))])\n",
    "        \n",
    "bar_data = np.array(bar_data)\n",
    "ax.bar(np.arange(3), bar_data[:, 0], color = color_list, yerr = 2*bar_data[:, 1])\n",
    "#ax.set_xlabel('Diameter', fontsize=18)\n",
    "#ax.set_ylabel('Mean Average Payoff', fontsize=18)\n",
    "ax.set_ylim(50, 100)\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis = 'both', labelsize=8)\n",
    "\n",
    "\n",
    "#ax.legend(fontsize=10, loc=4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Fig4c1.svg', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## p2 / p3\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "im_data = facecolors[:, :, -1].transpose(1, 0, 2)\n",
    "#im_data[..., -1] *= 2\n",
    "ax.imshow(im_data, origin='lower', extent=[0, 100, 0, 100])\n",
    "ax.set_xlabel(r'$p_3$', fontsize=30, labelpad=-70)\n",
    "ax.set_ylabel(r'$p_2$', fontsize=30, labelpad=-85)\n",
    "ax.set_xticks([0, 50, 100])\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.tick_params(axis = 'x', labelsize=24)\n",
    "ax.tick_params(axis = 'y', labelsize=24)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Fig2f_2.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19421c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation\n",
    "import matplotlib.animation as manimation\n",
    "\n",
    "try:\n",
    "    # self score\n",
    "    max_s = 100\n",
    "    s = 50\n",
    "    epoch_list = np.arange(0, 12850, 50)\n",
    "    graph_type = 'complete'\n",
    "    exp_name = 'EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "    label = 'EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "    name = f'{graph_type}_s{s}_{label}'\n",
    "    rescale = False\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, -75)\n",
    "    FFMpegWriter = manimation.writers['ffmpeg']\n",
    "    metadata = dict(title=f'test_{name}.mp4', artist='Matplotlib', comment='SocialNet')\n",
    "    writer = FFMpegWriter(fps=10, metadata=metadata)\n",
    "    writer.setup(fig, f'test_{name}.mp4', dpi=200)\n",
    "\n",
    "    for epoch in epoch_list:\n",
    "        ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "        print(epoch)\n",
    "        template = template_a1\n",
    "        \n",
    "        tc = coord_triplet(max_s)\n",
    "        data = np.repeat(template.reshape(1, 4, 17), len(tc), axis=0).astype(np.float)\n",
    "        tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "        if rescale:\n",
    "            data[:, :, -2] = tc\n",
    "        else:\n",
    "            data[:, :, -2] = tc / 100.\n",
    "        pi_list = []\n",
    "\n",
    "        for i in range((data.shape[0]//10000)+1):\n",
    "            a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "            x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "            pi_list.append(x)\n",
    "        pi_list = np.concatenate(pi_list, axis=0)\n",
    "        sp = template[0][:-2]\n",
    "        cp = template[-2][:-2]\n",
    "        hp = template[-1][:-2]\n",
    "        facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s)\n",
    "        stride = 5\n",
    "        assert max_s%stride == 0\n",
    "        facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "        \n",
    "        IMG_DIM = len(facecolors)\n",
    "        facecolors = explode(facecolors)\n",
    "        filled = facecolors[:,:,:,-1] != 0\n",
    "        #print(filled.shape)\n",
    "        #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "        x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "        ax.set_xlim(right=IMG_DIM*stride)\n",
    "        ax.set_ylim(top=IMG_DIM*stride)\n",
    "        ax.set_zlim(top=IMG_DIM*stride)\n",
    "\n",
    "        ax.set_xlabel(r'$p_3$', fontsize=18)\n",
    "        ax.set_ylabel(r'$p_2$', fontsize=18)\n",
    "        ax.set_zlabel(r'$p_1$', fontsize=18)\n",
    "        #ax.set_xticklabels([])\n",
    "        #ax.set_yticklabels([])\n",
    "        #ax.set_zticklabels([])\n",
    "        #ax.set_xticks([0, 50, 100])\n",
    "        #ax.set_yticks([0, 50, 100])\n",
    "        #ax.set_zticks([0, 50, 100])\n",
    "        #ax.tick_params(axis = 'x', labelsize=12)\n",
    "        #ax.tick_params(axis = 'y', labelsize=12)\n",
    "        #ax.tick_params(axis = 'z', labelsize=12)\n",
    "\n",
    "        ax.voxels(x/2*stride, y/2 * stride, z/2 * stride, filled, facecolors=facecolors, shade=False)\n",
    "        ax.text(20, 30, 5, f'Epoch {epoch}')\n",
    "        writer.grab_frame(facecolor='w')\n",
    "        ax.clear()\n",
    "    writer.finish()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    writer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c98949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation, SIRF\n",
    "import matplotlib.animation as manimation\n",
    "\n",
    "try:\n",
    "    # self score\n",
    "    max_s = 100\n",
    "    s = 50\n",
    "    epoch_list = np.arange(0, 5450, 50)\n",
    "    graph_type = 'complete'\n",
    "    exp_name = 'SIRF_TT_gene_ent_EC0.003_N15K7NN3RSFTMT_Z_adam_cr-1_lr1e-5_g98'\n",
    "    label = exp_name\n",
    "    name = f'{graph_type}_s{s}_{label}'\n",
    "    rescale = False\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(30, -75)\n",
    "    FFMpegWriter = manimation.writers['ffmpeg']\n",
    "    metadata = dict(title=f'test_{name}.mp4', artist='Matplotlib', comment='SocialNet')\n",
    "    writer = FFMpegWriter(fps=10, metadata=metadata)\n",
    "    writer.setup(fig, f'test_{name}.mp4', dpi=200)\n",
    "\n",
    "    for epoch in epoch_list:\n",
    "        ac, obs_dim, act_dim, dim_len, gamma, lam, env_kwargs = load_model(exp_name, epoch)\n",
    "        print(epoch)\n",
    "        template = template_a1\n",
    "        neighbor_num = 3\n",
    "        offset = 4\n",
    "        template = np.c_[template, np.array([[-1, 0], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num], [-1, 1 / neighbor_num]])]\n",
    "        \n",
    "        tc = coord_triplet(max_s)\n",
    "        data = np.repeat(template.reshape(1, 4, 19), len(tc), axis=0).astype(np.float)\n",
    "        tc = np.c_[np.ones(tc.shape[0])*s, tc]\n",
    "        if rescale:\n",
    "            data[:, :, -offset] = tc\n",
    "        else:\n",
    "            data[:, :, -offset] = tc / 100.\n",
    "\n",
    "        score_rank = rankdata(tc, axis=-1, method='min') / (neighbor_num + 1)\n",
    "        data[:, :, -2] = score_rank\n",
    "        pi_list = []\n",
    "        ent = 0\n",
    "        for i in range((data.shape[0]//10000)+1):\n",
    "            a, v, logp, pi = ac.step(torch.as_tensor(data[i*10000:(i+1)*10000], dtype=torch.float32, device='cuda'), return_pi=True)\n",
    "            x = pi.probs[..., 1].detach().cpu().numpy()\n",
    "            ent += pi.entropy().sum()\n",
    "            pi_list.append(x)\n",
    "            #print(x, pi.entropy().sum())\n",
    "        pi_list = np.concatenate(pi_list, axis=0)\n",
    "        ent /= data.shape[0] * 15\n",
    "        sp = template[0][:-offset]\n",
    "        cp = template[-2][:-offset]\n",
    "        hp = template[-1][:-offset]\n",
    "        facecolors, sp_dist, cp_dist, hp_dist = assign_facecolors(pi_list, sp, cp, hp, True, True, True, max_s)\n",
    "        stride = 5\n",
    "        assert max_s%stride == 0\n",
    "        facecolors = facecolors[::stride, ::stride, ::stride]\n",
    "        \n",
    "        IMG_DIM = len(facecolors)\n",
    "        facecolors = explode(facecolors)\n",
    "        filled = facecolors[:,:,:,-1] != 0\n",
    "        #print(filled.shape)\n",
    "        #print(np.indices(np.array(filled.shape) + 1).shape)\n",
    "        x, y, z = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "        ax.set_xlim(right=IMG_DIM*stride)\n",
    "        ax.set_ylim(top=IMG_DIM*stride)\n",
    "        ax.set_zlim(top=IMG_DIM*stride)\n",
    "\n",
    "        ax.set_xlabel(r'$p_3$', fontsize=18)\n",
    "        ax.set_ylabel(r'$p_2$', fontsize=18)\n",
    "        ax.set_zlabel(r'$p_1$', fontsize=18)\n",
    "        #ax.set_xticklabels([])\n",
    "        #ax.set_yticklabels([])\n",
    "        #ax.set_zticklabels([])\n",
    "        #ax.set_xticks([0, 50, 100])\n",
    "        #ax.set_yticks([0, 50, 100])\n",
    "        #ax.set_zticks([0, 50, 100])\n",
    "        #ax.tick_params(axis = 'x', labelsize=12)\n",
    "        #ax.tick_params(axis = 'y', labelsize=12)\n",
    "        #ax.tick_params(axis = 'z', labelsize=12)\n",
    "\n",
    "        ax.voxels(x/2*stride, y/2 * stride, z/2 * stride, filled, facecolors=facecolors, shade=False)\n",
    "        ax.text(20, 30, 5, f'Epoch {epoch}')\n",
    "        writer.grab_frame(facecolor='w')\n",
    "        ax.clear()\n",
    "    writer.finish()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    writer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "K = 14\n",
    "with open(f'./baseline_complete_N{N}K{K}NN3.pkl', 'rb') as f:\n",
    "    baseline_data_dict = pickle.load(f)\n",
    "\n",
    "# Figure drawing\n",
    "fig = plt.figure(figsize=(4,4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "color_list = ['red', 'blue', 'orange', 'yellow', 'black', 'gray', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowBest_prob':'BI-P',\n",
    "              'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R', 'FollowMajor_prob':'CF-P',\n",
    "             'IndvLearning':'PI', 'IndvRandom':'PI-R', 'IndvProb':'PI-P', 'RandomCopy':'RI'}\n",
    "counter=0\n",
    "\n",
    "for baseline_name in label_dict.keys():\n",
    "    x = baseline_data_dict[baseline_name]['scr_buf']\n",
    "    avg_pf = np.mean(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    std_pf = np.std(x, axis=tuple(range(0, len(x.shape) - 1)))\n",
    "    ax.plot(np.arange(x.shape[-1]), avg_pf, c=color_list[counter], ls=(0, (3, 2)), label=label_dict[baseline_name])\n",
    "    #ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "    counter+=1\n",
    "\n",
    "#ax.fill_between(np.arange(x.shape[-1]), avg_pf-std_pf, avg_pf+std_pf, facecolor=color_list[counter], alpha=0.2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Average Payoff')\n",
    "ax.legend(fontsize=8, loc=4)\n",
    "#fig_name = 'st_complete_indv_raw_full_total_random_SI_TT_N15K7NN3_disc_g99_I100_L200_RST_TMT'\n",
    "#plt.savefig(f'./result/figure/{fig_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=15\n",
    "max_K=15\n",
    "\n",
    "ret_complete_list = {K: {} for K in range(max_K)}\n",
    "final_complete_list = {K: {} for K in range(max_K)}\n",
    "\n",
    "color_list = ['red', 'blue', 'orange', 'yellow', 'black', 'gray', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "marker_list = ['o', 'x', 's', 'p', '*', '<', '>', 'd', 'v']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowBest_prob':'BI-P',\n",
    "              'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R', 'FollowMajor_prob':'CF-P',\n",
    "             'IndvLearning':'PI', 'IndvRandom':'PI-R', 'IndvProb':'PI-P', 'RandomCopy':'RI'}\n",
    "\n",
    "\n",
    "for K in range(max_K):\n",
    "    with open(f'./result/baseline_complete_N{N}K{K}NN3.pkl', 'rb') as f:\n",
    "        baseline_data_dict = pickle.load(f)\n",
    "    for i, baseline_name in enumerate(label_dict.keys()):\n",
    "        ret_complete_list[K][baseline_name] = baseline_data_dict[baseline_name]['Ret']\n",
    "        final_complete_list[K][baseline_name] = baseline_data_dict[baseline_name]['FinalScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=15\n",
    "max_K=15\n",
    "\n",
    "ret_maxmc_list = {K: {} for K in range(max_K)}\n",
    "final_maxmc_list = {K: {} for K in range(max_K)}\n",
    "\n",
    "color_list = ['red', 'blue', 'orange', 'yellow', 'black', 'gray', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "marker_list = ['o', 'x', 's', 'p', '*', '<', '>', 'd', 'v']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowBest_prob':'BI-P',\n",
    "              'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R', 'FollowMajor_prob':'CF-P',\n",
    "             'IndvLearning':'PI', 'IndvRandom':'PI-R', 'IndvProb':'PI-P', 'RandomCopy':'RI'}\n",
    "\n",
    "for K in range(max_K):\n",
    "    with open(f'./baseline_maxmc_N{N}K{K}NN3.pkl', 'rb') as f:\n",
    "        baseline_data_dict = pickle.load(f)\n",
    "    for i, baseline_name in enumerate(label_dict.keys()):\n",
    "        ret_maxmc_list[K][baseline_name] = baseline_data_dict[baseline_name]['Ret']\n",
    "        final_maxmc_list[K][baseline_name] = baseline_data_dict[baseline_name]['FinalScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=15\n",
    "max_K=15\n",
    "\n",
    "ret_complete4_list = {K: {} for K in range(max_K)}\n",
    "final_complete4_list = {K: {} for K in range(max_K)}\n",
    "\n",
    "color_list = ['red', 'blue', 'orange', 'yellow', 'black', 'gray', 'limegreen', 'darkgreen','deepskyblue', 'royalblue', 'purple', 'gold']\n",
    "marker_list = ['o', 'x', 's', 'p', '*', '<', '>', 'd', 'v']\n",
    "label_dict = {'FollowBest':'BI', 'FollowBest_indv':'BI-I', 'FollowBest_random':'BI-R', 'FollowBest_prob':'BI-P',\n",
    "              'FollowMajor':'CF', 'FollowMajor_indv':'CF-I', 'FollowMajor_random':'CF-R', 'FollowMajor_prob':'CF-P',\n",
    "             'IndvLearning':'PI', 'IndvRandom':'PI-R', 'IndvProb':'PI-P', 'RandomCopy':'RI'}\n",
    "\n",
    "\n",
    "for K in range(max_K):\n",
    "    with open(f'./baseline_complete_N{N}K{K}NN3_exp4.pkl', 'rb') as f:\n",
    "        baseline_data_dict = pickle.load(f)\n",
    "    for i, baseline_name in enumerate(label_dict.keys()):\n",
    "        ret_complete4_list[K][baseline_name] = baseline_data_dict[baseline_name]['Ret']\n",
    "        final_complete4_list[K][baseline_name] = baseline_data_dict[baseline_name]['FinalScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = ['FollowBest_indv', 'FollowBest_prob', 'FollowBest_random', 'FollowMajor_indv', 'FollowMajor_prob', 'FollowMajor_prob'] \n",
    "for K in range(max_K):\n",
    "    for i, baseline_name in enumerate(fig_list):\n",
    "        ax.scatter(ret_list[K][baseline_name], final_list[K][baseline_name], c=color_list[K], marker=marker_list[i], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0881a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = ['FollowBest_indv', 'FollowBest_prob', 'FollowBest_random', 'FollowMajor_indv', 'FollowMajor_prob', 'FollowMajor_prob'] \n",
    "for K in range(max_K):\n",
    "    for i, baseline_name in enumerate(fig_list):\n",
    "        ax.scatter(ret_list[K][baseline_name], final_list[K][baseline_name], c=color_list[i], s=(1/(K+1))*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = ['FollowBest_indv', 'FollowBest_prob', 'FollowBest_random', 'FollowMajor_indv', 'FollowMajor_prob', 'FollowMajor_prob'] \n",
    "K=7\n",
    "for i, baseline_name in enumerate(fig_list):\n",
    "    ax.scatter(ret_list[K][baseline_name], final_list[K][baseline_name], c=color_list[K], marker=marker_list[i], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = label_dict.keys()\n",
    "\n",
    "for i, baseline_name in enumerate(fig_list):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for K in range(15):\n",
    "        x_list.append(ret_complete_list[K][baseline_name])\n",
    "        y_list.append(final_complete_list[K][baseline_name])\n",
    "    ax.plot(list(range(15)), x_list, c=color_list[i], label=baseline_name)\n",
    "    \n",
    "ax.legend(fontsize=6, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d46237",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = label_dict.keys()\n",
    "\n",
    "for i, baseline_name in enumerate(fig_list):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for K in range(15):\n",
    "        x_list.append(ret_maxmc_list[K][baseline_name])\n",
    "        y_list.append(final_maxmc_list[K][baseline_name])\n",
    "    ax.plot(list(range(15)), x_list, c=color_list[i], label=baseline_name)\n",
    "    \n",
    "ax.legend(fontsize=6, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d992c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "ax = fig.add_subplot(111)\n",
    "fig_list = label_dict.keys()\n",
    "\n",
    "for i, baseline_name in enumerate(fig_list):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for K in range(max_K):\n",
    "        x_list.append(ret_complete4_list[K][baseline_name])\n",
    "        y_list.append(final_complete4_list[K][baseline_name])\n",
    "    ax.plot(list(range(max_K)), x_list, c=color_list[i], label=baseline_name)\n",
    "    \n",
    "ax.legend(fontsize=6, loc=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
